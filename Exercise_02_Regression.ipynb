{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GjkvxqusgFus"
   },
   "source": [
    "# Linear Models for Regression\n",
    "\n",
    "Given a training data set comprising N observations ${\\mathbf{x}^n \\in \\mathbb{R}^D }$ , where $n =1 ,...,N$ , together with corresponding target values ${ y^n \\in \\mathbb{R} }$ , the goal is to predict the value of $y $ for a new value of $\\mathbf{x}$.  \n",
    "\n",
    "In the simplest approach, this can be done by directly constructing an appropriate function $f(\\mathbf{x} )$ whose values for new inputs $\\mathbf{x}$ constitute the predictions for the corresponding values of $y$. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SijWis2soTNE"
   },
   "source": [
    "But first we define the required packages and create a small dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SJjqmkHQkHIf"
   },
   "source": [
    "\n",
    "### Packages\n",
    "\n",
    "Let's first import all the packages that you will need during this assignment.\n",
    "* `numpy` is the main package for scientific computing with Python.\n",
    "* `matplotlib` and `seaborn` are libraries to plot graphs in Python.\n",
    "* `np.random.seed(1)` is used to keep all the random function calls consistent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mTXgo2JijoCo"
   },
   "outputs": [],
   "source": [
    "# Insert the required Packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(1)\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sAYT7OS_k9_a"
   },
   "source": [
    "Define a function to generate a random data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gd3hCdKklMvg"
   },
   "outputs": [],
   "source": [
    "def dataset_regression(n=300,form = 'linear'): \n",
    "    x=np.sort(np.random.uniform(size=n)*2.*np.pi)\n",
    "    \n",
    "    if form =='non_linear':\n",
    "        y= 3.*np.sin(x)\n",
    "        # Add some noise to the observation \n",
    "        y += np.random.randn(n)/2.\n",
    "    else:\n",
    "        y = 2. * x - 5.5\n",
    "        # Add some noise to the observation \n",
    "        y += np.random.randn(n)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Reshape the observations to the shape (N,1)\n",
    "    x = x.reshape((-1, 1))\n",
    "    y = y.reshape((-1, 1))\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 354
    },
    "colab_type": "code",
    "id": "ZzupDsAWlwg3",
    "outputId": "17af9f6f-1ef4-4c22-9adc-74d2006c59f6"
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "n_samples = 150 # number of samples\n",
    "X_l, y_l = dataset_regression(n_samples, form = 'linear')\n",
    "X_n, y_n = dataset_regression(n_samples, form = 'non_linear')\n",
    "\n",
    "#print the shape of tha data: \n",
    "print('We have %d %d-dimensional observations.'%X_l.shape)\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize=(15,5))\n",
    "\n",
    "# Plot the dataset\n",
    "ax[0].scatter(X_l[:,0], y_l[:,0],s=40, cmap=plt.cm.Spectral, label = 'Dataset')\n",
    "ax[0].set_xlabel('x')\n",
    "ax[0].set_ylabel('y')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].scatter(X_n[:,0], y_n[:,0],s=40, cmap=plt.cm.Spectral, label = 'Dataset')\n",
    "ax[1].set_xlabel('x')\n",
    "ax[1].set_ylabel('y')\n",
    "ax[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q2slXQ_BhRjs"
   },
   "source": [
    "## Linear Basis Function Models\n",
    "The simplest linear model for regression is one that involves a linear combination of\n",
    "the input variables\n",
    "\n",
    "The output of the model for only one observation $\\mathbf{x}^{i} \\in \\mathbb{R}^D $\n",
    "$$ y^i = w_0 + w_1 x_1^i + ... + w_D x_D^i  \\tag{1}$$\n",
    "\n",
    "or for $N$ observations in matrix Form:\n",
    "$$ \\mathbf{y} = \\begin{bmatrix}\n",
    " y^1 \\\\ y^2 \\\\ \\vdots \\\\y^N\n",
    "\\end{bmatrix}, \\quad  \\mathbf{x} = \\begin{bmatrix}\n",
    "1&  \\mathbf{x}^1 \\\\ 1 & \\mathbf{x}^2 \\\\ \\vdots & \\vdots \\\\ 1 & \\mathbf{x}^N\n",
    "\\end{bmatrix},  \\quad \n",
    "\\mathbf{w} = \\begin{bmatrix}\n",
    " w_0 \\\\ w_1 \\\\ \\vdots \\\\w_D\n",
    "\\end{bmatrix}   \\Rightarrow$$\n",
    "\n",
    "$$\\mathbf{y} =  \\mathbf{x}\\mathbf{w} \\tag{2}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tw2lKnmUhQsT"
   },
   "outputs": [],
   "source": [
    "# 1D Models\n",
    "def constant_model(x):\n",
    "    return 0*x+3\n",
    "\n",
    "def inverter_model(x):\n",
    "    return (-1)*x+0    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "colab_type": "code",
    "id": "F5w1TvA4gDYf",
    "outputId": "b0eff0f1-77d6-406b-ba6a-28843c11ac96"
   },
   "outputs": [],
   "source": [
    "# Linear dataset\n",
    "res_1 = constant_model(X_l)\n",
    "res_2 = inverter_model(X_l)\n",
    "\n",
    "# Non linear dataset\n",
    "res_3 = constant_model(X_n)\n",
    "res_4 = inverter_model(X_n)\n",
    "\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize=(15,5))\n",
    "\n",
    "# Plot the dataset\n",
    "ax[0].scatter(X_l[:,0], y_l[:,0],s=40, cmap=plt.cm.Spectral, label = 'Dataset')\n",
    "ax[0].plot(X_l, res_1, c='g', label=\"constant\")\n",
    "ax[0].plot(X_l, res_2, c ='r', label=\"inverter\")\n",
    "ax[0].set_xlabel('x')\n",
    "ax[0].set_ylabel('y')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].scatter(X_n[:,0], y_n[:,0],s=40, cmap=plt.cm.Spectral, label = 'Dataset')\n",
    "ax[1].plot(X_n, res_3, c='g', label=\"constant\")\n",
    "ax[1].plot(X_n, res_4, c ='r', label=\"inverter\")\n",
    "ax[1].set_xlabel('x')\n",
    "ax[1].set_ylabel('y')\n",
    "ax[1].legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GPvzMJsNvjbQ"
   },
   "source": [
    "### Bringing data into matrix form\n",
    "\n",
    "Write a function to create a general linear model in **Matrix Form**, see Equation 2 :\n",
    "\n",
    "   **Note** you can use [ np.hstack](https://docs.scipy.org/doc/numpy/reference/generated/numpy.hstack.html) to stack arrays in sequence horizontally and  [ np.ones_like](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ones_like.html) to create an array of ones with the same shape and type as a given array.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ILEcWxg--s15"
   },
   "outputs": [],
   "source": [
    "# Returns the training data with an additional dimension(bias)\n",
    "def data_augmentation(X):\n",
    "    X_aug = np.hstack((np.ones_like(X), X))\n",
    "    \n",
    "    return X_aug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O25_UKey_c4O"
   },
   "source": [
    "Test your function and run the next code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "fk-7P_8T_jVd",
    "outputId": "fd4831ae-71b9-4eef-fc21-9946c209d4c3"
   },
   "outputs": [],
   "source": [
    "X_aug = data_augmentation(X_l)\n",
    "print('The first five augmented observations are:\\n', X_aug[:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5znTMPB3AHD8"
   },
   "source": [
    "### Task 1 (5 Min)\n",
    "\n",
    "Write a function to create a general linear model in **Matrix Form**, see Equation 2 :\n",
    "\n",
    "**Note** The matrix multiplication can be done using np.dot(a,b)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H03xUtOlwMQy"
   },
   "outputs": [],
   "source": [
    "# returns Predicted\n",
    "def linear_model(X_aug,w):\n",
    "    \n",
    "    # ToDo: compute y_estimate\n",
    "    y_estimate =    \n",
    "    \n",
    "    return  y_estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u3-QIWTnzBP-"
   },
   "source": [
    "Define the best weight vector for the linear data set and test your function `linear_model(X,w)` on linear dataset \n",
    "\n",
    "**Note**  you can define a vector matrix with numpy through:\n",
    "```python\n",
    "w = np.array([[1],[2]])\n",
    "```\n",
    "or use [np.expand_dims](https://https://docs.scipy.org/doc/numpy-1.15.1/reference/generated/numpy.expand_dims.html)  to expand the shape of one-dimensional array.\n",
    "\n",
    "\n",
    "```python\n",
    "w = np.array([1,2])\n",
    "w = np.expand_dims(w,axis=1)\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f2puFANizExf"
   },
   "outputs": [],
   "source": [
    "# Todo: write the best weight vector\n",
    "w ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zveq5guHBVYB"
   },
   "source": [
    "Test your function and run the next code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "colab_type": "code",
    "id": "KVUgkQOeBRxw",
    "outputId": "eb339b78-fdbb-4633-dfca-80f5229d5569"
   },
   "outputs": [],
   "source": [
    "# Make prediction \n",
    "y_estimate = linear_model(X_aug,w)\n",
    "\n",
    "# Plot the result\n",
    "fig,ax = plt.subplots(1,1,figsize=(7,5))\n",
    "\n",
    "# Plot the dataset\n",
    "ax.scatter(X_l[:,0], y_l[:,0],s=40, cmap=plt.cm.Spectral, label = 'Dataset')\n",
    "ax.plot(X_l, y_estimate, c='g', label=\"Linear model\")\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fJCocQEUw-CA"
   },
   "source": [
    "## Error Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "colab_type": "code",
    "id": "Tm_eo9LqxChu",
    "outputId": "23f0d361-8d4b-4b61-a788-fc2feff57b03"
   },
   "outputs": [],
   "source": [
    "# the index of the maximum error\n",
    "idx = np.argmax(- y_estimate[:,0] + y_l[:,0] )\n",
    "\n",
    "# Plot the error\n",
    "fig,ax = plt.subplots(1,1,figsize=(7,5))\n",
    "\n",
    "\n",
    "# Plot the dataset\n",
    "ax.scatter(X_l[:,0], y_l[:,0],s=40, cmap=plt.cm.Spectral, label = 'Dataset')\n",
    "ax.plot(X_l, y_estimate, c='g', label=\"Linear model\")\n",
    "ax.arrow(X_l[idx,0],y_estimate[idx,0], 0,- y_estimate[idx,0] + y_l[idx,0]-0.3, head_width=0.1, head_length=0.2, fc='k', ec='k')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f5_YSFm_3GVp"
   },
   "source": [
    "To estimate the accuracy of our model, we use the error function. One such function is the Mean Squared Error function, which measures the average of the squared difference between an estimation and the ground-truth value. The squared loss  would be the sum of square of the errors for each training point $\\mathbf{x}^i$ divided by the amount of points $N$.\n",
    "\n",
    "$$L = \\frac{1}{2N} \\sum^N_{i=1}(y^i- \\hat{y}^i )^2 \\tag{3}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DRfCBLDv5j_s"
   },
   "source": [
    "### Task 2 (5 Min)\n",
    "\n",
    "Write a function to estimate the  mean square error, see Equation 3. This function should return the loss function value and the error vector:\n",
    "$$\n",
    "\\mathbf{E} =\\mathbf{y} -  \\hat{\\mathbf{y}} $$\n",
    "\n",
    "\n",
    "**Note** Use the command ``y.shape[0]`` to estimate $N$,  ``errors**2`` to deterime the quadratic error and  [np.sum](https://docs.scipy.org/doc/numpy-1.15.1/reference/generated/numpy.sum.html)  to determine the sum of all  quadratic errors over the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "91RWJNoV37MK"
   },
   "outputs": [],
   "source": [
    "def loss_function(y,y_estimate):\n",
    "  \n",
    "  # ToDo: Compute error vector\n",
    "  E =\n",
    "  # ToDo: Compute the mean squared error\n",
    "  L =\n",
    "\n",
    "  return L, E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "32WI6G8fa5od"
   },
   "source": [
    "use the ``loss_function`` to determine the mean square error of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "w2QgbOB-fCEm",
    "outputId": "0e0353d4-4e54-4a9c-cc79-59bf5b02fd0e"
   },
   "outputs": [],
   "source": [
    "L, E = loss_function(y_l,y_estimate)\n",
    "print('The mean Square error is ', L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vNOvsY3jMY_e"
   },
   "source": [
    "## Linear Regression  using scikit Learn\n",
    "**Note** see the example on [sklearn.linear_model.LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_d8vC6u8pUbF"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "# fit_intercept: \n",
    "model_l = LinearRegression(fit_intercept=True)\n",
    "model_l.fit(X_l, y_l)\n",
    "yfit_l = model_l.predict(X_l)\n",
    "\n",
    "model_n = LinearRegression(fit_intercept=False)\n",
    "model_n.fit(X_n, y_n)\n",
    "yfit_n = model_n.predict(X_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3g5ZXPjvfXQN"
   },
   "source": [
    "run the next code to test your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "colab_type": "code",
    "id": "XFBIvaDtfcex",
    "outputId": "98598a9e-0732-4a41-ddb6-01a530147b04"
   },
   "outputs": [],
   "source": [
    "# Plot the result\n",
    "fig,ax = plt.subplots(1,2,figsize=(15,5))\n",
    "ax[0].scatter(X_l, y_l , s=40, cmap=plt.cm.Spectral, label = 'Ground Truth')\n",
    "ax[0].plot(X_l, yfit_l, c='g', label=\"Trained model\")\n",
    "ax[0].set_xlabel('x')\n",
    "ax[0].set_ylabel('y')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].scatter(X_n, y_n, s=40, cmap=plt.cm.Spectral, label = 'Ground Truth')\n",
    "ax[1].plot(X_n, yfit_n, c='g', label=\"Trained model\")\n",
    "ax[1].set_xlabel('x')\n",
    "ax[1].set_ylabel('y')\n",
    "ax[1].legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GUvvPQloNTi-"
   },
   "source": [
    "## Polynomial regression\n",
    "The key property of the linear model is that it is a linear function of the parameters $w_0 ,\\ldots,w_D$ .It is also, however, a linear function of the input variables $x_i$ , and this imposes significant limitations on the model. We therefore extend the class of models by considering linear combinations of fixed nonlinear functions of the input variables, of the form\n",
    "\n",
    "$$y^i=  f( x^i, w )= w_0 + \\sum_{j =1 }^{ D} w_j φ_j ( x^i )\\tag{7}$$\n",
    "\n",
    "where $φ_j ( x^i )$  are known as basis functions\n",
    "\n",
    "The Polynomial regression is a simple example for nonlinear basis functions\n",
    "$$ y = w_0 + w_1 x+  w_1 x^2 +  w_3 x^3  \\tag{8}$$\n",
    "\n",
    "**Note** see the example on [sklearn.preprocessing.PolynomialFeatures](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-2-4LB-qNWnr"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly=PolynomialFeatures(degree=3)\n",
    "\n",
    "poly_X =poly.fit_transform(X_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model=LinearRegression()\n",
    "model.fit(poly_X,y_n)\n",
    "\n",
    "yfit = model.predict(poly_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aAOLes7ypP2t"
   },
   "source": [
    "Run the next code to test your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "colab_type": "code",
    "id": "Pf4MS5SOpBq4",
    "outputId": "27e2f635-efee-4402-e0fb-615687858d84"
   },
   "outputs": [],
   "source": [
    "# Plot the result\n",
    "fig,ax = plt.subplots(1,1,figsize=(7,5))\n",
    "ax.scatter(X_n, y_n , s=40, cmap=plt.cm.Spectral, label = 'Ground Truth')\n",
    "ax.plot(X_n, yfit, c='g', label=\"Trained model\")\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Regression.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
