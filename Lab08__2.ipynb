{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e42763e",
   "metadata": {},
   "source": [
    "# Stochastic Simulation\n",
    "\n",
    "*Winter Semester 2023/24*\n",
    "\n",
    "12.01.2024\n",
    "\n",
    "Prof. Sebastian Krumscheid<br>\n",
    "Asstistant: Stjepan Salatovic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5187ec",
   "metadata": {},
   "source": [
    "<h3 align=\"center\">\n",
    "Exercise sheet 08\n",
    "</h3>\n",
    "\n",
    "---\n",
    "\n",
    "<h1 align=\"center\">\n",
    "Control Variates and Stratification\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f636d6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from ipywidgets import interact\n",
    "from scipy.stats import norm\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import Tuple, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a82b0a91-6d0f-436d-bc1e-bfc75cc60fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('axes', labelsize=14)     # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=12)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=12)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=14)    # legend fontsize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0d84ff-b2fb-4e5d-adb1-9fca7ff97936",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "Suppose we wish to construct a Brownian motion path\n",
    "$\\{B_t\\colon B_0=0,\\, 0\\le t\\le T\\}$ that finishes at $T= 1$ in $S$\n",
    "distinct strata. To stratify standard Brownian motion on its endpoint,\n",
    "one first generates the $S$ values at $T=1$ and then samples the\n",
    "Brownian paths on the interval $[0,T]$ conditional upon these\n",
    "stratified terminal values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fbb360-4b49-4967-b511-74a6172e4100",
   "metadata": {},
   "source": [
    "1. Implement an algorithm that generates\n",
    "\tstratified standard Brownian motion using $S$ equiprobable\n",
    "\tstrata. Specifically, for each stratum $\\Omega_j$, $j=1,\\dots,S$,\n",
    "\tyour algorithm should produce $N_j$ stratified Brownian samples\n",
    "\tpaths $B_{t_m}^{(i,j)}$, $i=1,\\dots,N_j$, evaluated in the discrete\n",
    "\ttimes $t_m = m/M$ with $m=1,\\dots, M\\in\\mathbb{N}$. Test your\n",
    "\timplementation for $S=12$, $M=1000$, and $N_j=2$ by plotting the\n",
    "\tstratified samples paths.\n",
    "\n",
    "    **Hint:** Brownian bridge sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01b72e91-f167-43fe-9fd3-b9a1382c6984",
   "metadata": {},
   "outputs": [],
   "source": [
    "def brownian_bridges(terminal_values: np.array, M: int) -> np.array:\n",
    "    \"\"\"\n",
    "    Generates Brownian bridges using `M` sample points that\n",
    "    start in 0 and end in given `terminal_values`.\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b1652fa-1700-49f7-969b-133675ba9c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_brownian_motions(S: int, N: np.array, M: int, T: float=1) -> np.array:\n",
    "    \"\"\"\n",
    "    Generates stratified Brownian motions with `S` strata and `M` sample points.\n",
    "    The array of sample sizes in each stratum is given by `N`.\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa0bd5f-8298-4d42-8353-dc16e6ebdfb4",
   "metadata": {},
   "source": [
    "2. Consider the geometric Brownian motion process $X_t$ that solves\n",
    "\t\\begin{equation*}\n",
    "\tdX= rX\\,dt + \\sigma X\\,dW\\;,\\quad X(0) = X_0\\;,\n",
    "\t\\end{equation*}\n",
    "\tand which is given by $X_t = X_0e^{Y_t}$, where\n",
    "\t$Y_t = (r-\\sigma^2/2)t + \\sigma W_t$ with $W$ being a standard\n",
    "\tWiener process. For $M\\in\\mathbb{N}$, let\n",
    "\t\\begin{equation*}\n",
    "\t\\Psi\\bigl(X_{t_0},\\dots , X_{t_M}\\bigr) = \\max_{0\\le m\\le M}X_{t_m} - \\min_{0\\le m\\le M}X_{t_m}\\;,\n",
    "\t\\end{equation*}\n",
    "\twhere $t_m=m/M$ as before.  We want to estimate\n",
    "\t$\\mu = \\mathbb{E}\\bigl[\\Psi\\bigl(X_{t_0},\\dots , X_{t_M}\\bigr)\\bigr]$ for\n",
    "\t$X_0=6$, $r=0.05$, $\\sigma = 0.3$, and $M=100$. Use your procedure\n",
    "\tdeveloped in point 1 to estimate $\\mu$ using\n",
    "\tstratified sampling with $S=10$ strata. Moreover, compute the total\n",
    "\tnumber of samples $N$ such that the asymptotic $99\\%$ confidence\n",
    "\tinterval is smaller than $2\\, tol$ for $tol = 10^{-2},\n",
    "\t10^{-3}$. Investigate both proportional and optimal sampling\n",
    "\tallocation in each strata and compare it to a crude Monte Carlo approach.\n",
    "\t\n",
    "\t**Remark:** The function $\\Psi$ is related to the value of a\n",
    "\tlook-back option whose payoff is equivalent to buying at the minimum\n",
    "\tand selling at the maximum price on the time interval $[0, T=1]$. As\n",
    "\tgiven here, $\\Psi$ omits the (constant) discount factor $e^{-rT}$\n",
    "\tthat compensates for waiting until time $T$ to collect the payoff.\n",
    "\n",
    "    **Remark:** At first glance, it may seem unusual that the `crude_Monte_carlo` and `stratification` function headers include an optional sample size `N` as an argument. This is because these functions are designed to automatically determine the sample size. However, the inclusion of `N` provides flexibility, allowing for a specific sample size to be set if needed. This will be particularly useful in the third part of the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "581875ab-7507-49e9-afb8-8b168b34528b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crude_Monte_Carlo(tol: float, N: float=None) -> Tuple[float, float, int]:\n",
    "    \"\"\"\n",
    "    Performs a crude Monte Carlo estimation based on a specified tolerance level, `tol`.\n",
    "    Returns the estimated mean, variance, as well as the sample size used.\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02343532-e611-4c4a-9cd8-c386093644b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratification(S: int, M: int, tol: float, alloc: str, N: int=None) -> Tuple[float, float, np.array]:\n",
    "    \"\"\"\n",
    "    Performs a stratified Monte Carlo simulation with `S` strata, based on a specified tolerance level, `tol`.\n",
    "    The allocation of samples to strata is determined by the `alloc` parameter, which can be either \"proportional\" or \"optimal\".\n",
    "    Returns the mean, variance, and number of samples in each stratum.\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da30480-9962-4570-8b9f-d2082e3b7d64",
   "metadata": {},
   "source": [
    "3. Repeat the previous point, but now consider only $N_j=2$ samples\n",
    "\tper stratum $\\Omega_j$, $j=1,\\dots, S$, and investigate the\n",
    "\testimator's variance decay as a function of $S$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6148b94d-8a5a-4fbf-9f66-2505abbd4561",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "Consider the problem of estimating $\\mu = \\mathbb{E}(Z)$ for $Z=\\psi(X)$ and\n",
    "$X\\sim U(0,1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9d0a41-ba28-4880-8dac-e9cb9a9f90b0",
   "metadata": {},
   "source": [
    "1. Show that the _randomized midpoint quadrature_ estimator\n",
    "\t\\begin{equation*}\n",
    "\t\\hat\\mu_S := \\frac{1}{S}\\sum_{j=1}^{S}\\psi\\biggl(\\frac{j-1+U_j}{S}\\biggr)\\;,\n",
    "\t\\end{equation*}\n",
    "\twith $U_1,\\dots,U_S$ i.i.d. $U(0,1)$, corresponds to a stratified\n",
    "\tsampling estimator of $\\mu$.\n",
    "\n",
    "    **Hint:** Consider uniform strata.\n",
    "   \n",
    "    **Optional:** Explain why $\\hat\\mu_S $ is called _randomized\n",
    "\t\tmidpoint quadrature_ estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e97b06-b15c-4057-9349-379072ab4727",
   "metadata": {},
   "source": [
    "2. Suppose that $\\psi\\in C^1\\bigl([0,1]\\bigr)$. Show that the\n",
    "\testimator $\\hat\\mu_S$, which is a Monte Carlo type\n",
    "\testimator, converges with _super-canonical rate_ (i.e. faster\n",
    "\tthan $S^{-1/2}$). Specifically, show that\n",
    "\t$$\\sqrt{\\mathbb{E}[{(\\mu-\\hat\\mu_S)}^2]} \\le c S^{-3/2}\\;,$$\n",
    "\tfor an appropriate positive constant $c<\\infty$ independent of\n",
    "\t$S$. Determine also the constant $c$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a906154a-1976-4bbc-a37d-395c128c698e",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "1. Consider the random variable $Z = 4\\, \\mathbb{I}_{\\{U_1^2 + U_2^2\\le 1\\}}$ with $U_1,U_2 \\overset{\\text{i.i.d.}}{\\sim} \\mathcal{U}(0,1)$, so that $\\mathbb{E}(Z) = \\pi$. Consider the control variates $\\tilde{Z}_{\\alpha,i} = Z - \\alpha(Y_i-\\mathbb{E}(Y_i))$ where the controls $Y_i$ are given by:\n",
    "$$\n",
    "Y_1 := \\mathbb{I}_{\\{U_1 + U_2\\le 1\\}}\\;,\\quad Y_2 := \\mathbb{I}_{\\{U_1 + U_2\\ge \\sqrt{2}\\}}\\;,\\quad\\text{and}\\quad Y_3 := (U_1+U_2-1)\\mathbb{I}_{\\{1<U_1 + U_2\\le \\sqrt{2}\\}}\\;.\n",
    "$$\n",
    "Estimate their respective expected variance reduction $\\mathbb{V}\\text{ar}(\\tilde{Z}_{\\alpha, i})/\\mathbb{V}\\text{ar}(Z)$ using $N= 10^6$ simulations.\n",
    "\n",
    "    **Hint:** The expectations for the control variates are given by\n",
    "    - $\\mathbb{E}(Y_1) = 1/2$\n",
    "    - $\\mathbb{E}(Y_2) = 3 - 2\\sqrt{2}$\n",
    "    - $\\mathbb{E}(Y_3) = -\\frac{8\\sqrt{2}}{3} +\\frac{23}{6}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7503240-0485-4f5e-af55-5ed1ddb46c73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def control_variate_estimator(Z: np.array, Y: np.array, mean_Y: float) -> np.array:\n",
    "    \"\"\"\n",
    "    Control variate estimation using original (`Z`) and control variate realizations (`Y`),\n",
    "    as well as the expected value for Y (`mean_Y`).\n",
    "    Returns the control variate estimator array.\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b433d7-3011-4d6f-9c65-886a54fd7af4",
   "metadata": {},
   "source": [
    "2. Consider again the random variable  $Z= 4\\, \\mathbb{I}_{\\{U_1^2 + U_2^2\\le 1\\}}$ as in point 1.\n",
    "We now wish to use multiple control variates and compare their variance reduction to the single control variate case.\n",
    "Consider the control variate $\\tilde{Z}_{\\boldsymbol{\\alpha}} = Z - \\boldsymbol{\\alpha} \\cdot (\\mathbf{Y} - \\mathbb{E}(\\mathbf{Y}))$ where $\\boldsymbol{\\alpha} \\in \\mathbb{R}^d$ and $\\mathbf{Y}$ is a $d$-dimensional control vector.\n",
    "Perform simulations and report the expected variance reduction $\\mathbb{V}\\text{ar}(\\tilde{Z}_{\\boldsymbol{\\alpha}}) / \\mathbb{V}\\text{ar}(Z)$ for each of the following control vectors:\n",
    "    \\begin{equation*}\n",
    "      \\boldsymbol{Y}^1 := (Y_1,Y_2)^T\\;,  \\quad \\boldsymbol{Y}^2 := (Y_1,Y_3)^T\\;,  \\quad\n",
    "      \\boldsymbol{Y}^3 := (Y_2,Y_3)^T\\;,  \\quad\\text{and}\\quad\n",
    "      \\boldsymbol{Y}^4 := (Y_1,Y_2,Y_3)^T\\;.\n",
    "    \\end{equation*}\n",
    "Here, the random variables $Y_i$, $i=1,2,3$ are as described in point 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8d014c8-291e-4b83-8649-73c08944d69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_control_variate_estimator(Z: np.array, Y: List[np.array], mean_Y: List[float]) -> np.array:\n",
    "    \"\"\"\n",
    "    Control variate estimation using original (`Z`) and control variates realizations (`Y`),\n",
    "    as well as the expected values for Y (`mean_Y`).\n",
    "    Returns the control variate estimator array.\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d207dc44-6b1e-4e5f-a930-a36e78764961",
   "metadata": {},
   "source": [
    "3. Implement a one-shot control variate algorithm for the control vector with the best variance reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aac4e3f2-7139-4561-8804-fa37d2e02d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_shot_best_variance(N: int, alpha: float=0.05) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Performs a one-shot Monte Carlo simulation with `N` samples using\n",
    "    control variate estimation to calculate the mean and confidence interval.\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39983de6-a989-4d85-beed-232181a68220",
   "metadata": {},
   "source": [
    "4. **Optional:** Show that the expectations of the control variates\n",
    "$$\n",
    "Y_1 := \\mathbb{I}_{\\{U_1 + U_2\\le 1\\}}\\;,\\quad Y_2 := \\mathbb{I}_{\\{U_1 + U_2\\ge \\sqrt{2}\\}}\\;,\\quad\\text{and}\\quad Y_3 := (U_1+U_2-1)\\mathbb{I}_{\\{1<U_1 + U_2\\le \\sqrt{2}\\}}\n",
    "$$\n",
    "are indeed given by\n",
    "    - $\\mathbb{E}(Y_1) = 1/2$\n",
    "    - $\\mathbb{E}(Y_2) = 3 - 2\\sqrt{2}$\n",
    "    - $\\mathbb{E}(Y_3) = -\\frac{8\\sqrt{2}}{3} +\\frac{23}{6}$.\n",
    "\n",
    "\n",
    "   **Hint:** Keep in mind that the probability density function for the sum of two independent random variables can be determined by performing the convolution of their individual density functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7231beed-b98d-468f-bbf5-47f757c3bd55",
   "metadata": {},
   "source": [
    "## Exercise 4 (optional, no solution)\n",
    "\n",
    "Let $Z$ be a random variable of which we would like to estimate the mean value and let $Y$ be a suitable control variate. It the mean of $Y$ is known, we can build a Control Variate Monte Carlo estimator as $$\\tag{1}\\hat\\mu_{CV} = \\frac{1}{N}\\sum_i ( Z^{(i)}-\\alpha (Y^{(i)}-E[Y]) ) ,\\text{ with } (Z^{(i)},Y^{(i)}) \\sim \\text{i.i.d $(Z,Y)$}.$$\n",
    "\n",
    "Consider now that case in which $\\mathbb{E}[Y]$ is not known and we need to estimate it via sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffbdef4-c398-4e6f-a345-5a4560e30466",
   "metadata": {},
   "source": [
    "1. A first idea is to estimate $\\mathbb{E}[Y]$ by the sample average estimator $\\hat{\\mu}_Y = \\frac{1}{N} \\sum_j Y^{(j)}$ using the same sample as in Eq. (1). Show that the resulting estimator is unbiased but its variance is not smaller than (actually equal to) the one of a crude Monte Carlo estimator on $Z$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628df03a-7864-41d0-8a19-e1b7464eda53",
   "metadata": {},
   "source": [
    "2. A second idea is to estimate $\\mathbb{E}[Y]$ with an independent Monte Carlo estimator using a sample size $N_Y$.\n",
    "Let us denote by $C_Z$ the cost of generating $Z^{(i)}$ and by $C_Y$ the cost of generating $Y^{(i)}$, which we assume smaller than $C_Z$, and rename the sample size $N$ used in Eq.(1) as $N_Z$. For a given total budget $C=N_Z(C_Z+C_Y) + N_YC_Y$ for this control variate estimator, determine the optimal choice of $N_Z$ and $N_Y$ and the minimal variance achievable by the above strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e37b264-360a-4f9d-a395-38497d52912a",
   "metadata": {},
   "source": [
    "3. Compare then the variance obtained with that of a crude Monte Carlo estimator that uses a sample size $N$ the exhausts the same total budget $C=N C_Z$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
