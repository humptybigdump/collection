{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e609411-8095-4610-9412-950a16cf735b",
   "metadata": {},
   "source": [
    "# RL Framework\n",
    "\n",
    "- Environment\n",
    "- Agent\n",
    "\n",
    "<div>\n",
    "<img src=\"img/rl_base.png\" width=\"500\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b038dc-078c-4510-8d9e-b8ef6576b245",
   "metadata": {},
   "source": [
    "## Environment\n",
    "### GridWorld\n",
    "GridWorld is a 2D rectangular grid of size NxM. It has an **agent** starting in one of the grid squares and possible **rewards** in other grid squares.\n",
    "\n",
    "In our initial setup, the GridWorld is a 3x4 grid with the agent starting in the bottom left corner. The world contains a blocking state, a positive and a negative reward.\n",
    "\n",
    "The agent's **goal** is to receive a positive reward by moving up, down, left or right. The game ends when a reward is received.\n",
    "\n",
    "<div>\n",
    "<img src=\"img/grid_example.png\" width=\"250\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6920753b-8605-4339-a226-285adbcf67b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions of the GridWorld\n",
    "world_shape = (3, 4)\n",
    "\n",
    "# initial position of the agent\n",
    "agent_init_pos = (2, 0)\n",
    "\n",
    "# list of blocking state positions\n",
    "blocking_states = [(1, 1)]\n",
    "\n",
    "# dictionary of rewards with key: position and value: reward\n",
    "reward_states = {\n",
    "    (0,3): 1,\n",
    "    (1,3): -1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf423e85-6d61-492b-b907-0651acbfac34",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "For now, only a human agent will interact with our environment.\n",
    "\n",
    "We need some visualizations.\n",
    "\n",
    "The environment is represented by a 2D array. We will label\n",
    "- empty states with 0,\n",
    "- the agent with 4,\n",
    "- blocking states 8,\n",
    "- rewards with their respective values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a433090b-65ed-4c0b-b8d9-f42cd465ac0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  1.]\n",
      " [ 0.  8.  0. -1.]\n",
      " [ 4.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "legend = {\n",
    "    'empty': 0,\n",
    "    'agent': 4,\n",
    "    'blocking': 8\n",
    "}\n",
    "\n",
    "def render_environment(world_shape, agent_pos, blocking_states, reward_states):\n",
    "    # initialize empty states\n",
    "    states = np.ones(world_shape) * legend['empty']\n",
    "    \n",
    "    # add agent\n",
    "    states[tuple(agent_pos)] = legend['agent']\n",
    "    \n",
    "    # add blocking states\n",
    "    for blocking_state in blocking_states:\n",
    "        states[blocking_state] = legend['blocking']\n",
    "    \n",
    "    # add rewards\n",
    "    for state, reward in reward_states.items():\n",
    "        states[state] = reward\n",
    "    return states\n",
    "    \n",
    "render = render_environment(world_shape, agent_init_pos, blocking_states, reward_states)\n",
    "print(render)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c8841d-a043-464f-8905-bf71e8045fd7",
   "metadata": {},
   "source": [
    "### Actions\n",
    "Possible actions in the GridWorld:\n",
    "- up\n",
    "- down\n",
    "- right\n",
    "- left\n",
    "\n",
    "the agent is blocked by the bounds of the GridWorld and blocking states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d805d87f-96e3-456f-9f2d-b89c63f700a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  1.]\n",
      " [ 0.  8.  0. -1.]\n",
      " [ 4.  0.  0.  0.]]\n",
      "going down\n",
      "[[ 0.  0.  0.  1.]\n",
      " [ 0.  8.  0. -1.]\n",
      " [ 4.  0.  0.  0.]]\n",
      "going up\n",
      "[[ 0.  0.  0.  1.]\n",
      " [ 4.  8.  0. -1.]\n",
      " [ 0.  0.  0.  0.]]\n",
      "going right\n",
      "[[ 0.  0.  0.  1.]\n",
      " [ 4.  8.  0. -1.]\n",
      " [ 0.  0.  0.  0.]]\n",
      "going left\n",
      "[[ 0.  0.  0.  1.]\n",
      " [ 4.  8.  0. -1.]\n",
      " [ 0.  0.  0.  0.]]\n",
      "going up\n",
      "[[ 4.  0.  0.  1.]\n",
      " [ 0.  8.  0. -1.]\n",
      " [ 0.  0.  0.  0.]]\n",
      "going up\n",
      "[[ 4.  0.  0.  1.]\n",
      " [ 0.  8.  0. -1.]\n",
      " [ 0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "possible_actions = {\n",
    "    'up': np.array([-1, 0]),\n",
    "    'down': np.array([1, 0]),\n",
    "    'right': np.array([0, 1]),\n",
    "    'left': np.array([0, -1])\n",
    "}\n",
    "\n",
    "def move_agent(agent_pos, action, world_shape, blocking_states):\n",
    "    # move agent\n",
    "    new_agent_pos = np.array(agent_pos) + possible_actions[action]\n",
    "    \n",
    "    # check if new position is blocked\n",
    "    if tuple(new_agent_pos) in blocking_states:\n",
    "        return agent_pos\n",
    "    \n",
    "    # check if new position is out of bounds\n",
    "    if (new_agent_pos < 0).any() or (new_agent_pos >= world_shape).any():\n",
    "        return agent_pos\n",
    "        \n",
    "    return tuple(new_agent_pos)\n",
    "\n",
    "# Test some actions\n",
    "actions = ['down', 'up', 'right', 'left', 'up', 'up']\n",
    "new_agent_pos = agent_init_pos\n",
    "render = render_environment(world_shape, new_agent_pos, blocking_states, reward_states)\n",
    "print(render)\n",
    "for action in actions:\n",
    "    print(f'going {action}')\n",
    "    new_agent_pos = move_agent(new_agent_pos, action, world_shape, blocking_states)\n",
    "    render = render_environment(world_shape, new_agent_pos, blocking_states, reward_states)\n",
    "    print(render)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cbf5f2-2fa0-47a0-82a2-eff7ea315e88",
   "metadata": {},
   "source": [
    "### Putting it together\n",
    "We have everything for the environment.\n",
    "\n",
    "Wi implement it in a class, that holds all required information (dimensions, agent_position ...) and can \n",
    "- <code>reset</code> the GridWorld to its initial state\n",
    "- <code>step</code> the environment by executing actions, returning new observations, calculating rewards and deciding whether the game has ended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7e28377-a8f9-414f-880a-f31e810f4711",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridWorld:\n",
    "    def __init__(self, world_shape, agent_init_pos, blocking_states, reward_states):\n",
    "        self.world_shape = world_shape\n",
    "        self.agent_init_pos = agent_init_pos\n",
    "        self.blocking_states = blocking_states\n",
    "        self.reward_states = reward_states\n",
    "        \n",
    "        self.agent_current_pos = self.agent_init_pos\n",
    "        \n",
    "    def reset(self):\n",
    "        # reset agent position\n",
    "        self.agent_current_pos = self.agent_init_pos\n",
    "            \n",
    "        # render initial observation\n",
    "        observation = render_environment(self.world_shape, \n",
    "                                         self.agent_current_pos, \n",
    "                                         self.blocking_states, \n",
    "                                         self.reward_states)\n",
    "        return observation\n",
    "        \n",
    "    def step(self, action):\n",
    "        # execute action\n",
    "        self.agent_current_pos = move_agent(self.agent_current_pos, \n",
    "                                            action, \n",
    "                                            self.world_shape, \n",
    "                                            self.blocking_states)\n",
    "        \n",
    "        # check if there is any reward and whether the game ended\n",
    "        if self.agent_current_pos in self.reward_states.keys():\n",
    "            done = True\n",
    "            reward = self.reward_states[self.agent_current_pos]\n",
    "        else:\n",
    "            done = False\n",
    "            reward = 0\n",
    "            \n",
    "        # render observation\n",
    "        observation = render_environment(self.world_shape, \n",
    "                                         self.agent_current_pos, \n",
    "                                         self.blocking_states, \n",
    "                                         self.reward_states)\n",
    "        return observation, reward, done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d95e24c-46bb-4c66-97e9-9c6680bf040c",
   "metadata": {},
   "source": [
    "## Agent\n",
    "We use python's <code>input()</code> method to receive actions from the human agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb6fc7bc-020f-47bb-abca-502f60df0ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "move with w, a, s, d; exit with q -  ljkj\n",
      "move with w, a, s, d; exit with q -  w\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'up'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def receive_action_input():\n",
    "    # read input and translate to action\n",
    "    action = input('move with w, a, s, d; exit with q - ')\n",
    "    if action == 'w':\n",
    "        return 'up'\n",
    "    elif action == 'a':\n",
    "        return 'left'\n",
    "    elif action == 's':\n",
    "        return 'down'\n",
    "    elif action == 'd':\n",
    "        return 'right'\n",
    "    # additional action to exit from GridWorld\n",
    "    elif action == 'q':\n",
    "        return 'exit'\n",
    "    else:\n",
    "        return receive_action_input()\n",
    "    \n",
    "receive_action_input()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daad8708-eaf2-4f43-88f6-58172fae0350",
   "metadata": {},
   "source": [
    "To act, the observation is presented and the agent is prompted to input an action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef35231b-f3ca-4a4b-b56e-dc1fd723f886",
   "metadata": {},
   "outputs": [],
   "source": [
    "def act(observation):\n",
    "    # present observation to human agent\n",
    "    print(observation)\n",
    "    \n",
    "    # obtain action from human agent\n",
    "    action = receive_action_input()\n",
    "    return action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68df1d87-ecd0-4c88-9356-dab87b0c6055",
   "metadata": {},
   "source": [
    "## Agent Environment Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfa48de3-e098-4ffb-bb8f-78b581974e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  1.]\n",
      " [ 0.  8.  0. -1.]\n",
      " [ 4.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "move with w, a, s, d; exit with q -  w\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "went up, received reward 0\n",
      "[[ 0.  0.  0.  1.]\n",
      " [ 4.  8.  0. -1.]\n",
      " [ 0.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "move with w, a, s, d; exit with q -  s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "went down, received reward 0\n",
      "[[ 0.  0.  0.  1.]\n",
      " [ 0.  8.  0. -1.]\n",
      " [ 4.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "move with w, a, s, d; exit with q -  d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "went right, received reward 0\n",
      "[[ 0.  0.  0.  1.]\n",
      " [ 0.  8.  0. -1.]\n",
      " [ 0.  4.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "move with w, a, s, d; exit with q -  d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "went right, received reward 0\n",
      "[[ 0.  0.  0.  1.]\n",
      " [ 0.  8.  0. -1.]\n",
      " [ 0.  0.  4.  0.]]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "move with w, a, s, d; exit with q -  d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "went right, received reward 0\n",
      "[[ 0.  0.  0.  1.]\n",
      " [ 0.  8.  0. -1.]\n",
      " [ 0.  0.  0.  4.]]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "move with w, a, s, d; exit with q -  w\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "went up, received reward -1\n",
      "============= game over =============\n",
      "[[ 0.  0.  0.  1.]\n",
      " [ 0.  8.  0. -1.]\n",
      " [ 4.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "move with w, a, s, d; exit with q -  w\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "went up, received reward 0\n",
      "[[ 0.  0.  0.  1.]\n",
      " [ 4.  8.  0. -1.]\n",
      " [ 0.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "move with w, a, s, d; exit with q -  w\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "went up, received reward 0\n",
      "[[ 4.  0.  0.  1.]\n",
      " [ 0.  8.  0. -1.]\n",
      " [ 0.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "move with w, a, s, d; exit with q -  d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "went right, received reward 0\n",
      "[[ 0.  4.  0.  1.]\n",
      " [ 0.  8.  0. -1.]\n",
      " [ 0.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "move with w, a, s, d; exit with q -  d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "went right, received reward 0\n",
      "[[ 0.  0.  4.  1.]\n",
      " [ 0.  8.  0. -1.]\n",
      " [ 0.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "move with w, a, s, d; exit with q -  d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "went right, received reward 1\n",
      "============= game over =============\n",
      "[[ 0.  0.  0.  1.]\n",
      " [ 0.  8.  0. -1.]\n",
      " [ 4.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "move with w, a, s, d; exit with q -  q\n"
     ]
    }
   ],
   "source": [
    "# initialize environment\n",
    "env = GridWorld(world_shape, agent_init_pos, blocking_states, reward_states)\n",
    "\n",
    "# reset environment and receive initial observaion\n",
    "obs = env.reset()\n",
    "while True:\n",
    "    # get action from agent\n",
    "    action = act(obs)\n",
    "    \n",
    "    # exit loop if exit action\n",
    "    if action == 'exit':\n",
    "        break\n",
    "    \n",
    "    # execute action in environment\n",
    "    obs, reward, done = env.step(action)\n",
    "    print(f'went {action}, received reward {reward}')\n",
    "    \n",
    "    # reset environment if game ended\n",
    "    if done:\n",
    "        print('============= game over =============')\n",
    "        obs = env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0e4863-2ac6-4d97-8fd8-b2a23b39200d",
   "metadata": {},
   "source": [
    "## Value\n",
    "The value is the cumulative future reward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d57693d2-b3e9-41fd-b941-19693220f265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 3, 2, 1, 0]\n",
      "[0, 4, 3, 2, 1]\n",
      "[ 0  4  7  9 10]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([10,  9,  7,  4,  0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_values(rewards):\n",
    "    # create a copy of rewards, to not change the original input\n",
    "    reversed_rewards = list(rewards)\n",
    "    \n",
    "    # reverse order, since we are interested in future rewards\n",
    "    reversed_rewards.reverse()\n",
    "    \n",
    "    # shift rewards to start cumulation from the next timestep\n",
    "    reversed_rewards = [0] + reversed_rewards[:-1]\n",
    "    \n",
    "    # calculate cumulative sum and reverse again, to obtain the original order\n",
    "    values = np.cumsum(reversed_rewards)\n",
    "    values = values[::-1]\n",
    "    return values\n",
    "\n",
    "rewards = [0, 1, 2, 3, 4]\n",
    "calculate_values(rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fb07f3-8145-4528-a2d3-3700f6c222aa",
   "metadata": {},
   "source": [
    "### Calculate values from a game "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ec71f70d-1894-45b1-84fe-2dd54087e1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  1.]\n",
      " [ 0.  8.  0. -1.]\n",
      " [ 4.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "move with w, a, s, d; exit with q -  d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "went right, received reward 0\n",
      "[[ 0.  0.  0.  1.]\n",
      " [ 0.  8.  0. -1.]\n",
      " [ 0.  4.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "move with w, a, s, d; exit with q -  d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "went right, received reward 0\n",
      "[[ 0.  0.  0.  1.]\n",
      " [ 0.  8.  0. -1.]\n",
      " [ 0.  0.  4.  0.]]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "move with w, a, s, d; exit with q -  d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "went right, received reward 0\n",
      "[[ 0.  0.  0.  1.]\n",
      " [ 0.  8.  0. -1.]\n",
      " [ 0.  0.  0.  4.]]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "move with w, a, s, d; exit with q -  w\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "went up, received reward -1\n",
      "[0, 0, 0, -1]\n",
      "[-1 -1 -1  0]\n"
     ]
    }
   ],
   "source": [
    "env = GridWorld(world_shape, agent_init_pos, blocking_states, reward_states)\n",
    "obs = env.reset()\n",
    "done = False\n",
    "\n",
    "# collect rewards from game\n",
    "rewards = []\n",
    "# also record agent position for later\n",
    "agent_positions = []\n",
    "while not done:\n",
    "    action = act(obs)\n",
    "    if action == 'exit':\n",
    "        break\n",
    "    agent_positions.append(env.agent_current_pos)\n",
    "    obs, reward, done = env.step(action)\n",
    "    rewards.append(reward)\n",
    "    print(f'went {action}, received reward {reward}')\n",
    "    \n",
    "print(rewards)\n",
    "values = calculate_values(rewards)\n",
    "print(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43ff78b-380b-4752-828c-eca9b6df4462",
   "metadata": {},
   "source": [
    "### Visualize obtained values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6d239404-5df4-4c6e-9fec-fab0db378076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.],\n",
       "       [-1., -1., -1.,  0.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def visualize_values(values, positions, world_shape):\n",
    "    value_vis = np.zeros(world_shape)\n",
    "    for p, v in zip(positions, values):\n",
    "        value_vis[tuple(p)] = v\n",
    "    return value_vis\n",
    "\n",
    "visualize_values(values, agent_positions, env.world_shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c0ced5-5990-4b94-9bf6-169436b07b05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
