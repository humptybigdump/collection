{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geospatial Data Analysis I \n",
    "\n",
    "## Linear Regression - Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple linear regression with scikit-learn\n",
    "\n",
    "In this exercise we are going to use one of the demo datasets from scikit-learn (https://scikit-learn.org/stable/datasets/toy_dataset.html#diabetes-dataset). The \"diabetes dataset\" contains data from 442 people (age, sex, etc.). We will try to predict the blood sugar content (parameter \"s6\") depending on other parameters (= independent variables). \n",
    "\n",
    "- First, import the function `load_diabetes()` from the scikit-learn example datasets (`sklearn.datasets`), and load the dataset into your workspace (`data = load_diabetes()`). \n",
    "\n",
    "- Then, transform the actual data (`diabetes_dataset.data`) into a Pandas DataFrame, assigning the \"feature_names\" as column names (`columns = data.feature_names`).\n",
    "\n",
    "- Last, create another variable named \"target\" using the function `dataset.target`. This will be dependent variable of the regression analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before doing statistical analyses, it's always good too take a look at the actual data (explorative data analysis) and inspect the relation between the individual parameters. \n",
    "\n",
    "- Create a correlation matrix for all variables in the data set (e.g. using `DataFrame.corr`) and visualise it as a heatmap (e.g. `using seaborn.heatmap()`, see exercise bivariate statistics). \n",
    "\n",
    "- Tipp: You can specify the figure size in seaborn by changing the general seaborn setting (`sns.set(rc={'figure.figsize':(10,8)})`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the multiple regression analysis, pick two suitable independent variables from the correlation matrix:\n",
    "\n",
    "- these should correlate strongly with the dependent variable (here blood sugar level \"s6\")\n",
    "\n",
    "- and correlate less strongly with each other. \n",
    "\n",
    "Save the values of the two chosen variables into another DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we are going to split the dataset into a training and test dataset for later validation. \n",
    "\n",
    "- To do so, use the function `sklearn.model_selection.train_test_split()` with the dependent (Y) and independent variables (X) as inputs. Also, add the argument `test_size=0.2` to specficy that 20% of the dataset shall be used for test (and 80% for training). Accordingly the function generates four outputs (e.g. X_train, X_test, Y_train, Y_test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [4]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can perform the linear regression analysis on the created training data set using e.g. `sklearn.linear_model.LinearRegression()`. \n",
    "\n",
    "- As in the last exercises, we first need to create a method object (here linear regression object) using the default settings of `sklearn.linear_model.LinearRegression()` (i.e. empty bracket).\n",
    "\n",
    "- Then, we can fit the created object to the training data (`object.fit(X_train, Y_train)`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [5] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we evaluate the fitted linear regression model using the test dataset and error metrics. \n",
    "\n",
    "- Import the functions `mean_squared_error` and `r2_score` (coefficient of determination) from `sklearn.metrics`. \n",
    "\n",
    "- Evaluate the linear regression object by appending `.predict()`, to obtain the predicted Y values (independent variable). First, do so using the X values from the training data set, and then (separately) using the X values from the test dataset. \n",
    "\n",
    "- To evaluate the goodness of fit of your regression model, calculate the RMSE and coefficient of determination for the oringial Y values (Y_train) and predicted data based on the training data (Y_train_predicted). How would you judge the goodness of fit? \n",
    "\n",
    "- In order to the robustness of the linear regression model, also calculate the RMSE and coefficient of determination based on the test data (i.e. using Y_test and Y_test_predicted). How do they look compared to the error metrics from the training data? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [6]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a last step, we can now also plot the data and the resulting linear regression, to check for plausibility, outliers, etc. First, pick one of the two independent variables to visualize here (you can also make two figures, one for each X)\n",
    "\n",
    "- Make a scatter plot for the selected Y (blood sugar level) and X (either triglycerides level \"s5\", or body mass index \"bmi\") values from the entire dataset (including training and test data). \n",
    "\n",
    "- In order to plot the regression line, you first need to get the intercept and coefficients of the fitted linear regression. You can do so by adding the attributes `.intercept_`and `coef_` to the linear regression object. \n",
    "\n",
    "- Then, calculate the \"y\" values for the regression line by \"y = intercept + coefficients * x\". You can generate the corresponding x values by `numpy.linspace(min, max, num=n)`. As we did a multiple linear regression analysis, we have two coefficients (one foe s4 and one for s5). Make sure you pick the one for s5 for visualisation alongside the data for s5. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [7]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END\n",
    "\n",
    "### References \n",
    "\n",
    "https://towardsdatascience.com/introduction-to-linear-regression-in-python-c12a072bedf0\n",
    "\n",
    "\n",
    "https://towardsdatascience.com/linear-regression-on-boston-housing-dataset-f409b7e4a155"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GDA1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "348daff44e8d26393a409574f2e4514257a97c14ec71abb995e14a187e3537bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
