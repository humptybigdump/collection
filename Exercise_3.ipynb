{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Uncertainty Quantification***\n",
    "\n",
    "Exercise 03, \n",
    "June 10,2021\n",
    "\n",
    "\n",
    "Prof. Dr. M.Frank\n",
    "\n",
    "\n",
    "Dr. Jonas Kusch\n",
    "\n",
    "\n",
    "Pia Stammer\n",
    "\n",
    "\n",
    "Maqsood Rajput\n",
    "\n",
    "-----------------------------------------------------------------------------------------\n",
    "\n",
    "Note: To render Jupyter Notebook and to run code on Bw-cloud instance, please sign up at https://e5188803.ka.bw-cloud-instance.org/ \n",
    "\n",
    "-----------------------------------------------------------------------------------------\n",
    "\n",
    "#### **EXERCISE SHEET 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install chaospy\n",
    "import numpy as np\n",
    "import math\n",
    "import scipy.special\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401 unused import\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import chaospy.distributions.copulas.clayton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;   \n",
    "\n",
    "**EXERCISE 1)**\n",
    "\n",
    "Consider the ODE with uncertainties\n",
    "$$\n",
    "\\dot u(t) = -z_1 u(t),\\quad u(0)=z_2.\n",
    "$$ \n",
    "Derive expressions for the\n",
    "sensitivities of \n",
    "$$R(u) = \\int_0^T u(t)dt$$ \n",
    "with respect to $z_1$ and $z_2$ by\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;   (a) using the explicit solution,\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;   (b) using forward differentiation,\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;   (c) using adjoints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;   \n",
    "\n",
    "**EXERCISE 2)**\n",
    "\n",
    "Look at the code below. The Clayton copula can be\n",
    "stated as\n",
    "\n",
    "$$\n",
    "C(u_1 ,u_2 )= \\max ((u_1^{-\\theta} +u_2^{-\\theta} -1)^{-1/\\theta},0),\\quad  \\theta > 0\n",
    "$$\n",
    "\n",
    "Sklar's Theorem says that any joint distribution function $F(x_1,x_2)$\n",
    "with strictly increasing marginal distribution functions $F_1(x_1)$ and\n",
    "$F_2(x_2)$ may be written as\n",
    "\n",
    "$$\n",
    "F (x_1, x_2) = C(u_1, u_2) \\text{ where } u_1 = F_1(x_1), u_2 = F_2(x_2).\n",
    "$$\n",
    "\n",
    "Additionally, the copula may be combined with either of\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&u_1 = F_1(x_1), 1 - u_2 = F_2(x_2)\\quad &\\text{ orientation (1,2)}\\\\\n",
    "&1 - u_1 = F_1(x_1), u_2 = F_2(x_2)\\quad &\\text{ orientation (2,1)}\\\\\n",
    "&1 - u_1 = F_1(x_1), 1 - u_2 = F_2(x_2)\\quad &\\text{ orientation (2,2)}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "and the effect is to rotate the copula patterns compared to the original\n",
    "one.\n",
    "\n",
    "Let the random variables $X_1$ and $X_2$ be distributed as\n",
    "$\\mathcal{N}(\\mu=0.005, \\sigma^2 = 0.05^2)$. Construct a two-dimensional\n",
    "joint distribution by using the Clayton copula with different values of\n",
    "$\\theta$ and different orientations. Sample from the joint cdf and\n",
    "visualize by using the given code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "def FInv(U,mu,sigma):\n",
    "    return scipy.special.erfinv(2*U-1)*math.sqrt(2)*sigma+mu\n",
    "\n",
    "#choose theta value\n",
    "theta = 0.5          # Change this value and see how the distribution changes\n",
    "\n",
    "#plot corresponding copula C(u1,u2)\n",
    "u = np.linspace(1,0,10,endpoint=True)\n",
    "u1,u2 = np.meshgrid(u,u)\n",
    "grid = np.empty((2,u.size**2))\n",
    "grid[1,:]= u1.flatten()\n",
    "grid[0,:]= u2.flatten()\n",
    "\n",
    "\n",
    "#change orientation \n",
    "#\n",
    "# add code to change the orientation of the Copula to (2,1),(1,2) or (2,2)\n",
    "#\n",
    "\n",
    "\n",
    "dist = dist = chaospy.Iid(chaospy.Uniform(), 2)\n",
    "clayton_cop = chaospy.Clayton(dist,theta)\n",
    "y = clayton_cop.pdf(grid)\n",
    "\n",
    "y = np.reshape(y,(10,10))\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "ax = fig.gca(projection='3d')\n",
    "surf = ax.plot_surface(u1, u2, y, cmap=cm.viridis, linewidth=0, antialiased=False)\n",
    "\n",
    "#sample u1, u2 from C\n",
    "u = clayton_cop.sample(100)\n",
    "\n",
    "#plot histogram of u1,u2\n",
    "plt.figure()\n",
    "scatter_axes = plt.subplot2grid((3, 3), (1, 0), rowspan=2, colspan=2)\n",
    "plt.subplots_adjust(wspace=0.5,hspace=0.5)\n",
    "x_hist_axes = plt.subplot2grid((3, 3), (0, 0), colspan=2,\n",
    "                               sharex=scatter_axes)\n",
    "y_hist_axes = plt.subplot2grid((3, 3), (1, 2), rowspan=2,\n",
    "                               sharey=scatter_axes)\n",
    "\n",
    "scatter_axes.plot(u[0,:],u[1,:], '.')\n",
    "_ = x_hist_axes.hist(u[0,:],5,color = \"white\", ec=\"C0\")\n",
    "_ = y_hist_axes.hist(u[1,:],5, orientation='horizontal',color = \"white\", ec=\"C0\")\n",
    "\n",
    "#transform to Gaussian variables\n",
    "mu = 0.005;\n",
    "sigma = 0.05;\n",
    "x1 = FInv(u[0,:],mu,sigma);\n",
    "x2 = FInv(u[1,:],mu,sigma);\n",
    "\n",
    "#plot histogram of x1,x2\n",
    "plt.figure()\n",
    "scatter_axes = plt.subplot2grid((3, 3), (1, 0), rowspan=2, colspan=2) \n",
    "plt.subplots_adjust(wspace=0.5,hspace=0.5)\n",
    "x_hist_axes = plt.subplot2grid((3, 3), (0, 0), colspan=2,\n",
    "                               sharex=scatter_axes)\n",
    "y_hist_axes = plt.subplot2grid((3, 3), (1, 2), rowspan=2,\n",
    "                               sharey=scatter_axes)\n",
    "\n",
    "scatter_axes.plot(x1, x2, '.')\n",
    "_ = x_hist_axes.hist(x1,color = \"white\", ec=\"C0\")\n",
    "_ = y_hist_axes.hist(x2, orientation='horizontal',color = \"white\", ec=\"C0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;   \n",
    "\n",
    "**EXERCISE 3)**\n",
    "\n",
    "Prove the Nataf covariance formula \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{cov}(Z_i,Z_j) = \\int\\int (z_i-\\mu_i)(z_j-\\mu_j)\\rho_i(z_i)\\rho_j(z_j)\\frac{\\varphi_2(y_i(z_i),y_j(z_j))}{\\varphi_1(y_i(z_i))\\varphi_1(y_j(z_j))}\\,dz_i\\,dz_j,\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where $\\varphi_1$ is a standard normal pdf and $\\varphi_2$ is the\n",
    "bivariate normal pdf with covariance matrix \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "V = \\begin{pmatrix}\n",
    "1 & V_{ij} \\\\\n",
    "V_{ji} & 1\n",
    "\\end{pmatrix}.\\end{aligned}\n",
    "$$ \n",
    "\n",
    "**Hint:** Use\n",
    "$\\left(f^{-1}\\right)'(a) = \\frac{1}{f'(f^{-1}(a))}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;   \n",
    "\n",
    "**EXERCISE 4)**\n",
    "\n",
    "The KL expansion of the random process $Z_t$ is given by\n",
    "\n",
    "\\begin{equation*}\n",
    "Z_t(\\omega)=\\sum_{j=1}^{\\infty}\\sqrt{\\lambda_j}\\psi_j(t)Z_j(\\omega)\n",
    "\\end{equation*}\n",
    "\n",
    "where\n",
    "\n",
    "\\begin{equation*}\n",
    "Z_j(\\omega)=\\frac{1}{\\sqrt{\\lambda_j}}\\left(Z_t{(\\omega)},\\psi_j(t)\\right)=\\frac{1}{\\sqrt{\\lambda_j}}\\int_0^TZ_t(\\omega)\\psi_j(t)dt.\n",
    "\\end{equation*}\n",
    "\n",
    "Show that if E$[Z_t]=0$, then E$[Z_i]=0$, E$[Z_iZ_j]=\\delta_{ij}$. This means that the new variables $Z_i$ are uncorrelated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "&nbsp;\n",
    "\n",
    "### **Additional Exercises**\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "**EXERCISE 5)**\n",
    "\n",
    "We want to compute the expected value of $g(Z)=\\sqrt{Z} sin(2\\pi Z)$, where $Z$ is uniformly distributed in [0,1], with the help of Monte-Carlo. We use control variates to speed up the computation. \n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;   (a) Plot $g$ and the control variate $\\lambda$ by running the following block of code. Choose different values of $\\lambda$ and try to get \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define g and h\n",
    "\n",
    "def g(Z):\n",
    "  y=math.sqrt(Z)*math.sin(2*math.pi*Z)\n",
    "  return y\n",
    "\n",
    "def h(Z):\n",
    "  y=math.sin(2*math.pi*Z)\n",
    "  return y \n",
    "\n",
    "g=np.vectorize(g)\n",
    "h=np.vectorize(h)\n",
    "\n",
    "#Plot g and control variate h\n",
    "lambda_c = 10\n",
    "zGrid = np.linspace(start=0,stop=1,num=1000)\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(zGrid,g(zGrid),label='g')\n",
    "plt.plot(zGrid,lambda_c*h(zGrid),linestyle='--',linewidth=2,label='h')\n",
    "_=plt.legend(shadow=True, fancybox=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;   (b) Compute the expected value of $g$ by using Monte Carlo with and without control variate. How does the choice of $\\lambda$ affect the solution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=5000  #number of samples\n",
    "\n",
    "tmpMC = 0\n",
    "tmpCV = 0\n",
    "\n",
    "expectedMC = np.zeros((N,1))\n",
    "expectedCV = np.zeros((N,1))\n",
    "\n",
    "for i in range(N):\n",
    "  Z=np.random.uniform(0,1,(1,1))\n",
    "\n",
    "  #Your code: Save MC and CV expectation value approximation with i+1 samples in expectedMC(i) and expectedCV(i)\n",
    "  #...\n",
    "  #expectedMC[i], expectedCV[i], tmpMC, tmpCV = solution_b(tmpMC,tmpCV,Z,lambda_c,i+1) #(run code section below exercise c) & uncomment this line to see solution)\n",
    "\n",
    "print(\"Expected value is {0}\".format(expectedMC[N-1]))\n",
    "\n",
    "expectedExact = -0.11980826271647446\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.loglog(np.arange(1,N+1),abs(expectedMC-expectedExact),label='MC')\n",
    "plt.loglog(np.arange(1,N+1),abs(expectedCV-expectedExact),label='CV')\n",
    "plt.loglog(np.arange(1,N+1),1/np.sqrt(np.arange(1,N+1)),linestyle='--',linewidth=2,label='slope 1/2')\n",
    "_=plt.legend(shadow=True, fancybox=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;   (c) Look at the code below. What is implemented here? How is the value of $\\lambda$ picked?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimateCov (covOld,QgOld,N,Z):\n",
    "  y=(N-1)/N*covOld + 1/N* (g(Z)-QgOld)* (h(Z)-QgOld)\n",
    "  return y\n",
    "\n",
    "#Compute integral with CV and optimal lambda\n",
    "\n",
    "expectedCVL = np.zeros((N,1))\n",
    "tmpCVL = 0\n",
    "covOld = 0.5           #estimated covariance\n",
    "expectedOld = -0.1     #estimated mean\n",
    "varH = 0.5             #exact variance of function h\n",
    "\n",
    "for i in range(N):\n",
    "  Z = np.random.uniform(0,1,(1,1))\n",
    "  cov = estimateCov(covOld, expectedOld, i+1 , Z) #update covariance\n",
    "  lambdaOpt = cov/varH\n",
    "  tmpCVL = tmpCVL + (g(Z) - lambdaOpt*h(Z))\n",
    "  expectedCVL[i] = 1/(i+1)*tmpCVL\n",
    "  covOld = cov\n",
    "  expectedOld = expectedCVL[i]\n",
    "\n",
    "print(\"Expected value is {0}\".format(expectedCVL[N-1]))\n",
    "\n",
    "expectedExact = -0.11980826271647446\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.loglog(np.arange(1,N+1),abs(expectedMC-expectedExact),label='MC')\n",
    "plt.loglog(np.arange(1,N+1),abs(expectedCV-expectedExact),linestyle='--',linewidth=2,label='CV')\n",
    "plt.loglog(np.arange(1,N+1),abs(expectedCVL-expectedExact),linestyle='-.',linewidth=2,label='CVOpt')\n",
    "plt.loglog(np.arange(1,N+1),1/np.sqrt(np.arange(1,N+1)),label='slope 1/2')\n",
    "_=plt.legend(shadow=True, fancybox=True)\n",
    "\n",
    "print(\"Lambda is {0}\".format(lambdaOpt))\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(zGrid,g(zGrid),label='g')\n",
    "plt.plot(zGrid,np.squeeze(lambdaOpt*h(zGrid)),label='$\\lambda_{Opt} \\; h$')\n",
    "plt.plot(zGrid,lambda_c*h(zGrid),linestyle='--',linewidth=2,label='$\\lambda \\; h$')\n",
    "_=plt.legend(shadow=True, fancybox=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solution to fill in field in (b)\n",
    "\n",
    "def solution_b (tmpMC,tmpCV,Z,lambda_c,i):\n",
    "  tmpMC = tmpMC + g(Z);\n",
    "  tmpCV = tmpCV + (g(Z)-lambda_c*h(Z));\n",
    "  expectedMC_i = (1.0/i)*tmpMC;\n",
    "  expectedCV_i = (1.0/i)*tmpCV;\n",
    "\n",
    "  return expectedMC_i, expectedCV_i, tmpMC, tmpCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "&nbsp;\n",
    "\n",
    "**EXERCISE 6)**\n",
    "\n",
    "Assume a (discretized) system can be written in the form\n",
    "$$ E(u,z) = 0,$$\n",
    "\n",
    "where\n",
    "- the solution $u$ $\\in \\mathbb{R}^K$\n",
    "- the parameters $z$ $\\in \\mathbb{R}^N$\n",
    "\n",
    "and the constraint E: $\\mathbb{R}^K \\times \\mathbb{R}^N \\rightarrow \\mathbb{R}^K$ admits a unique solution for $u$ depending on $z$. Assume further that we have quantities of interest\n",
    "$$R(u) = R(u(z))$$\n",
    "with $R: \\mathbb{R}^K \\rightarrow \\mathbb{R}^I$. We are interested in the sensitivity of $R$ with respect to $z$, i.e.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;   (a) Derive formulas for the sensitivities by forward-differentiation.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;   (b) Derive formulas for the sensitivities by adjoint calculus.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;   (c) Discuss the dimensions of all objects. When is forward differentiation advantageous, when adjoints?\n",
    "\n",
    "&nbsp;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;   \n",
    "\n",
    "**EXERCISE 7)**\n",
    "\n",
    "A bivariate copula is the joint distribution function\n",
    "\n",
    "$$\n",
    "C(u_1,u_2)=P(U_1 \\leq u_1,U_2 \\leq u_2),\\quad 0<u_1 \\leq 1, 0< u_2 \\leq 1.\n",
    "$$\n",
    "\n",
    "Any function $C(u_1,u_2)$ that is to play this role must be increasing\n",
    "in $u_1$ and $u_2$ and satisfy $C(u_1,0) = 0$, $C(0,u_2) = 0$ and\n",
    "$C(u_1,1) = u_1$, $C(1,u_2) = u_2$.\n",
    "\n",
    "Introduce the copulas\n",
    "\n",
    "$$\n",
    "C_{\\min}(u_1, u_2) = {\\max}(u_1 + u_2  -1, 0) \\text{ and } C_{\\max}(u_1, u_2) = {\\min}(u_1, u_2),\n",
    "$$\n",
    "\n",
    "where $0 < u_1, u_2 < 1$.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;   (a) Argue that $C_{\\min}(u_1, u_2)$ is the copula when $U_2 = 1 - U_1$.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;   (b) Also argue that $C_{\\max}(u_1,u_2)$ corresponds to $U_2 = U_1$.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;   (c) Verify that any copula $C(u_1,u_2)$ satisfies\n",
    "\n",
    "$$C_{\\min}(u_1, u_2) \\leq C(u_1, u_2) \\leq C_{\\max}(u_1, u_2), 0 \\leq u_1, u_2 \\leq 1.$$\n",
    "    \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;   This is known as the Frechet-Hoeffding inequality and shows that\n",
    "$C_{\\min}(u_1, u_2)$ is a minimum and $C_{\\max}(u_1, u_2)$ a maximum copula.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;   \n",
    "\n",
    "*Hint:* For the upper bound note that\n",
    "- $C(u_1,u_2) \\leq P(U_i \\leq u_i)$ and for the lower one introduce\n",
    "- $H(u_1)=C(u_1,u_2)-(u_1+u_2-1)$ for which $H(1)=0$ and\n",
    "- $\\frac{dH(u_1)}{du_1} = P(U_2 \\leq u_2 | u_1)-1\\leq 0$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
