{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A85Lvq_ayeFF"
   },
   "source": [
    "# Generative Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wm5jvfLwyeFG"
   },
   "source": [
    "### How to run this notebook\n",
    "\n",
    "Easy way:\n",
    "\n",
    "* Go to https://colab.research.google.com\n",
    "* Add this ipynb to colab\n",
    "* Go to Edit > Notebook settings, select GPU as Hardware accelerator\n",
    "* Run the notebook\n",
    "\n",
    "Harder way:\n",
    "* Install python 3\n",
    "* python3 -m venv my_venv\n",
    "* Activate venv \n",
    "\n",
    ">On unix `$ source my_ven/bin/activate`\n",
    "\n",
    ">On windows `$ my_venv\\Scripts\\activate`\n",
    "\n",
    "* Upgrade pip\n",
    "`pip install --upgrade pip`\n",
    "\n",
    "* Install tensorflow\n",
    "`pip install tensorflow`\n",
    "\n",
    "* Install other needed stuff\n",
    "`pip install jupyter scipy matplotlib pydot`\n",
    "\n",
    "* run this notebook with `jupyter notebook`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kCkeuZm7yeFI"
   },
   "source": [
    "# 1. Kullback-Leibler Divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZgtXrrEIyeFJ"
   },
   "source": [
    "Kullback-Leibler Divergence is a measure of how one probability distribution is different from a second, reference probability distribution. It is defined as the expectation of the logarithmic difference between the probabilities P and  Q, where the expectation is taken using the probabilities P:\n",
    "$$D_{KL}[P||Q]  = \\mathbb{E}_{x \\sim P}\\left[\\log P(x) - \\log Q(x)\\right] $$\n",
    "For discrete probability distributions P and Q defined on the same probability space, KL-divergence is defined as a sum:\n",
    "$$D_{KL}[P||Q]  = \\sum_{i} P(i) log\\frac{P(i)}{Q(i)}$$\n",
    "For distributions P and Q of a continuous random variable, the KL-divergence as an integral:\n",
    "$$D_{KL}[P||Q]  =  \\int_{} P(x) log\\frac{P(x)}{Q(x)}dx$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OwJp9QwByeFL"
   },
   "source": [
    "Define function to compute KL-divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_O78DDC4yeFM"
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def KL(p, q):\n",
    "    epsilon = 0.00001\n",
    "    p_eps = p+epsilon\n",
    "    q_eps = q+epsilon\n",
    "\n",
    "    return np.sum(p_eps*np.log(p_eps/q_eps))\n",
    "\n",
    "    #return np.sum(np.where(a != 0, a * np.log(a / b), 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H7gJrViKyeFV"
   },
   "source": [
    "The following example demonstrates KL-divergence for two normal distributions. We first plot the distributions and then the values under the integral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t35TWiKcyeFW"
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-5, 5, 500)\n",
    "distr_p = stats.norm.pdf(x, 0, 1)\n",
    "distr_q = stats.norm.pdf(x, 1, 1)\n",
    "plt.plot(x, distr_p, label=\"p(x)\")\n",
    "plt.plot(x, distr_q, label=\"q(x)\")\n",
    "plt.grid()\n",
    "plt.legend(fontsize='x-large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cbVrnJA2yeFc"
   },
   "outputs": [],
   "source": [
    "plt.plot(x, distr_p*np.log(distr_p/distr_q), label=\"p(x)*log(p(x)/q(x))\")\n",
    "plt.plot(x, distr_q*np.log(distr_q/distr_p), label=\"q(x)*log(q(x)/p(x))\")\n",
    "plt.grid()\n",
    "plt.legend(fontsize='x-large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9fz7fEXtyeFh"
   },
   "source": [
    "KL-divergence is not symmetric (and hence not a metric!). See the KL-divergence values $D_{KL}[p||q]$ and $D_{KL}[q||p]$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0miescaXyeFi"
   },
   "outputs": [],
   "source": [
    "print(\"D_KL(p||q) is\", KL(distr_p, distr_q))\n",
    "print(\"D_KL(q||p) is\",KL(distr_q, distr_p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "toN0PGrFyeFm"
   },
   "source": [
    "#### Jensen–Shannon divergence\n",
    "Now we define Jensen–Shannon divergence, which also measures the similarity between two probability distributions. JS-divergence is a symmetrized and smoothed version of the KL-divergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MUQcMpVAyeFn"
   },
   "outputs": [],
   "source": [
    "def JSD(p, q):\n",
    "    m = 0.5 * (p + q)\n",
    "    return 0.5 * (KL(p, m) + KL(q, m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hPWNBu7TyeFs"
   },
   "source": [
    "We now plot JS-divergence for the same two distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TXY4ZfCFyeFt"
   },
   "outputs": [],
   "source": [
    "m = 0.5 * (distr_p + distr_q)\n",
    "plt.plot(x, m, label=\"m\")\n",
    "plt.plot(x, 0.5 * (distr_p * np.log(distr_p/m) + distr_q * np.log(distr_q/m)), label=\"p(x)*log(p(x)/q(x))\")\n",
    "plt.plot(x, 0.5 * (distr_q * np.log(distr_q/m) + distr_p * np.log(distr_p/m)), label=\"q(x)*log(q(x)/p(x))\")\n",
    "plt.grid()\n",
    "plt.legend(fontsize='x-large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XpHytfLPyeFw"
   },
   "source": [
    "Now we compute JS-divergence values  $D_{JS}[p||q]$ and $D_{JS}[q||p]$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z5HtAbxiyeFw"
   },
   "outputs": [],
   "source": [
    "print(\"D_JS(p||q) is\", JSD(distr_p, distr_q))\n",
    "print(\"D_JS(q||p) is\",JSD(distr_q, distr_p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4EQrClVZyeF1"
   },
   "source": [
    "# 2. Variational Autoencoder (VAE)\n",
    "\n",
    "The first type of generative models is a Variational Autoencoder (co-discovered [here](https://arxiv.org/abs/1312.6114) and [here](https://arxiv.org/abs/1401.4082)). Variational autoencoders combine neural networks with variational inference to train deep generative models. These models tend to be far more stable and easier to train but currently don't produce samples that are as pretty as GANs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q58HO0AByeF1"
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9VmNDAc7yeF2"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda, LeakyReLU, Reshape, Flatten, Conv2D, MaxPooling2D, \\\n",
    "    Conv2DTranspose, BatchNormalization\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras import backend as K\n",
    "#from tensorflow.keras import objectives\n",
    "from tensorflow.keras.utils import model_to_dot, plot_model\n",
    "from scipy.stats import norm\n",
    "from IPython.display import SVG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gSMdFmeYyeF5"
   },
   "source": [
    "### LeakyReLU\n",
    "Instead of the function being zero when x < 0, a leaky ReLU will instead have a small negative slope α (e.g. $α=0.01$):\n",
    "$$ReLU(x) = max(0,x)$$\n",
    "\n",
    "$$LeakyReLU(x) = max(αx,x)$$\n",
    "\n",
    "![caption](relu.png)\n",
    "\n",
    "LeakyReLUs keep ReLU units from dying and are often used in GAN methods (as are maxout units, however those increase model size and therefore are not used in this notebook).\n",
    "\n",
    "We will use the already implemented LeakyReLU from keras in the following neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f_YMK-JuyeF-"
   },
   "source": [
    "### VAE Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z5PseIX_yeF_"
   },
   "source": [
    "First define some model variables and load MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9MNpKQ0VyeF_"
   },
   "outputs": [],
   "source": [
    "# network parameters\n",
    "batch_size = 100\n",
    "n_epoch = 10\n",
    "n_hidden = 256\n",
    "latent_dim = 2 # we will train a VAE with 2d latent space\n",
    "\n",
    "# get mnist dataset\n",
    "from tensorflow.keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "plt.imshow(np.concatenate((x_train[:6]), axis=1))\n",
    "plt.title('some examples of MNIST ')\n",
    "plt.show()\n",
    "\n",
    "# Cast to float values between (0,1)\n",
    "x_train, x_test = x_train.astype('float32')/255., x_test.astype('float32')/255.\n",
    "x_train, x_test = x_train.reshape(x_train.shape[0], -1), x_test.reshape(x_test.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xXX9eyF2yeGH"
   },
   "source": [
    "### Encoder\n",
    "Define an encoder: 2 FC layers with LeakyReLUs as activation functions and two output layers: one for the mean and one for the log variance. Note that we output the log variance instead of the standard deviation because this is not only more convenient to work with, but also helps with numerical stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(784,), name='MNIST_image')\n",
    "x = Dense(n_hidden, name='hidden_enc_1')(encoder_inputs)\n",
    "x = LeakyReLU(alpha=0.01)(x)\n",
    "x = Dense(n_hidden, name='hidden_enc_2')(x)\n",
    "x = LeakyReLU(alpha=0.01)(x)\n",
    "\n",
    "# mu and log_var both use the activated output of hidden_enc_2\n",
    "mu = Dense(latent_dim, name='mu')(x)\n",
    "log_var = Dense(latent_dim, name='log_var')(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EwmOYApXyeGO"
   },
   "source": [
    "### Reparameterization Trick\n",
    "\n",
    "Introduce a new parameter $\\epsilon \\sim N(0,1)$ to allow backprop: $z=\\mu + \\sigma * \\epsilon$.  \n",
    "\n",
    "The outcoder outputs the log variance, but we need the standard deviation. To recover it, we simply implement the appropriate transformation and encapsulate it in a new keras layer.\n",
    "\n",
    "Then we add this layer to the encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(tf.keras.layers.Layer):\n",
    "    \"\"\"Create a new keras layer for the reparameterization trick \"\"\"\n",
    "    def call(self, inputs):\n",
    "        # gets mu and log_var as input\n",
    "        mu, log_var = inputs\n",
    "        batch = tf.shape(mu)[0]\n",
    "        dim = tf.shape(mu)[1]\n",
    "        # creates a random value with shape [batchsize, 2]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        # Reparameterization trick\n",
    "        z = mu + tf.exp(0.5 * log_var) * epsilon\n",
    "        return z\n",
    "\n",
    "# connect mu and log_var to the sampling layer\"\n",
    "z = Sampling()([mu, log_var])\n",
    "\n",
    "# create a keras model of the encoder\n",
    "encoder = tf.keras.Model(encoder_inputs, [mu, log_var, z], name=\"encoder\")\n",
    "\n",
    "# visualization of the encoder with sampling\n",
    "SVG(model_to_dot(encoder, show_shapes=False, dpi=65)\n",
    "    .create(prog='dot', format='svg'))\n",
    "# encoder.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MWr0UpqqyeGS"
   },
   "source": [
    "### Decoder\n",
    "\n",
    "The decoder takes the latent dimension values and tries to predict an image\n",
    "We use 2 FC layers with LeakyReLU.\n",
    "Then we use one FC layer with sigmoid activation for the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_inputs = Input(shape=(latent_dim,), name='latent_dimension')\n",
    "x = Dense(n_hidden//2, name='hidden_dec_1')(latent_inputs)\n",
    "x = LeakyReLU(alpha=0.01)(x)\n",
    "\n",
    "x = Dense(n_hidden, name='hidden_dec_2')(x)\n",
    "x = LeakyReLU(alpha=0.01)(x)\n",
    "\n",
    "# predict a 28*28 pixel image, with values in (0,1)\n",
    "decoder_outputs=Dense(28*28, activation='sigmoid',name='input_reconstructed')(x)\n",
    "\n",
    "# create the decoder model\n",
    "decoder = tf.keras.Model(latent_inputs,decoder_outputs, name='decoder')\n",
    "\n",
    "# visualize the decoder\n",
    "SVG(model_to_dot(decoder, show_shapes=False, dpi=65)\n",
    "    .create(prog='dot', format='svg'))\n",
    "\n",
    "#decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating VAE\n",
    "\n",
    "A new keras model is created.\n",
    "\n",
    "We override the train_step function that is automatically called on training.\n",
    "There we connect the Encoder and the Decoder, calculate the VAE-loss and update the weights. \n",
    "\n",
    "VAE Loss consists of the reconstruction loss (is the input image similar to the output image) and\n",
    "the KL-divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o00qrPRWyeGD"
   },
   "outputs": [],
   "source": [
    "class VAE(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    The Variational Auto Encoder\n",
    "    \"\"\"\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize our encoder.\n",
    "        Takes an Encoder and a Decoder\n",
    "        \"\"\"\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    \n",
    "    def call(self,x):\n",
    "        \"\"\"\n",
    "        Not really necessary, but used for VAE initialization\n",
    "        \"\"\"\n",
    "        mu, log_var, z = self.encoder(x)\n",
    "        reconstruction = self.decoder(z)\n",
    "        return reconstruction\n",
    "    \n",
    "    \n",
    "    def train_step(self, x):\n",
    "        \"\"\"train step is automatically called on vae.fit.\n",
    "           It calculated the VAE-loss and updates the weights\n",
    "        \"\"\"\n",
    "        x = x[0] # we don't feed the MNIST label so we only care about the input image\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            # connect encoder with decoder\n",
    "            mu, log_var, z = self.encoder(x)\n",
    "            reconstruction = self.decoder(z)\n",
    "            \n",
    "            # create reconstruction loss with binary crossentropy\n",
    "            bc = tf.keras.losses.BinaryCrossentropy()\n",
    "            bc_loss = bc(x, reconstruction)\n",
    "            reconstruction_loss = tf.reduce_mean(bc_loss) * (28*28)\n",
    "            \n",
    "            #use Kullblack Leibler Divergence as second loss\n",
    "            kl_loss = tf.square(mu) + tf.exp(log_var) - log_var - 1\n",
    "            kl_loss = 0.5 * tf.reduce_mean(kl_loss)\n",
    "            \n",
    "            #combine both losses\n",
    "            vae_loss = reconstruction_loss + kl_loss\n",
    "        \n",
    "        #get gradients with regards to the vae_loss\n",
    "        grads = tape.gradient(vae_loss, self.trainable_weights)\n",
    "        \n",
    "        #update weights of the decoder and encoder using an optimizer\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "                                    \n",
    "        return {\"loss\": vae_loss,\"rec_loss\": reconstruction_loss, \"kl_loss\": kl_loss}                                \n",
    "                                       \n",
    "vae = VAE(encoder, decoder)\n",
    "vae.build((batch_size,784))\n",
    "# get some info about our variational auto encoder\n",
    "vae.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use an Adam optimizer here\n",
    "vae.compile(optimizer=tf.keras.optimizers.Adam())\n",
    "# train our model\n",
    "vae.fit(x_train, epochs=n_epoch, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q4Qdv_ipyeGg"
   },
   "source": [
    "### VAE Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RmlxF_y9yeGj"
   },
   "source": [
    "Next, we show how the encoder (the recognition network) encodes the test inputs (collapsing the Gaussian distribution in latent space to its mean). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_latent,_,_ = encoder.predict(x_test)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(mu_latent[:, 0], mu_latent[:, 1], c=y_test, cmap='jet')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HwmB2ckAyeGo"
   },
   "source": [
    "### Display 2D manifold of the MNIST digits\n",
    "\n",
    "Finally we display latent space as a 2D manifold. For this, we sample values from a unit normal distribution, feed them to our decoder and plot reconstrunctions at the positions in the latent space for which they have been generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display a 2D manifold of the digits\n",
    "n = 15 # figure with 15x15 digits\n",
    "digit_size = 28\n",
    "figure = np.zeros((digit_size * n, digit_size * n))\n",
    "\n",
    "grid_x = norm.ppf(np.linspace(0.01, 0.99, n)) \n",
    "grid_y = norm.ppf(np.linspace(0.01, 0.99, n))\n",
    "\n",
    "for i, yi in enumerate(grid_x):\n",
    "    for j, xi in enumerate(grid_y):\n",
    "        x_decoded = decoder.predict(np.array([[xi, yi]]))\n",
    "        x_decoded_reshaped = x_decoded[0].reshape(digit_size, digit_size)\n",
    "        figure[i * digit_size: (i + 1) * digit_size,\n",
    "               j * digit_size: (j + 1) * digit_size] = x_decoded_reshaped\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(figure, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RZqRq-beyeGw"
   },
   "source": [
    "# 3. Generative Adversarial Networks (GANs)\n",
    "\n",
    "A GAN is built up of two different neural networks:\n",
    "* a **discriminator** classifies images as being real (belonging to the training set) or fake (not present in the training set)\n",
    "* a **generator** takes random noise as input and transforms it using a neural network to produce images. The goal of the generator is to fool the discriminator into thinking the images it produced are real.\n",
    "\n",
    "This is an iterative process of the generator ($G$) trying to fool the discriminator ($D$), and the discriminator trying to correctly classify real vs. fake as a minimax game:\n",
    "$$\\underset{G}{\\text{minimize}}\\; \\underset{D}{\\text{maximize}}\\; \\mathbb{E}_{x \\sim p_\\text{data}}\\left[\\log D(x)\\right] + \\mathbb{E}_{z \\sim p(z)}\\left[\\log \\left(1-D(G(z))\\right)\\right]$$\n",
    "where $x \\sim p_\\text{data}$ are samples from the input data, $z \\sim p(z)$ are the random noise samples, $G(z)$ are the generated images using the neural network generator $G$, and $D$ is the output of the discriminator, specifying the probability of an input being real. \n",
    "\n",
    "We will use the **non-saturating heuristic** from the lecture: instead of maximizing the probability that the discriminator makes the correct choice, we will instead maximize the probability of the **discriminator making the incorrect choice**. \n",
    "\n",
    "We will alternate the following updates:\n",
    "1. Update the generator ($G$) to maximize the probability of the discriminator making the incorrect choice on generated data:\n",
    "$$\\underset{G}{\\text{maximize}}\\;  \\mathbb{E}_{z \\sim p(z)}\\left[\\log D(G(z))\\right]$$\n",
    "2. Update the discriminator ($D$), to maximize the probability of the discriminator making the correct choice on real and generated data:\n",
    "$$\\underset{D}{\\text{maximize}}\\; \\mathbb{E}_{x \\sim p_\\text{data}}\\left[\\log D(x)\\right] + \\mathbb{E}_{z \\sim p(z)}\\left[\\log \\left(1-D(G(z))\\right)\\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SEd87OGmyeGw"
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N7RkPFhsyeGw"
   },
   "outputs": [],
   "source": [
    "# number of images for each batch\n",
    "batch_size = 128\n",
    "# our noise dimension\n",
    "noise_dim = 96\n",
    "\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# A bunch of utility functions\n",
    "\n",
    "def deprocess_img(x):\n",
    "    \"\"\"convert values from (-1,1) to (0,1)\"\"\"\n",
    "    return (x + 1.0) / 2.0\n",
    "\n",
    "def show_images(images):\n",
    "    \"\"\"visualize generated images\"\"\"\n",
    "    images = np.reshape(images, [images.shape[0], -1])  # images reshape to (batch_size, D)\n",
    "    images = deprocess_img(images)\n",
    "    sqrtn = int(np.ceil(np.sqrt(images.shape[0])))\n",
    "    sqrtimg = int(np.ceil(np.sqrt(images.shape[1])))\n",
    "\n",
    "    fig = plt.figure(figsize=(sqrtn, sqrtn))\n",
    "    gs = gridspec.GridSpec(sqrtn, sqrtn)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, img in enumerate(images):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(img.reshape([sqrtimg,sqrtimg]))\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vS-zd9XYyeGz"
   },
   "source": [
    "### MNIST Dataset\n",
    "\n",
    "For GAN we normalize the images to (-1,1) and use a tensorflow dataset to increase I/O speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LdqRS58NyeG0"
   },
   "outputs": [],
   "source": [
    "train_images = x_train * 2 - 1 # Normalize the images to [-1, 1]\n",
    "print(train_images.shape)\n",
    "buffer_size = 60000\n",
    "# Batch and shuffle the data\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(buffer_size).batch(batch_size, drop_remainder=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mchiuU2myeG3"
   },
   "source": [
    "### Random Noise\n",
    "Generate a TensorFlow `Tensor` containing uniform noise from -1 to 1 with shape `[batch_size, dim]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I55wMqK3yeG4"
   },
   "outputs": [],
   "source": [
    "def sample_noise(batch_size, dim):\n",
    "    \"\"\"Generate random uniform noise from -1 to 1.\n",
    "    \n",
    "    Inputs:\n",
    "    - batch_size: integer giving the batch size of noise to generate\n",
    "    - dim: integer giving the dimension of the the noise to generate\n",
    "    \n",
    "    Returns:\n",
    "    TensorFlow Tensor containing uniform noise in [-1, 1] with shape [batch_size, dim]\n",
    "    \"\"\"\n",
    "    random_noise = tf.random.uniform(shape=(batch_size, dim), minval=-1, maxval=1, dtype=tf.float32)\n",
    "    return random_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hd1cx8KIyeG6"
   },
   "source": [
    "### Discriminator\n",
    "\n",
    "Architecture:\n",
    " * FC layer from size 784 to 256\n",
    " * LeakyReLU with alpha 0.01\n",
    " * FC layer from 256 to 256\n",
    " * LeakyReLU with alpha 0.01\n",
    " * FC layer from 256 to 1\n",
    " \n",
    "The output of the discriminator has shape `[batch_size, 1]`, and it contains the prediction, if the input image is real or generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "25gKQzgGyeG6"
   },
   "outputs": [],
   "source": [
    "def create_discriminator():\n",
    "    \"\"\"\n",
    "    Create and return a discriminator\n",
    "    \"\"\"\n",
    "    discriminator = tf.keras.Sequential(\n",
    "        [\n",
    "            Dense(units=256),\n",
    "            LeakyReLU(alpha=0.01),\n",
    "            Dense(units=256),\n",
    "            LeakyReLU(alpha=0.01),\n",
    "            Dense(units=1)\n",
    "        ]\n",
    "    )\n",
    "    return discriminator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L2DRY3hyyeG9"
   },
   "source": [
    "### Generator\n",
    "\n",
    "Architecture:\n",
    " * FC from tf.shape(z)[1] (the number of noise dimensions) to 1024\n",
    " * ReLU\n",
    " * FC layer from 1024 to 1024 \n",
    " * ReLU\n",
    " * FC layer from 1024 to 784\n",
    " * TanH (To restrict the output to be [-1,1])\n",
    " \n",
    "The generator takes a random noise value and predicts a 28*28 pixel image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J6V91tMGyeG9"
   },
   "outputs": [],
   "source": [
    "def create_generator():\n",
    "    \"\"\"\n",
    "    Create and return a generator\n",
    "    \"\"\"\n",
    "    generator = tf.keras.Sequential(\n",
    "        [\n",
    "            Dense(units=1024, activation='relu'),\n",
    "            Dense(units=1024, activation='relu'),\n",
    "            Dense(units=28*28, activation='tanh'),\n",
    "        ]\n",
    "    )\n",
    "    return generator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JMQYsx1Ke1B8"
   },
   "source": [
    "Initialize our generator and discriminator.\n",
    "\n",
    "Show initial generated images and their corresponding predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9AkBbiNX8ab1"
   },
   "outputs": [],
   "source": [
    "# create random noise for generator input\n",
    "noise = sample_noise(batch_size, noise_dim)\n",
    "generator = create_generator()\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "\n",
    "print(\"Initial generated images\")\n",
    "fig = show_images(generated_image[:16])\n",
    "plt.show()\n",
    "\n",
    "# discriminate the generated images\n",
    "discriminator = create_discriminator()\n",
    "decision = discriminator(generated_image)\n",
    "print('Certainty that the first row are real images \\n', tf.nn.sigmoid(decision[:5]).numpy())\n",
    "print(\"\")\n",
    "print(\"Neither our Generator nor Discriminator produce yet anything meaningful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hNnGCNBJyeHA"
   },
   "source": [
    "# GAN Loss\n",
    "\n",
    "Compute the generator and discriminator loss. The generator loss is:\n",
    "$$\\ell_G  =  -\\mathbb{E}_{z \\sim p(z)}\\left[\\log D(G(z))\\right]$$\n",
    "and the discriminator loss is:\n",
    "$$ \\ell_D = -\\mathbb{E}_{x \\sim p_\\text{data}}\\left[\\log D(x)\\right] - \\mathbb{E}_{z \\sim p(z)}\\left[\\log \\left(1-D(G(z))\\right)\\right]$$\n",
    "Note that these are negated from the equations presented earlier as we will be *minimizing* these losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ihPo-DJIyeHA"
   },
   "outputs": [],
   "source": [
    "def disc_loss(logits_real, logits_fake):\n",
    "    \"\"\"Calculate the discriminator loss\n",
    "    Inputs:\n",
    "        - logits_real: the output of the discriminator for real images\n",
    "        - logits_fake: the output of the discriminator for generated images.\n",
    "    Returns:\n",
    "        - The loss scalar of the discriminator\"\"\"\n",
    "        \n",
    "\n",
    "    # labels are '1' for every real image and '0' for every generated image \n",
    "    true_labels = tf.ones_like(logits_real)\n",
    "    \n",
    "    # DISCRIMINATOR loss has 2 parts: how well it classifies real images and how well it\n",
    "    # classifies fake images\n",
    "    real_image_loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=logits_real, labels=true_labels)\n",
    "    fake_image_loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=logits_fake, labels=1-true_labels)\n",
    "    \n",
    "    # Combine and average losses over the batch\n",
    "    discriminator_loss = tf.reduce_mean(real_image_loss + fake_image_loss)\n",
    "    \n",
    "    return discriminator_loss\n",
    "\n",
    "\n",
    "def gen_loss(logits_fake):\n",
    "    \"\"\"Calculate the generator loss\n",
    "    Input:\n",
    "        - logits_fake: the output of the discriminator for generated images\n",
    "    Returns:\n",
    "        - The loss scalar of the generator\"\"\"\n",
    "    \n",
    "    # True labels (1) for fake images\n",
    "    true_labels = tf.ones_like(logits_fake)\n",
    "\n",
    "    # The generator tries to increase the certainty of the discriminator for all its fake images\n",
    "    generator_loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=logits_fake, labels=true_labels)\n",
    "    \n",
    "    # Average generator loss over the batch\n",
    "    generator_loss = tf.reduce_mean(generator_loss)\n",
    "    \n",
    "    return generator_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uwBI8NuZyeHC"
   },
   "source": [
    "### Optimizing our loss\n",
    "Make an `AdamOptimizer` with a 1e-3 learning rate, beta1=0.5 to mininize G_loss and D_loss separately. The trick of decreasing beta was shown to be effective in helping GANs converge in the [Improved Techniques for Training GANs](https://arxiv.org/abs/1606.03498) paper. In fact, with our current hyperparameters, if you set beta1 to the Tensorflow default of 0.9, there's a good chance your discriminator loss will go to zero and the generator will fail to learn entirely. In fact, this is a common failure mode in GANs; if your D(x) learns to be too fast (e.g. loss goes near zero), your G(z) is never able to learn. Often D(x) is trained with SGD with Momentum or RMSProp instead of Adam, but here we'll use Adam for both D(x) and G(z). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M4cpWkniyeHD"
   },
   "outputs": [],
   "source": [
    "def get_optimizers(learning_rate=1e-3, beta1=0.5):\n",
    "    \"\"\"Create optimizers for GAN training.\n",
    "    \n",
    "    Inputs:\n",
    "    - learning_rate: learning rate to use for both solvers\n",
    "    - beta1: beta1 parameter for both solvers (first moment decay)\n",
    "    \n",
    "    Returns:\n",
    "    - disc_optimizer: instance of tf.train.AdamOptimizer with correct learning_rate and beta1\n",
    "    - gen_optimizer: instance of tf.train.AdamOptimizer with correct learning_rate and beta1\n",
    "    \"\"\"\n",
    "    \n",
    "    disc_optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=beta1)\n",
    "    gen_optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=beta1)\n",
    "    \n",
    "    return disc_optimizer, gen_optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DetkgmCKyeHH"
   },
   "source": [
    "### Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BIRzuu7qyeHH"
   },
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Tensorflow 2.x uses eager execution by default.\n",
    "@tf.function creates graphs and can increase performance drastically\n",
    "The speedup here with @tf.function per epoch is between 100 and 400%\n",
    "\"\"\"\n",
    "\n",
    "@tf.function\n",
    "def train_step(inputs, generator, discriminator):\n",
    "    \"\"\"Update the weights once of a given discriminator and a given generator\n",
    "    Inputs:\n",
    "        - inputs: the MNIST images for the discriminator\n",
    "        - generator: a created generator\n",
    "        - discriminator: a created discriminator\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create new noise for every training step\n",
    "    noise = sample_noise(batch_size, noise_dim)\n",
    "    \n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_imgs = generator(noise, training=True)\n",
    "        # The certainty that MNIST images are real\n",
    "        logits_real = discriminator(inputs, training=True)\n",
    "        # The certainty that generated images are real\n",
    "        logits_fake = discriminator(generated_imgs, training=True)\n",
    "        \n",
    "        # get our losses for discriminator and generator\n",
    "        g_loss = gen_loss(logits_fake)\n",
    "        d_loss = disc_loss(logits_real, logits_fake)\n",
    "\n",
    "    # calculate the gradients of the generator and the discriminator with regards to the loss\n",
    "    gradients_gen = gen_tape.gradient(g_loss, generator.trainable_variables)\n",
    "    gradients_disc = disc_tape.gradient(d_loss, discriminator.trainable_variables)\n",
    "\n",
    "    # Use our Adam optimizers to update weights with the corresponding gradients\n",
    "    disc_optimizer.apply_gradients(zip(gradients_disc, discriminator.trainable_variables))\n",
    "    gen_optimizer.apply_gradients(zip(gradients_gen, generator.trainable_variables))\n",
    "\n",
    "    \n",
    "# Get our adam optimizers\n",
    "disc_optimizer, gen_optimizer = get_optimizers()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k8FmupnmyeHJ"
   },
   "source": [
    "#### Train your GAN! This should take about 10 minutes on a CPU, or less than minute on GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WIWMkTzoKC5h"
   },
   "outputs": [],
   "source": [
    "def run_gan(generator, discriminator,train_step,show_every=250, print_every=100, batch_size=batch_size, num_epoch=10):\n",
    "    \"\"\"\n",
    "    Train a Gan for a certain amount of epochs\n",
    "    Inputs:\n",
    "        - generator: A generator for a gan\n",
    "        - discriminator: A discriminator for a gan\n",
    "        - train_step: The function that gets executed on every image batch\n",
    "        - show_every: How many steps between visualization of generated images\n",
    "        - print_every: The generator and discriminator loss of the current batch\n",
    "        - batch_size: Batchsize of the dataset\n",
    "        - num_epoch: How often do we iterate through the dataset\"\"\"\n",
    "    \n",
    "    # For the visualization we always the same noise to see improvements\n",
    "    vis_noise = sample_noise(batch_size, noise_dim)\n",
    "    print(\"For the visualization we always take the same noise to see improvements\")\n",
    "    print(\"Make sure the discriminator loss isn't '0' \")\n",
    "    for epoch in range(num_epoch):\n",
    "        epoch_start = time.time()\n",
    "        for it, image_batch in enumerate(train_dataset):\n",
    "            # train a batch of images\n",
    "            train_step(image_batch, generator, discriminator)              \n",
    "            \n",
    "            \n",
    "            # every so often, show a generated picture\n",
    "            if it % show_every == 0:\n",
    "                samples = generator(vis_noise, training=False)\n",
    "                fig = show_images(samples[:16])\n",
    "                plt.show()\n",
    "                print()\n",
    "            \n",
    "            # Make sure that the discriminator loss isn't '0'\n",
    "            if it % print_every == 0:\n",
    "                # calculate loss for current batch with eager execution\n",
    "                generated_imgs = generator(vis_noise, training=False)\n",
    "                logits_real = discriminator(image_batch, training=False)        \n",
    "                logits_fake = discriminator(generated_imgs, training=False)\n",
    "                g_loss = tf.reduce_mean(gen_loss(logits_fake)).numpy()\n",
    "                d_loss = tf.reduce_mean(disc_loss(logits_real, logits_fake)).numpy()\n",
    "                print('Iter: {}, D: {:.4}, G:{:.4}'.format(it,d_loss,g_loss))\n",
    "\n",
    "        print(\"Epoch {} finished in {} seconds\".format(epoch+1, time.time()-epoch_start))\n",
    "\n",
    "\n",
    "    print('Final images')\n",
    "    samples = generator(vis_noise, training=False)\n",
    "    fig = show_images(samples[:16])\n",
    "    plt.show()\n",
    "\n",
    "# Lets train our GAN\n",
    "run_gan(generator, discriminator, train_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HrBz7ziPyeHO"
   },
   "source": [
    "### Deep Convolutional GANs (DCGANs)\n",
    "\n",
    "Vanilla GAN (above) allows no real spatial reasoning. It is unable to reason about things like \"sharp edges\" in general because it lacks any convolutional layers. Thus, in this section, we will implement some of the ideas from [DCGAN](https://arxiv.org/abs/1511.06434), where we use convolutional networks as our discriminators and generators.\n",
    "\n",
    "#### Discriminator\n",
    "\n",
    "Architecture:\n",
    "* 32 Filters, 5x5, Stride 1, Leaky ReLU(alpha=0.01)\n",
    "* Max Pool 2x2, Stride 2\n",
    "* 64 Filters, 5x5, Stride 1, Leaky ReLU(alpha=0.01)\n",
    "* Max Pool 2x2, Stride 2\n",
    "* Flatten\n",
    "* FC size 4 x 4 x 64, Leaky ReLU(alpha=0.01)\n",
    "* FC size 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "17ul1-2GyeHP"
   },
   "outputs": [],
   "source": [
    "def create_dc_discriminator():\n",
    "    \"\"\"\n",
    "    Build a discriminator with convolutional layers.\n",
    "    Returns:\n",
    "    Keras model which predicts in shape [batch_size, 1].\n",
    "    This prediction contains the evaluation if an image is fake or real\n",
    "    \"\"\"\n",
    "    discriminator = tf.keras.Sequential(\n",
    "        [\n",
    "            Reshape((28,28,1)),\n",
    "            Conv2D(filters=32, kernel_size=5, strides=1),\n",
    "            LeakyReLU(alpha=0.01),\n",
    "            MaxPooling2D(pool_size=2, strides=2),\n",
    "            Conv2D(filters=64, kernel_size=5, strides=1),\n",
    "            LeakyReLU(alpha=0.01),\n",
    "            MaxPooling2D(pool_size=2, strides=2),\n",
    "            Flatten(),\n",
    "            Dense(units=1024),\n",
    "            LeakyReLU(alpha=0.01),\n",
    "            Dense(units=1)\n",
    "        ]\n",
    "    )\n",
    "    return discriminator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "12GzgOtpyeHR"
   },
   "source": [
    "#### Generator\n",
    "Architecture:\n",
    "* FC of size 1024, ReLU\n",
    "* BatchNorm\n",
    "* FC of size 7 x 7 x 128, ReLU\n",
    "* BatchNorm\n",
    "* Resize into Image Tensor\n",
    "* 64 conv2d^T (transpose) filters of 4x4, stride 2, ReLU\n",
    "* BatchNorm\n",
    "* 1 conv2d^T (transpose) filter of 4x4, stride 2, TanH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q_BgxWY3yeHR",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def create_dc_generator():\n",
    "    \"\"\"\n",
    "    Create and return a generator that takes noise and generates images with size 28*28\n",
    "    \"\"\"\n",
    "    generator = tf.keras.Sequential(\n",
    "        [\n",
    "            Dense(units=1024,activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            Dense(units=7*7*128, activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            Reshape((7,7,128)),\n",
    "            Conv2DTranspose(filters=64, kernel_size=4, strides=2, activation='relu', padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Conv2DTranspose(filters=1, kernel_size=4, strides=2, activation='tanh', padding='same'),\n",
    "            Flatten()\n",
    "        ]\n",
    "    )\n",
    "    return generator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sv-LFEA7d0FA"
   },
   "source": [
    "Initialize the generator/discriminator and show initial images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ap-aM61ZTWBd"
   },
   "outputs": [],
   "source": [
    "dc_generator = create_dc_generator()\n",
    "initial_img = dc_generator(noise)\n",
    "\n",
    "print(\"initial generated images\")\n",
    "fig = show_images(initial_img[:16])\n",
    "plt.show()\n",
    "\n",
    "dc_discriminator = create_dc_discriminator()\n",
    "decision = dc_discriminator(initial_img)\n",
    "print('Certainty that the first row are real images \\n', tf.nn.sigmoid(decision[:5]).numpy())\n",
    "print(\"\")\n",
    "print(\"Neither our Generator nor Discriminator produce anything meaningful yet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zUNiWWrtyeHZ"
   },
   "source": [
    "### Let's train our newly created Deep Convolutional GAN\n",
    "We have to create a new train_step function because we are running in graph mode \n",
    "\n",
    "Lets give the run_gan function the new generator, discriminator and the new train_step\n",
    "Also reduced the amount of epochs for faster results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "re8sQaL5yeHa"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step_dc(inputs, generator, discriminator):\n",
    "    \n",
    "    noise = sample_noise(batch_size, noise_dim)\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_imgs = generator(noise, training=True)\n",
    "        \n",
    "        logits_real = discriminator(inputs, training=True)\n",
    "        logits_fake = discriminator(generated_imgs, training=True)\n",
    "        \n",
    "        g_loss = gen_loss(logits_fake)\n",
    "        d_loss = disc_loss(logits_real, logits_fake)\n",
    "\n",
    "    # calculate the gradients with regards to the loss\n",
    "    gradients_gen = gen_tape.gradient(g_loss, generator.trainable_variables)\n",
    "    gradients_disc = disc_tape.gradient(d_loss, discriminator.trainable_variables)\n",
    "\n",
    "    # Use Adam optimizer to update weights with the gradients\n",
    "    disc_optimizer.apply_gradients(zip(gradients_disc, discriminator.trainable_variables))\n",
    "    gen_optimizer.apply_gradients(zip(gradients_gen, generator.trainable_variables))\n",
    "\n",
    "#increase epoch size for better results\n",
    "run_gan(dc_generator, dc_discriminator, train_step_dc, num_epoch=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Kopie von tf2_Exercise_06_Generative_Models.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
