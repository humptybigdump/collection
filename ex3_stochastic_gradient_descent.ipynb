{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent for a Maximum a Posteriori Estimate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains a simple implementation of the stochastic gradient descent (SGD) method. SGD is a very popular optimization method for the training of Neural Networks (see for instance the *Adam* optimizer). Compared to standard gradient descent methods, it has several potential benefits, particularly for large parameter vectors and data sets:\n",
    "- We do not need to store the entire gradient of the cost functional\n",
    "- Data can be incorporated in a streaming fashion\n",
    "- Randomness improves convergence for non-convex problems"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the SGD method to find the maximum a posteriori (MAP) estimate for a simplistic Bayesian inverse problem. To this end, we define a scalar unknown $u\\in\\mathbb{R}$ and a vector of data samples $\\mathbf{y}=(y_1,y_2,\\ldots,y_N)^T\\in\\mathbb{R}^N$. We assign a Gaussian prior and component-wise Gaussian additive noise to the problem,\n",
    "$$\n",
    "\\begin{gather*}\n",
    "    \\rho(u) \\propto \\mathrm{exp}\\Bigl( -\\frac{c_{prior}}{2} (u-u_{prior})^2  \\Bigr), \\\\\n",
    "    l(\\mathbf{y}|u) \\propto \\mathrm{exp}\\Bigl( -\\frac{c_{noise}}{2} \\sum_{i=1}^N (y_i-u)^2 \\Bigr),\n",
    "\\end{gather*}\n",
    "$$\n",
    "where $c_{prior}$ and $c_{noise}$ denote the prior and noise precision, respectively. We already know that the posterior for this problem will be Gaussian as well.\n",
    "\n",
    "**Exercise:** Show that the posterior mean and the MAP coincide at\n",
    "$$\n",
    "    \\hat{u}_{post} = \\frac{c_{prior}u_{prior} + c_{noise}\\sum_i y_i}{c_{prior} + N c_{noise}}.\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we turn to the problem of finding the optimizer with the SGD algorithm. The cost functional is simply given as the negative log-posterior,\n",
    "$$\n",
    "    J(u) = \\frac{c_{prior}}{2} (u-u_{prior})^2 + \\frac{c_{noise}}{2} \\sum_{i=1}^N (y_i-u)^2.\n",
    "$$\n",
    "Moving on, we define a discrete random variable $z=(z_1, z_2,\\ldots,z_N)^T\\in\\mathbb{R}^N$. We further describe its pdf as a sum of dirac masses,\n",
    "$$\n",
    "    \\zeta(z) = \\frac{1}{N}\\sum_{i=1}^N\\delta(z-e^i),\n",
    "$$\n",
    "where $e_i$ denotes the $i$-th unit vector.\n",
    "\n",
    "**Exercise:** Find a representation for $J(u)$ as\n",
    "$$\n",
    "    J(u) = \\int_{\\mathbb{R}^N} F(u,z)\\zeta(z)dz.\n",
    "$$\n",
    "\n",
    "*Tip: The prior clearly does not depend on $\\zeta$, but it can be \"equally distributed\" among the addends in the sum of the likelihood term.*\n",
    "\n",
    "*Note: This will lead to a so-called data subsampling technique.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now recall the standard SGD algorithm. For an initial state $u^{0}$, a number of steps $L$ and a sequence of learning rates $\\{\\alpha_l\\}_{l=0}^{L-1}$, we can compute iterates as\n",
    "$$\n",
    "    u^{(l+1)} = u^{(l)} - \\alpha_l D_u F(u^{(l)}, z^{(l)}),\\quad z^{(l)} \\sim \\zeta\\ \\mathrm{i.i.d.}\n",
    "$$\n",
    "In the context of data subsampling, drawing samples from $\\zeta$ corresponds to choosing a random index $i$ and computing the partial gradient from the $i$-th addend of $J(u)$ (with data sample $y_i$). We might therefore reformulate the SGD iteration as\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    i^{(l)} &\\sim \\mathrm{uni}(\\{ 1,2,\\ldots,N \\})\\ \\mathrm{i.i.d.}, \\\\\n",
    "    u^{(l+1)} &= u^{(l)} - \\alpha_l D_u \\tilde{F}(u^{(l)}, i^{(l)}).\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Finally, we can turn to the implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary libraries\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Interactive plotting and style\n",
    "%matplotlib widget\n",
    "plt.close('all')\n",
    "plt.style.use('bmh')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Consider the Bayesian inverse problem with the parameters given below. Implement the SGD algorithm to compute the MAP estimate. Compare the iterates to the exact solution. You can use the code cells below as guidance for your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the simulation\n",
    "TRUE_PARAMETER = 1.\n",
    "NUM_SAMPLES = 10\n",
    "NOISE_PRECISION = 10\n",
    "PRIOR_MEAN = 0.\n",
    "PRIOR_PRECISION = 1\n",
    "\n",
    "# Generate data\n",
    "data = norm.rvs(TRUE_PARAMETER, np.power(NOISE_PRECISION, -0.5), NUM_SAMPLES, random_state=42)\n",
    "\n",
    "# Analytical solution of the MAP estimate\n",
    "map_exact = # -> Enter solution\n",
    "\n",
    "# Function to evaluate the partial gradient for given state, data and index permutation\n",
    "def evaluate_gradient(state, data, index):\n",
    "    # -> Implement function for the partial gradient\n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, choosing a proper learning rate is non-trivial. A too-low learning rate leads to slow convergence, while high rates might lead to strong noise and oscillations or even divergence. For the plain SGD method, we employ a constant learning rate, since the optimization problem is very nice (1D and convex)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the optimization algorithm\n",
    "NUM_ITERATIONS = 1000\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "# Initialize RNG and solution vectors\n",
    "rng = np.random.default_rng(seed=123456)\n",
    "iterates = [PRIOR_MEAN] # Use prior as initial guess\n",
    "\n",
    "# Perform optimization\n",
    "for i in range(NUM_ITERATIONS):\n",
    "    # -> Implement SGD iteration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Perform the optimization for different hyperparameters `NUM_ITERATIONS` and `LEARNING_RATE`. What do you observe? Can you think of modifications to increase the robustness and/or convergence rate of the algorithm? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Visualization\n",
    "iterations = np.arange(0, NUM_ITERATIONS+1, 1)\n",
    "exact_values = map_exact * np.ones((NUM_ITERATIONS+1,))\n",
    "\n",
    "plt.close('all')\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Stochastic Gradient Descent')\n",
    "ax.plot(iterations, iterates)\n",
    "ax.plot(iterations, exact_values)\n",
    "ax.set_xlim(0, NUM_ITERATIONS+1)\n",
    "ax.set_ylim(iterations[0], map_exact + 0.2)\n",
    "ax.set_xlabel(r'$l$')\n",
    "ax.set_ylabel(r'$u^{(l)}$')\n",
    "ax.text(NUM_ITERATIONS/20, 1.02*map_exact, 'True Value')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
