{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e42763e",
   "metadata": {},
   "source": [
    "# Stochastic Simulation\n",
    "\n",
    "*Winter Semester 2023/24*\n",
    "\n",
    "24.11.2023\n",
    "\n",
    "Prof. Sebastian Krumscheid<br>\n",
    "Asstistant: Stjepan Salatovic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5187ec",
   "metadata": {},
   "source": [
    "<h3 align=\"center\">\n",
    "Exercise sheet 04\n",
    "</h3>\n",
    "\n",
    "---\n",
    "\n",
    "<h1 align=\"center\">\n",
    "Stochastic process generation\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f636d6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "\n",
    "from ipywidgets import interact\n",
    "from scipy.fft import fft, ifft\n",
    "from scipy.stats import uniform, norm, expon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc556f51-f693-4b9d-89dd-dfdac32825dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('axes', labelsize=14)     # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=12)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=12)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=14)    # legend fontsize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6ec4b1",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "Consider a fractional Brownian motion (fBM) $\\{B^H(t), t\\in[0,1]\\}$,  which is a centred Gaussian process with $B^H(0)=0$ and covariance function \n",
    "\n",
    "$$\n",
    "\\mathrm{Cov}(t,s) = \\frac{1}{2}(|t|^{2H} + |s|^{2H} - |t-s|^{2H}),\n",
    "$$\n",
    "\n",
    "where $H\\in (0,1)$ is the so-called _Hurst index_. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09db19c",
   "metadata": {},
   "source": [
    "1. To sample such a process let us consider, for a fixed $h>0$, the increment process $\\delta B_h(t) = B^H(t+h)-B^H(t)$. Show that $\\delta B_h(t)$ is a centered stationary Gaussian process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31254d18",
   "metadata": {},
   "source": [
    "We begin by obtaining the covariance matrix for the incremental process $\\delta B^H$. For any $t,s,h \\geq 0$ we have\n",
    "\n",
    "\\begin{align*}\n",
    "    \\mathrm{Cov}_{\\delta B^H}(t,s) &:= \\mathrm{Cov}[B^H(t+h)-B^H(t),B^H(s+h)-B^H(s)]\\\\\n",
    "    &=\\mathbb{E}\\left[\\left(B^H(t+h)-B^H(t)\\right)\\left(B^H(s+h)-B^H(s)\\right)\\right]\\\\\n",
    "    &=\\mathbb{E}\\left[ B^H(t+h)B^H(s+h)\\right]-\\mathbb{E}\\left[B^H(t+h)B^H(s)\\right]-\\mathbb{E}\\left[B^H(t)B^H(s+h)\\right]+\\mathbb{E}\\left[B^H(s)B^H(t)\t\t\\right]\\\\\n",
    "    &=\\mathrm{Cov}_{\\delta B^H}(t+h,s+h)-\\mathrm{Cov}_{\\delta B^H}(t+h,s)-\\mathrm{Cov}_{\\delta B^H}(t,s+h)+\\mathrm{Cov}_{\\delta B^H}(t,s)\\\\\n",
    "    &=\\frac{1}{2}\\left(\t|t+h|^{2H}\t+|s+h|^{2H}-|t-s|^{2H}-|t+h|^{2H}-|s|^{2H}+|t+h-s|^{2H}-|t|^{2H}\\right.\\\\ &-\\left.|s+h|^{2H}+|s+h-t|^{2H}+|t|^{2H}+|s|^{2H}-|t-s|^{2H}\t\\right)\\\\\n",
    "    &=\\frac{1}{2}\\left(|t+h-s|^{2H}+|s+h-t|^{2H}-2|t-s|^{2H}\\right),\n",
    "    \\end{align*}\n",
    "\n",
    "which is a stationary Gaussian process. Notice, moreover, that since  $\\mathbb{E}[B^H(t)]=0, \\ \\forall t\\geq 0$, then $\\mathbb{E}[\\delta B^H]=\\mathbb{E}[B^H(t+h)]-\\mathbb{E}[B^H(t)]=0$, and as such, $\\delta B^H$ is a centered stationary Gaussian process. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a705f04",
   "metadata": {},
   "source": [
    "2. If one is able to sample exactly the process $\\delta B_h(t)$ on a\n",
    "\tuniform grid $t_j=jh$, then one can construct an exact sample of the\n",
    "\tfractional Brownian motion on the same grid points as $B^H(t_k) =\n",
    "\t\\sum_{j=0}^{k-1}\\delta B_h(t_j)$. Sample a fractional Brownian motion using FFT and circular embedding. Implement your experiment for different values of $H<1/2$ and $H>1/2$.\n",
    "\n",
    "    **Hint:** Have a look at Scipy's FFT module [`scipy.fft`](https://docs.scipy.org/doc/scipy/tutorial/fft.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c97bc3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cov(t, s, h: float, H: float):\n",
    "    \"\"\"\n",
    "    Covariance function of the fractional Gaussian noise with Hurst index `H`.\n",
    "    \"\"\"\n",
    "    H2 = 2 * H\n",
    "    return (np.abs(t + h - s) ** H2 + np.abs(s + h - t) ** H2 - 2 * np.abs(t - s) ** H2) / 2    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2c57921-5dd8-4485-8335-21c7160f7683",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fractional_Brownian_motion(n: int, H: float) -> np.array:\n",
    "    \"\"\"\n",
    "    Samples one realization of a fractional Brownian motion on a\n",
    "    uniform grid in [0, 1] with `n` points and Hurst index `H`.\n",
    "    \"\"\"\n",
    "    h = 1 / n\n",
    "    covs = cov(np.zeros(n + 1), np.arange(n + 1) * h, h, H)\n",
    "    alpha = np.hstack((covs, covs[1:-1][::-1]))\n",
    "    lambda_ = fft(alpha)\n",
    "    y = np.random.randn(2 * n) + np.random.randn(2 * n) * 1j\n",
    "    x_tilde = ifft(np.sqrt(2 * n) * np.sqrt(lambda_) * y)\n",
    "    x1 = np.real(x_tilde[1:n])\n",
    "    fBm = np.hstack((np.zeros(1), np.cumsum(x1)))\n",
    "    return fBm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a04dc7fd-8ced-4a2d-bcf9-534ba1cdd901",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fBm(n, H):\n",
    "    \"\"\"Interaction helper.\"\"\"\n",
    "    np.random.seed(999)\n",
    "\n",
    "    t = np.linspace(0, 1, n)\n",
    "    fBm = fractional_Brownian_motion(n, H)\n",
    "\n",
    "    plt.plot(t, fBm)\n",
    "    plt.xlabel(r\"$t$\")\n",
    "    plt.ylabel(r\"$B^H(t)$\")\n",
    "    plt.title(rf\"Fractional Brownian motion with Hurst index $H = {H:.1f}$\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58be2a64-0e3e-44d3-8cc3-efdf3174e8ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "250aca27cff140d494c4205cfd13eda3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=505, description='n', max=1000, min=10), FloatSlider(value=0.5, descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interact(plot_fBm, n=(10, 1000), H=(0.1, 0.9));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9696751f-2eca-43ea-aac9-46deb5ccd21b",
   "metadata": {},
   "source": [
    "## Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eead44b-26a9-49c2-a01b-196727d5a9fa",
   "metadata": {},
   "source": [
    "1. Generate a random walk $\\{X_n\\in\\mathbb{Z},\\,n\\in\\mathbb{N}_0,\\,X_0=0\\}$\n",
    "  with transition probabilities\n",
    "  \\begin{equation*}\n",
    "    \\mathbb{P}(X_{n+1} = j \\vert X_n = j-1) = \\mathbb{P}(X_{n+1} = j \\vert X_n = j+1) = a\\;,\\quad\n",
    "    \\mathbb{P}(X_{n+1} = j \\vert X_n = j) = 1-2a\\;,\n",
    "  \\end{equation*}\n",
    "  for some $0<a\\le 1/2$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a554bcbe-4f12-4b23-bef4-a7321d518b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_walk(n: int, a: float=.5) -> np.array:\n",
    "    \"\"\"\n",
    "    Generates a random walk with `n` steps and transition probabilities specified by `a`.\n",
    "    \"\"\"\n",
    "    u = np.random.rand(n)\n",
    "    incr = 1 * (u <= a) - (u > a) * (u <= 2 * a)\n",
    "    x = np.hstack((np.zeros(1), incr)).cumsum()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17e531c3-29a9-4053-872e-20fa50586119",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_random_walk(n: int, a: float=.5):\n",
    "    \"\"\"Interaction helper.\"\"\"\n",
    "    np.random.seed(999)\n",
    "\n",
    "    x = random_walk(n, a=a)\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.plot(x)\n",
    "    plt.xlabel(r\"$n$\", size=14)\n",
    "    plt.ylabel(r\"$X_n$\", size=14)\n",
    "    plt.title(rf\"Random walk for $a = {a}$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04d56e72-a7ae-4ef4-bae3-10f9cc622b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2446b8af8cc743a582e59e138f9e457d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5005, description='n', max=10000, min=10), FloatSlider(value=0.5, descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interact(plot_random_walk, n=(10, 10000), a=(0, 0.5));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a35d56-1ed6-4edc-912e-d8560ba96039",
   "metadata": {},
   "source": [
    "2. Consider the rescaled process $Y_{t_i} := \\sqrt{\\Delta t/(2a)}X_i$\n",
    "  for $i=0,\\dots, n$ with $t_i = i\\Delta t$. Compare this process with\n",
    "  the process $W_{t_i}$, $i=0,\\dots, n$, where $W_t$ denotes a Wiener\n",
    "  process with $W_0 = 0$. That is, show that both processes \"look\n",
    "  similar\" in the limit as $\\Delta t\\to 0$ by plotting multiple\n",
    "  realizations of both processes for $n = \\lceil 1/\\Delta t \\rceil$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a519600-2e92-4e27-9325-37322035ccdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_random_walk(x: np.array, a: float=.5) -> np.array:\n",
    "    \"\"\"\n",
    "    Rescales the random walk `x` onto [0, 1] using transition probabilities specified by `a`.\n",
    "    \"\"\"\n",
    "    dt = 1 / len(x)\n",
    "    y = np.sqrt(dt / 2 / a) * x\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf270ccc-0505-4e9e-bdbc-29bbfc244bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wiener_process(n: int) -> np.array:\n",
    "    \"\"\"Generates a Wiener process wih `n` points.\"\"\"\n",
    "    dt = 1 / n\n",
    "    w = np.zeros(n + 1)\n",
    "    w[1:] = np.sqrt(dt) * np.random.randn(n).cumsum()\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba771b8d-46b4-49f4-883b-2c78c99d20c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_rescaled_rw_and_wp(n: int, a: float=.5):\n",
    "    \"\"\"Interaction helper.\"\"\"\n",
    "    t = np.linspace(0, 1, n + 1)\n",
    "\n",
    "    x = random_walk(n, a)\n",
    "    y = rescale_random_walk(x, a=a)\n",
    "    w = wiener_process(n)\n",
    "    \n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.plot(t, y, label=r\"Rescaled Random walk $Y_t$\")\n",
    "    plt.plot(t, w, label=r\"Wiener process $W_t$\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(r\"$t$\")\n",
    "    plt.title(rf\"Rescaled random walk compared to a Wiener process\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6783f55e-a981-46dc-b630-9087e2a84a07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e45820651d843198ab68ec2dc5f7293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5005, description='n', max=10000, min=10), FloatSlider(value=0.5, descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interact(compare_rescaled_rw_and_wp, n=(10, 10000), a=(0, 0.5));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979b3243-0ae4-4c57-a45a-2c170066d1f4",
   "metadata": {},
   "source": [
    "3. **(Optional):** More theoretical analysis of the observed phenomenon:\n",
    "\n",
    "    1. Consider the spatial mesh $x_m = m\\Delta x = m \\sqrt{\\Delta t/(2a)}$ for\n",
    "    $m \\in \\mathbb{Z}$ and the following notation for the rescaled\n",
    "    process' probability mass function at time $t_i$:\n",
    "    \n",
    "    $$\n",
    "      \\bar u(t_i,x_m) := \\mathbb{P}(Y_{t_i} = x_m|Y_{0} = 0), \\quad m \\in \\mathbb{Z}, i =0,1,\\ldots\n",
    "    $$\n",
    "    \n",
    "    Use the discrete Chapman-Kolmogorov formula\n",
    "    \n",
    "    $$\n",
    "       \\tag{1}\n",
    "      \\mathbb{P}(Y_{t_{i+1}} = x_m|Y_{0} = 0) = \\sum_{k} \\mathbb{P}(Y_{t_{i+1}} = x_m|Y_{t_i} = x_k)\\mathbb{P}(Y_{t_{i}} = x_k|Y_{0} = 0)\n",
    "    $$\n",
    "    \n",
    "    to derive a difference equation for $\\bar u(t_{i+1},x_m)$ in terms of\n",
    "    $\\bar u(t_{i},\\cdot)$.\n",
    "\n",
    "   2. Show that the difference equation obtained in $(1)$ corresponds to a finite difference approximation of the one dimensional heat equation\n",
    "   \n",
    "    $$\n",
    "    u_t(t,x) = \\frac{u_{xx}(t,x)}{2}, \\quad x \\in \\mathbb{R}, t > 0,\n",
    "    $$\n",
    "       on a uniform grid $x_i = i \\Delta x$ and $t_j = j \\Delta t$ with $\\Delta t = 2 a x^2$, using a second order centered finite difference stencil in space and a first order forward Euler scheme in time.\n",
    "\n",
    "   3. For the standard Wiener process with $\\mathbb{P}(W_0 =0)=1$,\n",
    "    we denote the probability density function at time $t>0$ by\n",
    "    $$\n",
    "      u(t,x) := \\frac{e^{-x^2/(2t)}}{\\sqrt{2\\pi t}}, \\qquad x \\in \\mathbb{R}.\n",
    "    $$\n",
    "    For all $t> 0$ and $x \\in \\mathbb{R}$, show that the density satisfies the same heat equation introduced in point B."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ad2d25-5d72-46f4-87eb-df128bddcd7f",
   "metadata": {},
   "source": [
    "A. We have that,\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\bar{u}(t_{i+1}, x_m) &= \\mathbb{P}(Y_{t_{i+1}} = x_m | Y_0 = 0)\\\\\n",
    "&= \\sum_{k \\in \\mathbb{Z}} \\mathbb{P}(Y_{t_{i+1}} = x_m | Y_{t_i} = x_k) \\mathbb{P}(Y_{t_{i}} = x_k | Y_0 = 0)\\\\\n",
    "&= \\sum_{k \\in \\mathbb{Z}} \\mathbb{P}(Y_{t_{i+1}} = x_m | Y_{t_i} = x_k) \\bar{u}(t_i,x_k)\\\\\n",
    "&= (1-2a) \\bar{u}(t_i,x_m) + a \\bar{u}(t_i,x_{m-1}) + a \\bar{u}(t_i,x_{m+1}) \\tag{2}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "B. Using the Taylor series for the solution of the heat equation, we have that\n",
    "$$\n",
    "\\begin{align*}\n",
    "u(t_{i}, x_{m-1}) &= u(t_{i}, x_m) - \\Delta x u_x(t_{i}, x_m) + \\frac{\\Delta x^2}{2} u_{xx}(t_{i}, x_m) + \\mathcal{O}(\\Delta x^4),\\\\\n",
    "u(t_{i}, x_{m+1}) &= u(t_{i}, x_m) + \\Delta x u_x(t_{i}, x_m) + \\frac{\\Delta x^2}{2} u_{xx}(t_{i}, x_m) + \\mathcal{O}(\\Delta x^4),\\\\\n",
    "u(t_{i+1},x_m) &= u(t_{i},x_m) + \\Delta t u_t(t_i,x_m) + \\mathcal{O}(\\Delta t^2).\n",
    "\\end{align*}\n",
    "$$\n",
    "With the choice $\\Delta x=\\sqrt{\\Delta t/2a}$, this leads to\n",
    "$$\n",
    "\\begin{align*}\n",
    "u(t_{i+1},x_m ) &= u(t_i,x_m) + \\frac{\\Delta t}{2} u_{xx}(t_i,x_m) + \\mathcal{O}(\\Delta t^2)\\\\\n",
    "&= u(t_i,x_m) + \\frac{\\Delta t}{2} \\frac{u(t_i,x_{m-1})+u(t_i,x_{m+1})-2u(t_i,x_{m})}{\\Delta x^2}+ \\mathcal{O}(\\Delta t^2 + \\Delta x^4)\\\\\n",
    "&= (1-2a)u(t_i,x_m) +a u(t_i,x_{m-1}) + u(t_i,x_{m+1})+ \\mathcal{O}(\\Delta t^2),\n",
    "\\end{align*}\n",
    "$$\n",
    "which corresponds to Eq. (2), up to error terms that vanish as $\\Delta t\\to 0$. \n",
    "\n",
    "C. This can be seen by simply substituting the density into the standard heat equation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7072cf54-b8cc-4810-8ad4-c83fc7356a34",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "**Note:** Refer to Section **4.3** of the lecture notes.\n",
    "\n",
    "Consider the chemical reactions between three species $S_1$, $S_2$,\n",
    "$S_3$, which are determined by the following four reaction channels:\n",
    "\\begin{equation*}\n",
    "  \\begin{aligned}\n",
    "    S_1 &\\overset{c_1}{\\to} \\emptyset\\;,\\\\\n",
    "    S_1 + S_1  &\\overset{c_2}{\\to} S_2\\;,\\\\\n",
    "    S_2 &\\overset{c_3}{\\to} S_1 + S_1\\;,\\\\\n",
    "    S_2 &\\overset{c_4}{\\to} S_3\\;.\n",
    "  \\end{aligned}\n",
    "\\end{equation*}\n",
    "To simulate this system, consider the process\n",
    "$\\boldsymbol{N}_t = (N_t^1,N_t^2,N_t^3)\\in\\mathbb{N}_0^3$, where\n",
    "$N_t^i$ denotes the number of molecules of species $S_i$ at time\n",
    "$t\\ge 0$. In fact, this process is a time-continuous Markov chain with\n",
    "transition probabilities given by\n",
    "\\begin{equation*}\n",
    "  \\begin{aligned}\n",
    "    \\mathbb{P}\\bigl(\\boldsymbol{N}_{t+h} = \\boldsymbol{N}_{t,1} = (N^1-1,N^2,N^3)\\bigl\\vert\\bigr. \\boldsymbol{N}_{t} &= (N^1,N^2,N^3)\\bigr) = a_1(\\boldsymbol{N}_{t})h + o(h)\\;,\\\\\n",
    "    \\mathbb{P}\\bigl(\\boldsymbol{N}_{t+h}= \\boldsymbol{N}_{t,2} = (N^1-2,N^2+1,N^3)\\bigl\\vert\\bigr. \\boldsymbol{N}_{t} &= (N^1,N^2,N^3)\\bigr) = a_2(\\boldsymbol{N}_{t})h + o(h)\\;,\\\\\n",
    "    \\mathbb{P}\\bigl(\\boldsymbol{N}_{t+h} = \\boldsymbol{N}_{t,3}= (N^1+2,N^2-1,N^3)\\bigl\\vert\\bigr. \\boldsymbol{N}_{t} &= (N^1,N^2,N^3)\\bigr) = a_3(\\boldsymbol{N}_{t})h + o(h)\\;,\\\\\n",
    "    \\mathbb{P}\\bigl(\\boldsymbol{N}_{t+h} = \\boldsymbol{N}_{t,4} =(N^1,N^2-1,N^3+1)\\bigl\\vert\\bigr. \\boldsymbol{N}_{t} &= (N^1,N^2,N^3)\\bigr) =  a_4(\\boldsymbol{N}_{t})h + o(h)\\;,\\\\\n",
    "    \\mathbb{P}\\bigl(\\boldsymbol{N}_{t+h} = \\boldsymbol{N}_{t,5}= (N^1,N^2,N^3)\\bigl\\vert\\bigr. \\boldsymbol{N}_{t}  &= (N^1,N^2,N^3)\\bigr) = 1 - h\\sum_{j=1}^4a_j(\\boldsymbol{N}_{t})+ o(h)\\;,\\\\\n",
    "  \\end{aligned}\n",
    "\\end{equation*}\n",
    "for $h$ sufficiently small, where $\\boldsymbol{N}_{t,k}, k \\in \\{1,...,5\\}$ indexes the possible transitions. \n",
    "Here, the so-called propensity functions are\n",
    "\\begin{equation*}\n",
    "  a_1(\\boldsymbol{N}) = c_1 N^1\\;,\\quad a_2(\\boldsymbol{N}) = c_2 \\frac{N^1(N^1-1)}{2}\\;,\\quad a_3(\\boldsymbol{N}) = c_3 N^2\\;,\\quad \\quad a_4(\\boldsymbol{N}) = c_4N^2\\;,\n",
    "\\end{equation*}\n",
    "with $\\boldsymbol{N} = (N^1,N^2,N^3)$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce7a2ab-4b0b-4fd4-b7a3-eb1f22ced96e",
   "metadata": {},
   "source": [
    "1. Try to construct the transition matrix corresponding to the above transition\n",
    "  probabilities and note the challenges. Is it possible to simulate the chemical reaction without the explicit $Q$ matrix?\n",
    "\n",
    "    **Hint:** Think back to how you simulated the process in Exercise 2.1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8e0c18-54c0-41ae-bc1c-7b15bc9ef739",
   "metadata": {},
   "source": [
    "Let $\\bigl\\{\\boldsymbol{N}_t\\in \\mathbb{N}_0^3\\colon t\\in[0,T]\\bigr\\}$\n",
    "be the Markov jump process that describes the number of each species\n",
    "present in the chemical reaction system. That is, unlike the processes\n",
    "covered during the lecture, we have to deal with both a vector-valued\n",
    "process and the fact that the state space may be unbounded. Regardless\n",
    "of these differences, the $Q$-matrix could be constructed as usual,\n",
    "namely by\n",
    "$Q = \\bigl(q(\\boldsymbol{n},\\boldsymbol{m}),\\,\n",
    "\\boldsymbol{n},\\boldsymbol{m}\\in \\mathbb{N}_0^3\\bigr)$, where\n",
    "\n",
    "$$\n",
    "\\large\n",
    "\\begin{equation*}\n",
    "  q(\\boldsymbol{n},\\boldsymbol{m}) = \\begin{cases} \\lim_{h\\to 0}\\frac{\\mathbb{P}(\\boldsymbol{N}_{t+h} = \\boldsymbol{n}\\vert \\boldsymbol{N}_{t} = \\boldsymbol{m})}{h}\\;,& \\boldsymbol{n} \\not=\\boldsymbol{m}\\;,\\\\\n",
    "    -\\lim_{h\\to 0}\\frac{1-\\mathbb{P}(\\boldsymbol{N}_{t+h} = \\boldsymbol{n}\\vert \\boldsymbol{N}_{t} = \\boldsymbol{n})}{h}\\;,& \\boldsymbol{n} =\\boldsymbol{m}\\;.\n",
    "    \\end{cases}\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "If one wanted to implement this matrix, then one would, of course,\n",
    "have to truncate the state space appropriately. However, implementing\n",
    "this matrix explicitly is neither needed nor advisable! In fact, the\n",
    "code below shows an exemplary implementation. There, first the jump\n",
    "times are generated, before its is determined which reaction takes\n",
    "place."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d935286-24ee-47dd-bd4f-4002acfd289e",
   "metadata": {},
   "source": [
    "2. Utilise the following algorithm to simulate the chemical reaction\n",
    "  system. Plot a time series for each species' number of molecules for\n",
    "  $t\\in[0, T]$, $T=0.2$, for the reaction rates\n",
    "  \\begin{equation*}\n",
    "    c_1 = 1\\;,\\quad c_2 = 5\\;,\\quad c_3 = 15\\;,\\quad c_4 = \\frac{3}{4}\\;,\n",
    "  \\end{equation*}\n",
    "  using $\\boldsymbol{N}_0 = (400,800,0)$ as initial number of\n",
    "  molecules. Repeat the simulation for the same reaction rates\n",
    "  $c_1,\\dots, c_4$ also for $T=5$.\n",
    "\n",
    "    **Algorithm 1:** Reaction simulation\n",
    "    \n",
    "    - Set $\\boldsymbol{N}_0 = (N^1_0,N^2_0,N^3_0)$, $J_0=0$\n",
    "    - **for** $n=1, 2, \\ldots$ **do**\n",
    "        - Compute $\\lambda = \\sum_{j=1}^4 a_j(\\boldsymbol{N}_{J_{n-1}})$\n",
    "        - Generate $S_n\\sim \\text{Exp}\\left(\\lambda\\right)$ and set $J_n=J_{n-1}+S_n$\n",
    "        - Generate $I \\in \\{1,2,3,4\\}$ with probability mass function\n",
    "          $$\\mathbb{P}(I=j) = \\frac{a_j(\\boldsymbol{N}_{J_{n-1}})}{\\sum_{l=1}^4 a_l(\\boldsymbol{N}_{J_{n-1}})},\n",
    "          $$\n",
    "          which is the probability that the $j^{th}$ reaction happens.\n",
    "        - Set $\\boldsymbol{N}_t = \\boldsymbol{N}_{J_{n-1}} \\forall t \\in [J_{n-1},J_n)$ and $\\boldsymbol{N}_{J_n} = \\boldsymbol{N}_{t,I}$\n",
    "    - **end for**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f42a0786-0d04-42b2-a953-696230eb945e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reaction_simulation(N0: np.array, c: np.array, T: float) -> np.array:\n",
    "    \"\"\"\n",
    "    Reaction simulation for intial values `N0`, reaction rates `c` and time horizon `T`.\n",
    "    Returns jump times as well as the process itself.\n",
    "    \"\"\"\n",
    "    def transition(I: int) -> np.array:\n",
    "        \"\"\"State transition `I` in {1, 2, 3, 4}.\"\"\"\n",
    "        x, y, z = N[-1]\n",
    "        if I == 0:\n",
    "            x = x - 1\n",
    "        elif I == 1:\n",
    "            x, y = x - 2, y + 1\n",
    "        elif I == 2:\n",
    "            x, y = x + 2, y - 1\n",
    "        elif I == 3:\n",
    "            y, z = y - 1, z + 1\n",
    "        N.append(np.array([x, y, z]))\n",
    "\n",
    "    propensity = lambda N: c * np.array([N[0], N[0] * (N[0] - 1) / 2, N[1], N[1]])\n",
    "    \n",
    "    N = [N0]\n",
    "    J = [0]\n",
    "    \n",
    "    while J[-1] < T:\n",
    "        a = propensity(N[-1])\n",
    "        lam = a.sum()\n",
    "        S = expon(scale=1 / lam).rvs()\n",
    "        J.append(J[-1] + S)\n",
    "    \n",
    "        u = np.random.rand()\n",
    "        I = np.argmax(u <= np.cumsum(a / lam))\n",
    "        transition(I)\n",
    "\n",
    "    return J, N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0a2b851f-b916-47f8-aa5b-224d523ad73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_reaction_simulation(N0: np.array, c: np.array, T: float):\n",
    "    \"\"\"Interaction helper.\"\"\"\n",
    "    J, N = reaction_simulation(N0, c, T)\n",
    "\n",
    "    plt.plot(J, N, label=[r\"$N^1$\", r\"$N^2$\", r\"$N^3$\"])\n",
    "    plt.xlabel(r\"$t$\", size=14)\n",
    "    plt.ylabel(r\"$N_t$\", size=14)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.title(\"Reaction simulation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b8d3f17d-8cff-403c-9768-a11570a0d3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.array([1, 5, 15, 3 / 4])\n",
    "N0 = np.array([400, 800, 0])\n",
    "T = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "836b9498-74f0-47e6-a7fd-a0457ddb44df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a94b956d8c7e497aabb1c32e3ba858b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='T', options=(0.2, 5.0), value=0.2), Output()), _dom_classes=('widg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interact(lambda T: plot_reaction_simulation(N0, c, T), T=[0.2, 5.0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f941c7a1-635e-47e2-acb5-815b26a55061",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "\n",
    "Let $\\{N_t\\in\\mathbb{N}_0\\colon t\\ge 0,\\, N_0=0\\}$ be a Poisson process\n",
    "with rate $\\lambda$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402ef0be-6c86-4d01-841b-e3dd42d6516b",
   "metadata": {},
   "source": [
    "1. Show that, conditional on the event $\\{N_T = n\\}$, the jump\n",
    "  times $J_1,\\dots, J_n$ have joint density function\n",
    "  \\begin{equation*}\n",
    "   f_{J_1,\\dots,J_n}(j_1,\\dots,j_n) =  n! \\, T^{-n} \\, \\mathbb{I}(0\\le j_1\\le \\dots\\le j_n\\le T)\\;.\n",
    " \\end{equation*}\n",
    " In other words, show that conditional on $\\{N_T = n\\}$, the jump\n",
    " times $J_1,\\dots, J_n$ have the same distribution as an ordered sample of size $n$ from the uniform distribution on $[0, T]$.\n",
    "\n",
    "    **Hints:** Use the joint distribution of the holding times\n",
    "       $S_1,\\dots,S_{n+1}$ to first derive the joint distribution of the\n",
    "       jump times, where $S_{i+1} = J_{i+1}-J_i$. Then compute the conditional distribution of the jump\n",
    "       times given that $N_T = n$, using the fact that\n",
    "       $\\{N_T = n\\} = \\{J_n\\le T < J_{n+1}\\}$ a.s.} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51dcfdc0-a769-4ab1-8a3f-0fa446fc6e93",
   "metadata": {},
   "source": [
    "Since the Poisson process\n",
    "  $\\{N_t\\in\\mathbb{N}_0\\colon t\\ge 0,\\, N_0=0\\}$ is non-decreasing,\n",
    "  the condition $N_T=n$ implies that $n$ jumps need to take\n",
    "  place. Let's denote these jump times by $J_1,\\dots ,J_n$. As a\n",
    "  matter of fact, the jump times are related to the $(n+1)$ holding\n",
    "  times $S_1,\\dots , S_{n+1}$ by $S_{i+1} = J_{i+1} - J_i$ for\n",
    "  $i=0,\\dots,n$, with the convention that $J_0 = 0$. We know that the\n",
    "  holding times are i.i.d. $\\text{Exp}(\\lambda)$ for some\n",
    "  $\\lambda>0$. Consequently, their joint PDF reads\n",
    "  \\begin{equation*}\n",
    "    f_{S_1,\\dots , S_{n+1}}(s_1,\\dots, s_{n+1}) = \\lambda^{n+1}\\exp{\\biggl(-\\lambda\\sum_{i=1}^{n+1}s_i\\biggr)}\\mathbb{I}(s_1,\\dots s_{n+1}\\ge 0)\\;.\n",
    "  \\end{equation*}\n",
    "  As\n",
    "  $\\sum_{i=1}^{n+1}S_i = \\sum_{i=1}^{n+1}(J_{i} - J_{i-1}) = J_{n+1}$,\n",
    "  the joint PDF of the jumping times  $J_1,\\dots ,J_{n+1}$ is given by\n",
    "  \\begin{equation*}\n",
    "    f_{J_1,\\dots , J_{n+1}}(t_1,\\dots, t_{n+1}) = \\lambda^{n+1}e^{(-\\lambda t_{n+1})}\n",
    "    \\mathbb{I}(0\\le t_1\\le \\dots\\le t_{n+1})\\;.\n",
    "  \\end{equation*}\n",
    "  For any (Borel set) $A\\subseteq \\mathbb{R}^n$ we thus find  \n",
    "  \\begin{equation*}\n",
    "    \\begin{aligned}\n",
    "      \\mathbb{P} & \\bigl((J_1,\\dots , J_{n})\\in A\\vert N_T = n) = \\frac{\\mathbb{P}\\bigl((J_1,\\dots , J_{n})\\in A\\,,\\, N_T = n)}{\\mathbb{P}(N_T=n)}\\\\\n",
    "      &= \\mathbb{P}((J_1,...,J_n) \\in A, J_n \\leq T < J_{n+1})\\\\      \n",
    "      &= \\frac{n! T^{-n}}{\\lambda^n e^{- \\lambda T}} \\int_T^{\\infty} \\left( \\int_{A} \\lambda^{n+1} e^{-\\lambda t_{n+1}} \\mathbb{I}(0\\leq t_1 \\leq ... \\leq  t_n \\leq T) dt_1 dt_2...dt_n\\right)dt_{n+1}\\\\\n",
    "      &= \\frac{\\lambda n! T^{-n}}{e^{- \\lambda T}} \\int_T^{\\infty} e^{-\\lambda t_{n+1}} dt_{n+1} \\int_{A} \\mathbb{I}(0\\leq t_1 \\leq ... \\leq  t_n \\leq T) dt_1 dt_2...dt_n\\\\\n",
    "      &= n! T^{-n}\\int_{A}\\mathbb{I}(0\\le t_1\\le \\dots\\le t_{n}\\leq T)\\,dt_1\\dots dt_n\\;,\n",
    "    \\end{aligned}\n",
    "  \\end{equation*}\n",
    "  as claimed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9170b4-9d85-4406-84d0-0b1993426a7c",
   "metadata": {},
   "source": [
    "2. Use the property above to propose an algorithm to generate the\n",
    "  process $N_t$, $t\\in (t_1,t_2)$, conditional upon $N_{t_1} = n_1$\n",
    "  and $N_{t_2} = n_2>n_1$. Such a process is called _Poisson bridge_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "787d873d-3c34-436f-a3bb-014939630080",
   "metadata": {},
   "outputs": [],
   "source": [
    "def poisson_bridge(t1: float, t2: float, n1: int, n2: int) -> np.array:\n",
    "    \"\"\"Generates a Poisson bridge between (`t1`, `n1`) and (`t2`, `n2`).\"\"\"\n",
    "    assert n1 < n2, \"n1 should be smaller than n2.\"\n",
    "\n",
    "    dt = t2 - t1\n",
    "    dn = n2 - n1\n",
    "\n",
    "    J = np.sort(dt * np.random.rand(dn))\n",
    "    \n",
    "    t = t1 + np.hstack([0., J])\n",
    "\n",
    "    t = np.hstack([t, t2])\n",
    "    N = n1 + np.arange(dn + 1)\n",
    "    N = np.hstack([N, n2])\n",
    "    return t, N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e52b2abe-bdd9-460c-8617-234af62a033f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_poisson_bridge(t1: float, t2: float, n1: int, n2: int):\n",
    "    \"\"\"Interaction helper.\"\"\"\n",
    "    t, N = poisson_bridge(t1, t2, n1, n2)\n",
    "\n",
    "    plt.step(t, N)\n",
    "    plt.plot([t1, t2], [n1, n2], \"ro\", label=r\"$n_1$ and $n_2$\")\n",
    "    plt.xlabel(\"t\", size=14)\n",
    "    plt.ylabel(r\"$N_t$\", size=14)\n",
    "    plt.title(\"Poisson bridge\")\n",
    "    plt.legend(fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "12f86bf5-4e68-4d28-bef2-d0d31727650f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf527e7fc318447985d61dddd9395f13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='t1', max=10), IntSlider(value=10, description='t2', max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interact(plot_poisson_bridge, t1=(0, 10), t2=(0, 20), n1=(1, 10), n2=(10, 100));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
