{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Process Regression\n",
    "\n",
    "This notebook comprises a simple demonstration of Gaussian processes regression (GPR) using\n",
    "*scikit-learn*, a popular ML & data science toolbox. GPR is a supervised learning technique that\n",
    "relies on a Bayesian Ansatz. In a nutshell, GPR aims to find a (somewhat optimal) Gaussian process\n",
    "representation, conditioned on (noisy) input-output data we have for that function. GPR is \n",
    "non-parametric and quite flexible, as it can be based on a variety of kernel functions and \n",
    "hyperparameters. However, standard Gaussian processes are dense in the sense that every prediction\n",
    "depends on all training points. Hence, they do not scale well in higher dimensions, although\n",
    "extensions like sparse Gaussian processes can overcome this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "%matplotlib widget\n",
    "plt.close('all')\n",
    "plt.style.use('bmh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we want to showcase the regression problem for a 1D function given noisy data.\n",
    "As a first step, we need to generate a ground truth and perturbed data points.\n",
    "\n",
    "**Exercise:** Evaluate the function $f(x)=(3x-1.4) \\sin (18x)$ on a 1D grid. Choose 10 random \n",
    "$x$-values and create data points for these locations by perturbing the exact solution with i.i.d\n",
    "Gaussian increments,\n",
    "$$\n",
    "    y_i = f(x_i) + \\eta,\\quad \\eta\\sim\\mathcal{N}(0,\\sigma^2),\\ \\sigma=0.1,\\quad\n",
    "    \\mathrm{for}\\ i=1,2,\\ldots,10.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_std = 0.1\n",
    "#x_grid = #???\n",
    "#x_data = #???\n",
    "#y_data = #???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use the training data to construct a Gaussian process regressor with `sklearn`. We choose\n",
    "a radial basis function kernel with fixed length scale $l$,\n",
    "$$\n",
    "    k(x_1, x_2) = \\exp\\Bigl( \\frac{(x_1-x_2)^2}{2 l^2} \\Bigr).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_length_scale = 0.1\n",
    "kernel = RBF(length_scale=kernel_length_scale, length_scale_bounds='fixed')\n",
    "gaussian_process = GaussianProcessRegressor(kernel=kernel, alpha=noise_std**2)\n",
    "gaussian_process.fit(x_data, y_data)\n",
    "mean_prediction, std_prediction = gaussian_process.predict(x_grid, return_std=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Evaluate and plot the posterior mean and 95% confidence interval of the GPR compared\n",
    "to the exact solution for different values of the kernel length scale $l$. What do you observe and\n",
    "why? What could be a good strategy to \"learn\" $l$ from the training data?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
