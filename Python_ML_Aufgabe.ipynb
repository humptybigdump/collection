{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Übung 2: Maschinelles Lernen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In dieser Python Übung befassen wir uns mit der Anwendung maschineller Lernverfahren auf Bilddaten. Dazu verwenden wir den MNIST Datensatz. Dies ist ein sehr bekannter Datensatz für das Benchmarking von Deep Learning Algorithmen. Zunächst installieren wir alle benötigten Packages und importieren diese."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Falls Python für Sie neu ist, empfehlen wir Ihnen folgendes Tutorial: https://www.w3schools.com/python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation notwendiger Packages\n",
    "!pip install sklearn\n",
    "!pip install tensorflow\n",
    "!pip install keras\n",
    "!pip install matplotlib\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import notwendiger Packages\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Der MNIST Datensatz besteht aus 70.000 Bildern der Größe 28x28 Pixel. Die Bilder enthalten dabei die Zahlen von 0 bis 9. Wir laden zunächst den Datensatz und überprüfen die Dimensionen der Daten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lade den Datensatz\n",
    "(trainX, trainY), (testX, testY) = mnist.load_data()\n",
    "\n",
    "# Gebe einen Überblick über die Dimensionen aus\n",
    "print('Train: X={trainX}, y={trainY}'.format(trainX = trainX.shape, trainY = trainY.shape))\n",
    "print('Test: X={testX}, y={testY}'.format(testX = testX.shape, testY = testY.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Wir visualisieren nun ein paar Trainingsdaten. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot der ersten 9 Trainingsbilder\n",
    "for i in range(9):\n",
    "    pyplot.subplot(330 + 1 + i)\n",
    "    pyplot.imshow(trainX[i], cmap = pyplot.get_cmap('gray'))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teil 1: Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Zunächst verwenden wir eine SVM zur Klassifikation der Bilddaten. Da SVMs eindimensionale Inputdaten erwarten, müssen die Bilddaten in diese Form transformiert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX_1d = trainX.reshape((60000, 28*28))\n",
    "testX_1d = testX.reshape((10000, 28*28))\n",
    "\n",
    "# Gebe einen Überblick über die Dimensionen aus\n",
    "print('Train: X={trainX}, y={trainY}'.format(trainX = trainX_1d.shape, trainY = trainY.shape))\n",
    "print('Test: X={testX}, y={testY}'.format(testX = testX_1d.shape, testY = testY.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Die SVM wird zunächst mit den Trainingsdaten trainiert. Zur Verringerung der Rechenzeit beschränken wir die maximale Anzahl an Iterationen. Anschließend wird das Modell dazu verwendet, um die Daten aus dem Hold Out Testdatensatz vorherzusagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instanziiere eine SVM\n",
    "svm = SVC(max_iter = 50)\n",
    "\n",
    "# trainiere die SVM mit den Trainingsdaten\n",
    "svm.fit(trainX_1d, trainY)\n",
    "\n",
    "# sage die Testdaten vorher\n",
    "predY_svm = svm.predict(testX_1d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mithilfe der Testdaten berechnen wir die Konfusionsmatrix für das Modell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# berechne die Konfusionsmatrix\n",
    "cm = metrics.confusion_matrix(testY, predY_svm)\n",
    "\n",
    "# plotte die Matrix\n",
    "pyplot.figure(figsize=(9,9))\n",
    "sns.heatmap(cm, annot = True, fmt = \".3f\", linewidths = .5, square = True, cmap = 'Blues_r');\n",
    "pyplot.ylabel('Tatsächliche Klasse');\n",
    "pyplot.xlabel('Ermittelte Klasse');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 1: Berechnen Sie Accuracy, Precision und Recall des Modells.\n",
    "##### Hinweis: Es empfielt sich, eine Funktion dafür zu schreiben, da die Metriken im späteren Verlauf wieder benötigt werden. Eine Dokumentation zu den Metriken in sklearn finden Sie hier: https://scikit-learn.org/stable/modules/model_evaluation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier ist Platz für Ihre Lösung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 2: Welche Parameterwerte hat das SVM Modell standardmäßig?\n",
    "##### Hinweis: Eine Dokumentation zu SVMs in sklearn finden Sie hier: https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier ist Platz für Ihre Lösung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 3: Verwenden Sie nun eine SVM mit linearem Kernel. Vergleichen Sie die Performance des neuen Modells mit dem Standard-Modell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier ist Platz für Ihre Lösung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teil 2: Multi Layer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Im nächsten Schritt verwenden wir ein Feed-Forward Neuronales Netz. Dabei beschränken wir wieder die Anzahl an Iterationen, um die Rechenzeit zu begrenzen. Das MLP erwartet ebenso wie die SVM eindimensionale Inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# instanziiere ein neuronales Netz\n",
    "mlp = MLPClassifier(max_iter = 50, verbose = True)\n",
    "\n",
    "# trainiere das MLP mit den Trainingsdaten\n",
    "mlp.fit(trainX_1d, trainY)\n",
    "\n",
    "# sage die Testdaten vorher\n",
    "predY_mlp = mlp.predict(testX_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# berechne die Konfusionsmatrix\n",
    "cm = metrics.confusion_matrix(testY, predY_mlp)\n",
    "\n",
    "# plotte die Matrix\n",
    "pyplot.figure(figsize=(9,9))\n",
    "sns.heatmap(cm, annot = True, fmt = \".3f\", linewidths = .5, square = True, cmap = 'Blues_r');\n",
    "pyplot.ylabel('Tatsächliche Klasse');\n",
    "pyplot.xlabel('Ermittelte Klasse');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 4: Berechnen Sie erneut Accuracy, Precision und Recall des Modells. Welche Parameterwerte hat das neuronale Netz standardmäßig?\n",
    "\n",
    "##### Hinweis: Eine Dokumentation zu MLPs in sklearn finden Sie hier: https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier ist Platz für Ihre Lösung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 5: Wie lässt sich die Performance des Modells verbessern? Experimentieren Sie mit den Modellparametern. Welche Parameter haben hierbei einen entscheidenden Einfluss?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier ist Platz für Ihre Lösung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teil 3: Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Zuletzt schauen wir uns CNNs an. Für ausführlichere Erläuterungen sei auf https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-from-scratch-for-mnist-handwritten-digit-classification/ verwiesen. Wie Sie in der Vorlesung bereits erfahren haben, sind CNNs State of the Art, wenn es um die Klassifikation von Bildern geht. Bevor wir das Klassifikationsmodell erstellen, müssen die MNIST Daten noch transformiert werden. Im Gegensatz zu SVMs und MLPs erwartet ein CNN dreidimensionale Inputs. Ein Eingabebild muss in der Dimension b x h x c übergeben werden, wobei:\n",
    "##### b: Breite des Bildes (#Pixel)\n",
    "##### h: Höhe des Bildes (#Pixel)\n",
    "##### c: Anzahl der Channels, bei Schwarz/Weiß-Bildern: 1, bei Farb-Bildern: 3 (für die Pixelcodierung in rot, grün und blau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformiere den Datensatz\n",
    "trainX_cnn = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
    "testX_cnn = testX.reshape((testX.shape[0], 28, 28, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Die Pixelwerte im Datensatz liegen zwischen 0 (schwarz) und 255 (weiß). Bevor wir das CNN-Modell erstellen, sollte der Datensatz normalisiert werden, z.B. durch Skalierung der Pixelfarbwerte auf das Intervall [0,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skaliere die Trainingsdaten\n",
    "trainX_cnn = trainX_cnn.astype('float32')\n",
    "trainX_cnn = trainX_cnn / 255.0\n",
    "\n",
    "# skaliere die Testdaten\n",
    "testX_cnn = testX_cnn.astype('float32')\n",
    "testX_cnn = testX_cnn / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Außerdem codieren wir den Output des Netzes, so dass das CNN später 10 Outputneuronen besitzt (für jede Zahl von 0-9 eine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kodierung des Outputs\n",
    "trainY_cnn = to_categorical(trainY)\n",
    "testY_cnn = to_categorical(testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Nun erstellen wir ein CNN mit einem Convolutional Layer, einem Max Pooling Layer und einem Fully Connected Layer. Wir trainieren das Modell mit dem stochastischen Gradientenabstiegsverfahren (SGD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# erstelle ein CNN-Modell\n",
    "def create_cnn():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation = 'relu', kernel_initializer = 'he_uniform', \n",
    "                     input_shape = (28, 28, 1)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation = 'relu', kernel_initializer = 'he_uniform'))\n",
    "    model.add(Dense(10, activation = 'softmax'))\n",
    "    \n",
    "    # kompiliere das Modell\n",
    "    opt = SGD(lr = 0.01, momentum = 0.9)\n",
    "    model.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 6: Führen Sie k-Fold Cross Validation (k = 4) mit dem oben definierten CNN-Modell durch. Greifen Sie dabei auf die Funktion create_cnn zurück. Wie robust ist das Modell?\n",
    "##### Hinweis: Hierfür müssen Sie nur auf die Trainingsdaten zurückgreifen. Sie können die KFold Funktion von sklearn verwenden: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier ist Platz für Ihre Lösung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 7: Trainieren Sie das obige CNN-Modell nun mit dem kompletten Trainingsdatensatz. Wie hoch ist die Accuracy auf dem Testdatensatz?\n",
    "##### Hinweis: Sie können diese Aufgabe auch bearbeiten, falls Sie die Aufgabe 6 nicht lösen konnten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier ist Platz für Ihre Lösung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Wie wir sehen, ist die Vorhersagegenauigkeit des CNN-Modells bereits sehr hoch. Zur Veranschaulichung plotten wir ein zufälliges Bild aus dem Testdatensatz und schauen uns an, was die Vorhersage des Modells ist. Die Vorhersageergebnisse des CNNs stehen dabei für die Wahrscheinlichkeiten, die das Modell den Klassen (Zahlen von 0-9) zuordnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zufälliger Index für ein Bild aus dem Testdatensatz\n",
    "image_index = 26\n",
    "\n",
    "# plotte das Bild\n",
    "pyplot.imshow(testX[image_index], cmap=pyplot.get_cmap('gray'))\n",
    "pyplot.show()\n",
    "\n",
    "# berechne die Vorhersage des CNNs\n",
    "image = testX_cnn[image_index].reshape(1, 28, 28, 1)\n",
    "digit = cnn.predict(image)\n",
    "print(\"Vorhersage des CNNs: \\n{}\".format(digit[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 8: Können Sie die Vorhersagegenauigkeit noch weiter steigern? Welche Modellparameter lassen sich beim CNN dazu noch verändern? Experimentieren Sie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier ist Platz für Ihre Lösung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
