{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be64febb",
   "metadata": {},
   "source": [
    "# ID3 from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f11159e",
   "metadata": {},
   "source": [
    "Let us import some libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a3716a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset loader utility for OpenML\n",
    "from openml.datasets import get_dataset\n",
    "# Working with data frames\n",
    "import pandas as pd\n",
    "# Matrices, n-dimensional arrays etc.\n",
    "import numpy as np\n",
    "# Encoder for labels --> integers\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3fdf26",
   "metadata": {},
   "source": [
    "Different data sets have different IDs on OpenML\n",
    "- we can load a dataset based on its id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65776f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "MUSHROOM = 24\n",
    "TICTACTOE = 50  # We are using this dataset today\n",
    "MONK1 = 333\n",
    "MONK2 = 334"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3011a9f1",
   "metadata": {},
   "source": [
    "## Utility functions and definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287fe99f",
   "metadata": {},
   "source": [
    "Shuffle dataframe by sampling from it with `frac=1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5aeba2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_df(df: pd.DataFrame):\n",
    "    return df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0710ad",
   "metadata": {},
   "source": [
    "### Decision tree utilities\n",
    "\n",
    "Utilities for checking \n",
    "1. if all values in a series are the same\n",
    "2. what the most common value in the given series is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69f8708f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_homogeneous(values: pd.Series):\n",
    "    return len(np.unique(values)) == 1\n",
    "\n",
    "\n",
    "def most_common_label(values: pd.Series):\n",
    "    values, counts = np.unique(values, return_counts=True)\n",
    "    most_frequent_index = np.argmax(counts)\n",
    "    return values[most_frequent_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede4d301",
   "metadata": {},
   "source": [
    "Entropy and information gain calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b457acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(values: pd.Series):\n",
    "    num_values = len(values)\n",
    "    unique_vals = np.unique(values)\n",
    "    probabilities = [\n",
    "        np.sum(values == this_value) / num_values\n",
    "        for this_value in unique_vals\n",
    "    ]\n",
    "    entropy = 0\n",
    "    for probability in probabilities:\n",
    "        entropy -= probability * np.log2(probability)\n",
    "    return entropy\n",
    "\n",
    "\n",
    "def information_gain(data: pd.DataFrame, attribute: str):\n",
    "    entropy_total =  entropy(data[\"class\"])\n",
    "    split_entropy = 0\n",
    "    for att_value, partition in data.groupby(attribute):\n",
    "        weight = len(partition) / len(data)\n",
    "        split_entropy += weight * entropy(partition[\"class\"])\n",
    "    return entropy_total - split_entropy\n",
    "\n",
    "\n",
    "def find_split_attribute(data: pd.DataFrame):\n",
    "        attributes = data.columns[data.columns != \"class\"].to_numpy()\n",
    "        IG_all_splits = [\n",
    "            information_gain(data, attribute) for attribute in attributes\n",
    "        ]\n",
    "        att_index = np.argmax(IG_all_splits)\n",
    "        return attributes[att_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2609a720",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "\n",
    "- our fundamental class is an `ID3` node in our decision tree\n",
    "- each node has\n",
    "    - children (if not a leaf node)\n",
    "    - some data (we may discard after building the tree)\n",
    "    - the assigned label (if a leaf node)\n",
    "    - a flag indicating if the node is a leaf\n",
    "    \n",
    "Note that ID3 works only with categorical data. Newer methods also can handle numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a42f05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOLABEL = -1\n",
    "\n",
    "class ID3:\n",
    "    def __init__(self, data: pd.DataFrame):\n",
    "        self.children = {}  # an empty dict, will take the form {att_value: child}\n",
    "        self.data = data\n",
    "        self.split_attribute = None\n",
    "        self.is_leaf = False\n",
    "        self.label = NOLABEL\n",
    "\n",
    "    def fit(self):\n",
    "        # ID3 algorithm\n",
    "        labels = self.data[\"class\"].to_numpy()\n",
    "        attributes = self.data.columns[self.data.columns != \"class\"].to_numpy()\n",
    "        # check if this node should be a leaf node\n",
    "        if is_homogeneous(labels):\n",
    "            self.is_leaf = True\n",
    "            self.label = labels[0]\n",
    "        if len(attributes) == 0:\n",
    "            self.is_leaf = True\n",
    "            self.label = most_common_label(labels)\n",
    "        else:\n",
    "            self.split_attribute = find_split_attribute(self.data)\n",
    "            for att, partition in self.data.groupby(self.split_attribute):\n",
    "                # remove split attribute of this node from remaining partition\n",
    "                partition_wo_split_attribute = partition.drop(self.split_attribute, axis=1)\n",
    "                new_node = ID3(partition_wo_split_attribute)\n",
    "                if len(partition) == 0:\n",
    "                    label = most_common_label(labels)\n",
    "                    new_node.label = label\n",
    "                    new_node.is_leaf = True\n",
    "                else:\n",
    "                    # expand tree\n",
    "                    new_node = ID3(data=partition_wo_split_attribute)\n",
    "                    new_node.fit()\n",
    "                    self.children[att] = new_node\n",
    "\n",
    "    def predict(self, x):\n",
    "        if self.is_leaf:\n",
    "            return self.label\n",
    "        else:\n",
    "            att_value = x[self.split_attribute]\n",
    "            if att_value in self.children.keys():\n",
    "                return self.children[att_value].predict(x)\n",
    "            else:\n",
    "                return most_common_label(self.data[\"class\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b3e947",
   "metadata": {},
   "source": [
    "## Running our algorithm\n",
    "- define dataset\n",
    "- preprocess data\n",
    "- build tree\n",
    "- evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c41b876",
   "metadata": {},
   "source": [
    "We first load the data from OpenML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60b32ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_dataset(dataset_id=TICTACTOE).get_data()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87664223",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "1. shuffle data\n",
    "2. rename target column (some are \"Class\" instead of \"class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4987c7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = shuffle_df(data)\n",
    "data.rename({\"Class\": \"class\"}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57856ad",
   "metadata": {},
   "source": [
    "Encode labels as integers (zeros and ones for binary classification)\n",
    "- we use the label encoder from scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6945dbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"class\"] = LabelEncoder().fit_transform(data[\"class\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafffccf",
   "metadata": {},
   "source": [
    "Split the data into train and test\n",
    "- 80/20 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4279984",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = int(0.8 * len(data))\n",
    "train, test = data.loc[:num_train], data.loc[num_train:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da72395b",
   "metadata": {},
   "source": [
    "### Building the tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b8aadb",
   "metadata": {},
   "source": [
    "Fitting the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3526e70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "id3 = ID3(train)\n",
    "id3.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bad0a6e",
   "metadata": {},
   "source": [
    "- Evaluate on training and test data\n",
    "- Store data in a nested list (we will afterwards convert to a data frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59c0ce4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_datasets = {\"Training data\": train, \"Test data\": test}\n",
    "result_df = []\n",
    "for ds_name, eval_data in eval_datasets.items():\n",
    "    majority_vote_agreement = np.sum(test[\"class\"])\n",
    "    if majority_vote_agreement < 0.5 * len(eval_data):\n",
    "        majority_vote_agreement = len(eval_data) - majority_vote_agreement    \n",
    "    predictions = [id3.predict(sample) for _, sample in eval_data.iterrows()]\n",
    "    correct_predictions = predictions == eval_data[\"class\"]\n",
    "    num_correct = np.sum(correct_predictions)\n",
    "    accuracy = num_correct / len(eval_data)\n",
    "    kappa = (num_correct - majority_vote_agreement) / (len(eval_data) - majority_vote_agreement)\n",
    "    result_df.append([ds_name, accuracy, kappa])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fad801",
   "metadata": {},
   "source": [
    "Convert nested list `result_df` to data frame and show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c0ba0bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Training data</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test data</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Dataset  Accuracy     Kappa\n",
       "0  Training data  1.000000  1.000000\n",
       "1      Test data  0.854167  0.636364"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_df = pd.DataFrame(result_df, columns=[\"Dataset\", \"Accuracy\", \"Kappa\"])\n",
    "display(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638f7db8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "E2_kernel",
   "language": "python",
   "name": "e2_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
