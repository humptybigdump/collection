{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Science and AI for Energy Systems** \n",
    "\n",
    "Karlsruhe Institute of Technology\n",
    "\n",
    "Institute of Automation and Applied Informatics\n",
    "\n",
    "Summer Term 2024\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise XIII: \"Other ML\" applications for energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix, RocCurveDisplay, roc_curve, PrecisionRecallDisplay, precision_recall_curve, precision_score, recall_score, f1_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem XIII.2 (programming) - Applying Isolation Forests to Time Series Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this programming task, we apply isolation forests for unsupervised anomaly detection.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a) We start by applying and visualizing an isolation forest to randomly generated data points by following the [scikit-learn example](https://scikit-learn.org/stable/auto_examples/ensemble/plot_isolation_forest.html).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**i. Generate the random data points as described in the notebook.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_outliers = 120, 40\n",
    "\n",
    "\n",
    "covariance = np.array([[0.5, -0.1], [0.7, 0.4]])\n",
    "cluster_1 = 0.4 * rng.randn(n_samples, 2) @ covariance + np.array([2, 2])  # general\n",
    "cluster_2 = 0.3 * rng.randn(n_samples, 2) + np.array([-2, -2])  # spherical\n",
    "\n",
    "\n",
    "# create uniformely distributed \"outliers\"\n",
    "outliers = rng.uniform(low=-4, high=4, size=(n_outliers, 2))\n",
    "\n",
    "X = np.concatenate([cluster_1, cluster_2, outliers])\n",
    "y = np.concatenate([np.ones((2 * n_samples), dtype=int), -np.ones((n_outliers), dtype=int)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into a training and test set. You can use ```train_test_split``` from scikit-learn. By setting ```stratify=y``` you can ensure that the train and test set contain the same proportion of outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the generated data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter = plt.scatter(X[:, 0], X[:, 1], c=y, s=20, edgecolor=\"k\")\n",
    "handles, labels = scatter.legend_elements()\n",
    "plt.axis(\"square\")\n",
    "plt.legend(handles=handles, labels=[\"outliers\", \"inliers\"], title=\"true class\")\n",
    "plt.title(\"Gaussian inliers with \\nuniformly distributed outliers\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ii. Train the isolation forest.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = IsolationForest(max_samples=100, random_state=0)\n",
    "clf.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**iii. Visualize the decision boundary.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sklearn implementation of the isolation forest returns the negative of the  anomaly score defined in the paper for the ```score_samples``` method. Therefore we multiply the scores by -1 to get the anomaly scores defined in Exercise XIII.1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scatter = plt.scatter(X[:, 0], X[:, 1], c=clf.score_samples(X) * -1, s=20, edgecolor=\"k\")\n",
    "handles, labels = scatter.legend_elements()\n",
    "plt.axis(\"square\")\n",
    "plt.title(\"Anomaly Scores\")\n",
    "plt.colorbar(scatter)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision boundary that is used when calling ```predict()``` is defined by the ```contamination``` parameter. In this case we have not set it so it defaults to ```auto``` which in principle means that the threshold is set at an anomaly score of ```0.5```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "disp = DecisionBoundaryDisplay.from_estimator(\n",
    "    clf,\n",
    "    X,\n",
    "    response_method=\"predict\",\n",
    "    alpha=0.5,\n",
    ")\n",
    "disp.ax_.scatter(X[:, 0], X[:, 1], c=y, s=20, edgecolor=\"k\")\n",
    "disp.ax_.set_title(\"Binary decision boundary \\nof IsolationForest\")\n",
    "plt.axis(\"square\")\n",
    "plt.legend(handles=handles, labels=[\"outliers\", \"inliers\"], title=\"true class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the ```decision_function``` of the isolation forest. By looking at the docs we can see that ```decision_function = score_samples - offset_``` where the offset is either set as ```0.5``` if the contamination is set to ```auto``` or as if the contamination is set to a specific value it is is defined in such a way we obtain the expected number of outliers. The decision function then divides outliers from inliers at ```0```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = DecisionBoundaryDisplay.from_estimator(\n",
    "    clf,\n",
    "    X,\n",
    "    response_method=\"decision_function\",\n",
    "    alpha=0.5,\n",
    ")\n",
    "disp.ax_.scatter(X[:, 0], X[:, 1], c=y, s=20, edgecolor=\"k\")\n",
    "disp.ax_.set_title(\"Path length decision boundary \\nof IsolationForest\")\n",
    "plt.axis(\"square\")\n",
    "plt.legend(handles=handles, labels=[\"outliers\", \"inliers\"], title=\"true class\")\n",
    "plt.colorbar(disp.ax_.collections[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) Now we look into how to apply this algorithm for time series as encountered in energy applications. Specifically, we introduce synthetic anomalies into load data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**i. Retrieve the Load data from BWsyncandshare.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data\n",
    "load_data = pd.read_csv('data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data.plot(figsize=(20, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ii. Introduce synthetic anomalies as described in the notebook.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we introduce anomalies by adding or subtracting from the original data at randomly selected points.\n",
    "Start with large anomalies (e.g. offsets of around 8000) and then reduce the size of the anomalies to see how the isolation forest reacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the data to retain the original data\n",
    "data = load_data.copy()\n",
    "\n",
    "# randomly select 5% of the data as anomalies\n",
    "anomaly_indices = np.random.choice(len(data), size=int(0.05*len(data)), replace=False)\n",
    "\n",
    "# generate random offsets for the anomalies\n",
    "anomaly_offset = np.random.choice([-1, 1], size=(len(anomaly_indices))) * np.random.normal(2500, 800, size=(len(anomaly_indices)))\n",
    "\n",
    "# introduce anomalies in the data\n",
    "data.iloc[anomaly_indices] = (data.iloc[anomaly_indices].values.flatten() + anomaly_offset).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the isolation forest is unsupervised we do not need a ground truth during training. However we can use the ground truth to evaluate the performance of the isolation forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the indices of the anomalies as ground_truth\n",
    "ground_truth = pd.Series(np.zeros(len(data)), index=data.index)\n",
    "ground_truth.iloc[anomaly_indices] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the data into a training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train = data.loc[:'2020']\n",
    "X_test = data.loc['2020':]\n",
    "y_train = ground_truth.loc[:'2020']\n",
    "y_test = ground_truth.loc['2020':]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**iii. Train an Isolation Forest with the training set and predict on the test set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the isolation forest\n",
    "clf = IsolationForest(max_samples=100, random_state=0, contamination=0.05)\n",
    "clf.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```predict``` method returns ```1``` for normal data and ```-1``` for anomalies. We want to compare the predictions with the ground truth. Therefore we need to convert the predictions to the same format as the ground truth which is ```1``` for anomalies and ```0``` for normal data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = (clf.predict(X_test) - 1) / - 2 \n",
    "prediction = pd.Series(prediction, index=X_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**iv. Evaluate the predictions.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a Confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, prediction)\n",
    "\n",
    "cm_display = ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The F1 score is the harmonic mean of precision and recall. It is a good metric to evaluate the performance of the isolation forest. If we want to emphasize either precision or recall we can use the F-beta score which is a weighted harmonic mean of precision and recall. The beta parameter determines the weight of precision in the F-beta score. If beta is larger than 1 recall is emphasized, if beta is smaller than 1 precision is emphasized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate f1 score\n",
    "f1_score(y_test, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also calculate precision and recall separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate precision\n",
    "print('Precision:', precision_score(y_test, prediction))\n",
    "\n",
    "# calculate recall\n",
    "print('Recall:', recall_score(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By plotting the ROC curve and the Precision-Recall curve we can see how the isolation forest performs for different thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = (clf.decision_function(X_test) - 1) / - 2 \n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr)\n",
    "\n",
    "prec, recall, _ = precision_recall_curve(y_test, y_score)\n",
    "pr_display = PrecisionRecallDisplay(precision=prec, recall=recall)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 8))\n",
    "\n",
    "roc_display.plot(ax=ax1)\n",
    "pr_display.plot(ax=ax2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**v. Improve the performance of the isolation forest for time series by giving context via engineered features.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In time series anomalies the context is often important. For example, a change in load that is normal during the day could be an anomaly if it happens during the night. Also deviations that are not extreme on the global scale could be very large in their local surrounding. Therefore we can engineer features that give the isolation forest more context and improve its performance. Here we start by adding the increments of the load data as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include the difference of the load as a feature\n",
    "data['load_DE_diff'] = data['load_DE'].diff(1)\n",
    "# data['load_DE_diff2'] = data['load_DE'].diff(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train = data.loc[:'2020']\n",
    "X_test = data.loc['2020':]\n",
    "y_train = ground_truth.loc[:'2020']\n",
    "y_test = ground_truth.loc['2020':]\n",
    "\n",
    "# drop the first row as it contains NaN\n",
    "X_train = X_train.dropna()\n",
    "y_train = y_train.loc[X_train.index]\n",
    "\n",
    "# train the isolation forest\n",
    "clf = IsolationForest(max_samples=100, random_state=0, contamination=0.05)\n",
    "clf.fit(X_train)\n",
    "\n",
    "prediction = (clf.predict(X_test) - 1) / - 2 \n",
    "prediction = pd.Series(prediction, index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, prediction)\n",
    "\n",
    "cm_display = ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate f1 score\n",
    "f1_score(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate precision\n",
    "print('Precision:', precision_score(y_test, prediction))\n",
    "\n",
    "# calculate recall\n",
    "print('Recall:', recall_score(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "language": "python",
   "name": ""
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
