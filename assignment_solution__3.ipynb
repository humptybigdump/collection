{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Machine Vision 2022/23 - Assignment 7: Deep Learning\n",
    "\n",
    "In this exercises you will apply different concepts of deep learning in order to classify images of traffic signs. While working through this notebook, different links to official web-sites or blog-posts are provided for additional information.\n",
    "This exercise uses the Tensorflow framework, which is one of the most popular deep learning frameworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-10 09:01:56.514703: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "tf.get_logger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### Preparation\n",
    "\n",
    "##### German Traffic Sign Recognition Benchmark\n",
    "\n",
    "The German Traffic Sign Recognition Benchmark [(GTSRB)](https://benchmark.ini.rub.de/) is a competition that was held at the IJCNN 2011. In this competition images of traffic signs should be classified.\n",
    "You will implement your own neural network to classify a subset of the GTSRB dataset. This subset consists of `12` different classes, which are shown in the figures below. However, you are free to extend your solution to the full dataset.\n",
    "\n",
    "\n",
    "|---|------------------------------|-------------------------------|-------------------------------|-------------------------------|-------------------------------|-------------------------------|-------------------------------|-------------------------------|-------------------------------|--------------------------------|--------------------------------|--------------------------------|\n",
    "|  ![Class 0](res/images/0.png) | ![Class 1](res/images/6.png) | ![Class 2](res/images/16.png) | ![Class 3](res/images/17.jpg) | ![Class 4](res/images/19.png) | ![Class 5](res/images/22.jpg) | ![Class 6](res/images/28.png) | ![Class 7](res/images/29.png) | ![Class 8](res/images/32.png) | ![Class 9](res/images/33.png) | ![Class 10](res/images/38.png) | ![Class 11](res/images/40.png) |\n",
    "<br></br>\n",
    "\n",
    "In order to simplify this exercise, the raw GTSRB images are already transformed into a dataset, where each image has the shape of `[H,W,C]` (Height x Width x Channels) with values ranging from `0-1`.\n",
    "Furthermore, the dataset is split into a train-, validation- and test-dataset, where the train- and validation-datasets are provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-10 09:01:58.027242: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-10 09:01:58.035386: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-02-10 09:01:58.036541: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-10 09:01:58.037134: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES = 12\n",
    "\n",
    "def get_datasets(*, images, labels, shuffle=True):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((np.load(images), np.load(labels)))\n",
    "\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(1024)\n",
    "\n",
    "    return ds.batch(32)\n",
    "\n",
    "# Create a dataset for training\n",
    "train_ds = get_datasets(\n",
    "    images=\"res/images_train.npy\",\n",
    "    labels=\"res/labels_train.npy\",\n",
    ")\n",
    "# Create a dataset for validation\n",
    "val_ds = get_datasets(\n",
    "    images=\"res/images_val.npy\",\n",
    "    labels=\"res/labels_val.npy\",\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The `gen_datasets` function creates a [Tensorflow dataset](https://blog.tensorflow.org/2019/02/introducing-tensorflow-datasets.html) from two numpy arrays containing the images and the corresponding ground truth class labels.\n",
    "\n",
    "A Tensorflow dataset is a python class, which provide an easy way iterate a dataset. Each iteration, the dataset returns a batch of `x = [Bx32x32x3]` images and `y = [Bx12]` class labels, where B is the batch size.\n",
    "\n",
    "There are different approaches to encode the class label. For further information you can read this blog entry [integer- or one-hot-encoding](https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/).\n",
    "In this exercise the labels are encoded in one-hot format. Which means, that each label is a vector of 12 entries, where only the entry of the class has the value $1$ and all others values are $0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape: (32, 32, 32, 3)\n",
      "label shape: (32, 12)\n"
     ]
    }
   ],
   "source": [
    "x_batch, y_batch = next(iter(train_ds))\n",
    "\n",
    "# @student print the image and label shape of a batch\n",
    "print(f\"image shape: {x_batch.shape}\")\n",
    "print(f\"label shape: {y_batch.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# @student show one image of the batch and its label\n",
    "print(f\"label: {y_batch[1]}\")\n",
    "plt.imshow(x_batch[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### Execution\n",
    "\n",
    "In order to compare models against each other metrics are calculated on an unseen test dataset. In this exercise you should try to develop your own model and upload the `final_model` directory to ilias.\n",
    "All submitted models are compared to each other using the accuracy metric.\n",
    "\n",
    "**The student that submits the best model will be given the chance to be in the passenger seat while our autonomous car drives around the adenauer ring**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_model(image_shape):\n",
    "    input = tf.keras.layers.Input(shape=image_shape)\n",
    "    # @student implement your neural network\n",
    "\n",
    "    # Augementation Layers\n",
    "    x = tf.keras.layers.RandomBrightness(factor=(-0.5, 0.5), value_range=(0, 1))(input)\n",
    "\n",
    "    # Model Layers\n",
    "    x = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    x = tf.keras.layers.AveragePooling2D()(x)\n",
    "    x = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    x = tf.keras.layers.AveragePooling2D()(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(units=120, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    x = tf.keras.layers.Dense(units=84, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    x = tf.keras.layers.Dense(units=NUM_CLASSES, activation=\"linear\")(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=input, outputs=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In the `create_model` function you can define your own neural network using the [functional tensorflow API](https://www.tensorflow.org/guide/keras/functional).\n",
    "You can also use other tensorflow APIs like the [SequentialModel](https://www.tensorflow.org/guide/keras/sequential_model). However, when transitioning to complex architectures the functional API provides the more flexibility.\n",
    "\n",
    "\n",
    "You are free to use any layer and activation provided by tensorflow for example:\n",
    "[tf.keras.layers.Conv2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D)\n",
    "[tf.keras.layers.Dropout](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout)\n",
    "[tf.keras.layers.AveragePooling2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/AveragePooling2D)\n",
    "[tf.keras.layers.Flatten](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten)\n",
    "[tf.keras.layers.Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense)\n",
    "[tf.keras.activations.relu](https://www.tensorflow.org/api_docs/python/tf/keras/activations/relu)\n",
    "\n",
    "For inspiration you can take a look at these ground-breaking publications:\n",
    "[LeNet](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf)\n",
    "[AlexNet](https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf)\n",
    "[GoogLeNet](https://arxiv.org/pdf/1409.4842.pdf)\n",
    "[ResNet](https://arxiv.org/pdf/1512.03385.pdf)\n",
    "\n",
    "Additionally, you can also add data augmentation to the training data in order to improve the generalization of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " random_brightness (RandomBr  (None, 32, 32, 3)        0         \n",
      " ightness)                                                       \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 30, 30, 32)        0         \n",
      "                                                                 \n",
      " average_pooling2d (AverageP  (None, 15, 15, 32)       0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 13, 13, 64)        18496     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 13, 13, 64)        0         \n",
      "                                                                 \n",
      " average_pooling2d_1 (Averag  (None, 6, 6, 64)         0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2304)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 120)               276600    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 120)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 84)                10164     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 84)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 12)                1020      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 307,176\n",
      "Trainable params: 307,176\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(image_shape=(32,32,3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "217/217 [==============================] - ETA: 0s - loss: 1.4010 - accuracy: 0.5462"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217/217 [==============================] - 5s 20ms/step - loss: 1.4010 - accuracy: 0.5462 - val_loss: 2.5948 - val_accuracy: 0.2333\n",
      "Epoch 2/25\n",
      "216/217 [============================>.] - ETA: 0s - loss: 0.8625 - accuracy: 0.7258"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217/217 [==============================] - 9s 41ms/step - loss: 0.8613 - accuracy: 0.7260 - val_loss: 1.4670 - val_accuracy: 0.5750\n",
      "Epoch 3/25\n",
      "216/217 [============================>.] - ETA: 0s - loss: 0.5030 - accuracy: 0.8410"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217/217 [==============================] - 8s 37ms/step - loss: 0.5032 - accuracy: 0.8411 - val_loss: 1.1006 - val_accuracy: 0.6000\n",
      "Epoch 4/25\n",
      "216/217 [============================>.] - ETA: 0s - loss: 0.4365 - accuracy: 0.8562"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217/217 [==============================] - 7s 34ms/step - loss: 0.4365 - accuracy: 0.8562 - val_loss: 1.6335 - val_accuracy: 0.6250\n",
      "Epoch 5/25\n",
      "215/217 [============================>.] - ETA: 0s - loss: 0.4185 - accuracy: 0.8657"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217/217 [==============================] - 7s 34ms/step - loss: 0.4166 - accuracy: 0.8663 - val_loss: 0.8032 - val_accuracy: 0.7500\n",
      "Epoch 6/25\n",
      "217/217 [==============================] - ETA: 0s - loss: 0.3499 - accuracy: 0.8860"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217/217 [==============================] - 8s 36ms/step - loss: 0.3499 - accuracy: 0.8860 - val_loss: 0.8461 - val_accuracy: 0.7667\n",
      "Epoch 7/25\n",
      "217/217 [==============================] - ETA: 0s - loss: 0.2753 - accuracy: 0.9095"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217/217 [==============================] - 8s 35ms/step - loss: 0.2753 - accuracy: 0.9095 - val_loss: 0.6758 - val_accuracy: 0.8500\n",
      "Epoch 8/25\n",
      "217/217 [==============================] - 5s 25ms/step - loss: 0.2473 - accuracy: 0.9187 - val_loss: 0.6786 - val_accuracy: 0.8167\n",
      "Epoch 9/25\n",
      "215/217 [============================>.] - ETA: 0s - loss: 0.2251 - accuracy: 0.9289"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217/217 [==============================] - 8s 35ms/step - loss: 0.2249 - accuracy: 0.9288 - val_loss: 0.5001 - val_accuracy: 0.9000\n",
      "Epoch 10/25\n",
      "217/217 [==============================] - 5s 24ms/step - loss: 0.2082 - accuracy: 0.9346 - val_loss: 0.4496 - val_accuracy: 0.8583\n",
      "Epoch 11/25\n",
      "217/217 [==============================] - 6s 27ms/step - loss: 0.1937 - accuracy: 0.9398 - val_loss: 0.8537 - val_accuracy: 0.8500\n",
      "Epoch 12/25\n",
      "217/217 [==============================] - 6s 26ms/step - loss: 0.2146 - accuracy: 0.9342 - val_loss: 0.4428 - val_accuracy: 0.8667\n",
      "Epoch 13/25\n",
      "217/217 [==============================] - 6s 26ms/step - loss: 0.2011 - accuracy: 0.9363 - val_loss: 1.0292 - val_accuracy: 0.8083\n",
      "Epoch 14/25\n",
      "217/217 [==============================] - ETA: 0s - loss: 0.1887 - accuracy: 0.9410"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217/217 [==============================] - 8s 35ms/step - loss: 0.1887 - accuracy: 0.9410 - val_loss: 0.2278 - val_accuracy: 0.9417\n",
      "Epoch 15/25\n",
      "217/217 [==============================] - 5s 24ms/step - loss: 0.1689 - accuracy: 0.9460 - val_loss: 0.4905 - val_accuracy: 0.8750\n",
      "Epoch 16/25\n",
      "217/217 [==============================] - 6s 28ms/step - loss: 0.1632 - accuracy: 0.9488 - val_loss: 0.2932 - val_accuracy: 0.9333\n",
      "Epoch 17/25\n",
      "217/217 [==============================] - 6s 25ms/step - loss: 0.1590 - accuracy: 0.9503 - val_loss: 0.5758 - val_accuracy: 0.9083\n",
      "Epoch 18/25\n",
      "217/217 [==============================] - 5s 25ms/step - loss: 0.1557 - accuracy: 0.9512 - val_loss: 0.1910 - val_accuracy: 0.9417\n",
      "Epoch 19/25\n",
      "217/217 [==============================] - 5s 25ms/step - loss: 0.1520 - accuracy: 0.9524 - val_loss: 0.4585 - val_accuracy: 0.9083\n",
      "Epoch 20/25\n",
      "217/217 [==============================] - 5s 25ms/step - loss: 0.1739 - accuracy: 0.9440 - val_loss: 0.4996 - val_accuracy: 0.9167\n",
      "Epoch 21/25\n",
      "217/217 [==============================] - 5s 25ms/step - loss: 0.1490 - accuracy: 0.9495 - val_loss: 0.2472 - val_accuracy: 0.9417\n",
      "Epoch 22/25\n",
      "217/217 [==============================] - 5s 24ms/step - loss: 0.1508 - accuracy: 0.9508 - val_loss: 0.4806 - val_accuracy: 0.9000\n",
      "Epoch 23/25\n",
      "217/217 [==============================] - 5s 25ms/step - loss: 0.1557 - accuracy: 0.9521 - val_loss: 0.3244 - val_accuracy: 0.9083\n",
      "Epoch 24/25\n",
      "217/217 [==============================] - 5s 25ms/step - loss: 0.1478 - accuracy: 0.9553 - val_loss: 0.2610 - val_accuracy: 0.9083\n",
      "Epoch 25/25\n",
      "217/217 [==============================] - 6s 27ms/step - loss: 0.1335 - accuracy: 0.9573 - val_loss: 0.2476 - val_accuracy: 0.9333\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x7ff9d5dbdd20>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-3)\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "acc_metric = tf.keras.metrics.CategoricalAccuracy(name=\"accuracy\")\n",
    "model.compile(optimizer, loss=loss_fn, metrics=[acc_metric])\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    epochs=25,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.ModelCheckpoint(filepath=\"final_model\", monitor='val_accuracy', mode='max', save_best_only=True)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2278 - accuracy: 0.9417\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"final_model/\")\n",
    "loss, acc = model.evaluate(val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### From Logits to Labels\n",
    "\n",
    "Your network will output logits as long as you use `tf.keras.losses.CategoricalCrossentropy` as loss function.\n",
    "However, if you want to manually infer you have to calculate the predicted label based on the logits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_logit = model.predict(val_ds)\n",
    "y_labels = [labels for _, labels in val_ds.unbatch()]\n",
    "y_labels = tf.argmax(y_labels, axis=1)\n",
    "\n",
    "\n",
    "# @student: pred_logit are the predicted logits of your model, while y_labels are the ground truth labels.\n",
    "# calculate the labels from the logits\n",
    "pred_softmax = tf.math.softmax(pred_logit)\n",
    "pred_labels = tf.argmax(pred_softmax, -1)\n",
    "\n",
    "\n",
    "confusion_matrix = tf.math.confusion_matrix(y_labels, pred_labels, num_classes=NUM_CLASSES)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix.numpy())\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}