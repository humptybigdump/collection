{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spflow -q\n",
    "!pip install matplotlib -q  \n",
    "!pip install numpy -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "- Network Polynomials\n",
    "- Sum Product Networks \n",
    "    - Overview\n",
    "    - Valid or not\n",
    "    - Inference\n",
    "        - Probabilities\n",
    "        - Marginals\n",
    "        - Conditional Probabilities\n",
    "        - Sampling\n",
    "        - Most Probable Explanation (MPE)\n",
    "    - Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "# Set numpy precision\n",
    "np.set_printoptions(precision=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Polynomials and Joint Distributions\n",
    "\n",
    "We start with an example for a joint distribution table. Our simple example has four random variables $X = (X_1, X_2, X_3, X_4)$ each of binary scope ($X_i \\in \\{0, 1\\}$) with the following probabilities.\n",
    "\n",
    "| $X_1$ | $X_2$ | $X_3$ | $X_4$ | P(X) |\n",
    "|---|---|---|---|------------------|\n",
    "| 0 | 0 | 0 | 0 | 0.1  |\n",
    "| 0 | 0 | 0 | 1 | 0.0  |\n",
    "| 0 | 0 | 1 | 0 | 0.0  |\n",
    "| 0 | 0 | 1 | 1 | 0.2  |\n",
    "| 0 | 1 | 0 | 0 | 0.25 |\n",
    "| 0 | 1 | 0 | 1 | 0.05 |\n",
    "| 0 | 1 | 1 | 0 | 0.0  |\n",
    "| 0 | 1 | 1 | 1 | 0.0  |\n",
    "| 1 | 0 | 0 | 0 | 0.0  |\n",
    "| 1 | 0 | 0 | 1 | 0.0  |\n",
    "| 1 | 0 | 1 | 0 | 0.0  |\n",
    "| 1 | 0 | 1 | 1 | 0.0  |\n",
    "| 1 | 1 | 0 | 0 | 0.1  |\n",
    "| 1 | 1 | 0 | 1 | 0.05 |\n",
    "| 1 | 1 | 1 | 0 | 0.05 |\n",
    "| 1 | 1 | 1 | 1 | 0.2  |\n",
    "\n",
    "Given the partition table, we can construct a network polynomial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "Construct the network polynomial (in a python function)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "Compute the probabilities of the following random variable instantiations by using the network polynomial \n",
    "\n",
    "| $X_1$ | $X_2$ | $X_3$ | $X_4$ | \n",
    "|---|---|---|---|\n",
    "| 1 | 1 | 1 | 1 |\n",
    "| 1 | 0 | 0 | 0 |\n",
    "| 0 | 0 | 0 | 1 |\n",
    "| 0 | 0 | 0 | 0 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "Use the network polynomial to compute the marginal distribution $P(X_1 = 1, X_2 = 1, X_3 = 1)$. This means we have no information given on $X_4$. How can we use the network polynomial to do so?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "What happens when we marginalize over all variables, meaning we insert ($x_1, \\overline{x}_1, x_2, \\overline{x}_2, x_3, \\overline{x}_3, x_4, \\overline{x}_4) = (1, 1, 1, 1, 1, 1, 1, 1)$ into the network polynomial?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sum Product Networks\n",
    "\n",
    "Sum Product Networks are (deep) probabilistic models that encode a joint probability distribution (JPD) over a set of random variables. SPNs allow different inference types in an efficient way and can be trained by gradient based methods, expectation maximization. Even structure learning algorithms exist that make it obsolete to specify the network structure a priori.\n",
    "\n",
    "SPNs factorize the network polynomial of the underlying distribution and enable efficient computations of multiple queries possible: \n",
    "* **Probabilities/Likelihoods**\n",
    "* **Magignals** \n",
    "* **Conditional Probabilities**\n",
    "* approx. **Most Probable Explanation (MPE)**\n",
    "* **Sampling**.\n",
    "\n",
    "Every of these operations can be done in linear time of the network, where the size of the network is determined by the number of edges.\n",
    "\n",
    "In the following, we will build an SPN in spflow and examine different inference types.\n",
    "\n",
    "![alt text](SPN1.png \"SPN1\")\n",
    "\n",
    "## When is an SPN valid?\n",
    "In order to be valid, meaning the SPN represents a correct joint probability distribution over its variables, it is sufficient to check two properties:\n",
    "\n",
    "#### At Sum Nodes\n",
    "Each child of the sum node has to have the same scope!\n",
    "\n",
    "#### At Product Nodes\n",
    "Each child of the product node has to have a disjoint scope of the other childs.\n",
    "\n",
    "The scope of leafes are defined as follows:\n",
    "\\begin{align}\n",
    "sc(X_i) &= \\{ X_i \\} \\\\\n",
    "sc(\\overline{X}_i) &= \\{ X_i \\}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPFlow\n",
    "\n",
    "SPFlow is a Sum Product Network framework in python: https://github.com/SPFlow/SPFlow.git.\n",
    "If you want to get in touch with SPNs, you might try it out, since it offer multiple inference mechanisms, as well as an implementation of the structure learning algorithm LearnSPN. Let's get started by building the same network, we already investigated. \n",
    "\n",
    "## Building an SPN in spflow\n",
    "\n",
    "\n",
    "![alt text](SPN1.png \"SPN1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import spflow\n",
    "import spn\n",
    "from spn.structure.leaves.parametric.Parametric import Bernoulli\n",
    "from spn.structure.Base import Product, Sum, assign_ids, rebuild_scopes_bottom_up\n",
    "from spn.algorithms.Inference import log_likelihood, likelihood\n",
    "from spn.io.Graphics import plot_spn\n",
    "from numpy.random.mtrand import RandomState\n",
    "from spn.algorithms.Sampling import sample_instances\n",
    "from spn.algorithms.MPE import mpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = Bernoulli(p=1.0, scope=0)\n",
    "X1_ = Bernoulli(p=0.0, scope=0)\n",
    "\n",
    "X2 = Bernoulli(p=1.0, scope=1)\n",
    "X2_ = Bernoulli(p=0.0, scope=1)\n",
    "\n",
    "X3 = Bernoulli(p=1.0, scope=2)\n",
    "X3_ = Bernoulli(p=0.0, scope=2)\n",
    "\n",
    "# Here you can change the weights if you like and see what happens.\n",
    "sum1 = Sum(children=[X2, X2_], weights=[0.3, 0.7])\n",
    "sum2 = Sum(children=[X2, X2_], weights=[0.5, 0.5])\n",
    "sum3 = Sum(children=[X3, X3_], weights=[0.6, 0.4])\n",
    "sum4 = Sum(children=[X3, X3_], weights=[0.9, 0.1])\n",
    "\n",
    "Prod1 = Product(children=[X1, sum1, sum3])\n",
    "Prod2 = Product(children=[X1_, sum2, sum4])\n",
    "\n",
    "# Here you can change the weights if you like and see what happens.\n",
    "SPN = Sum(children=[Prod1, Prod2], weights=[0.8, 0.2])\n",
    "\n",
    "# Call these to reorganize the indicies internally.\n",
    "assign_ids(SPN)\n",
    "rebuild_scopes_bottom_up(SPN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the SPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spn(SPN, 'SPN.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a next step, we want to do the same computation as before, namely computing the probabilities the SPN represents:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Probabilities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = np.array([0, 0, 0]).reshape(1, 3)\n",
    "print(\"P(X1 = 0, X2 = 0, X3 = 0) = \" + str(likelihood(SPN, input_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "Compute the full joint probability distribution table by calling the likelihood function of spflow. In other words: Compute the probability for each combination of variable assignments on $X_1, X_2$ and $X_3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marginalization of Variables\n",
    "\n",
    "Now let's examine how marginal probabilities can be computed in the spflow network. While we have to set \"ones\" for every unknown indicator in a classical SPN, things are slightly different in spflow: Here we have to give \"np.nan\" as a value for the referring random variable and spflow takes care of the rest for us. Let's try it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([1, np.nan, np.nan]).reshape(-1, 3)\n",
    "print('P(X1 = 1) = {}'.format(likelihood(SPN, data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, the marginal probability $P(X_1 = 1)$ equals the previous probability computed by the network polynomial or the joint distribution table.\n",
    "\n",
    "spflow can compute multiple queries of this type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a numpy data array form a given list\n",
    "data = np.array([1, np.nan, np.nan, \n",
    "                 0, np.nan, np.nan, \n",
    "                 np.nan, 0, np.nan, \n",
    "                 np.nan, 1, np.nan]).reshape(-1, 3)\n",
    "print(\"input data:\")\n",
    "print(data)\n",
    "print()\n",
    "\n",
    "print(\"Marginal Probabilities:\")\n",
    "res = likelihood(SPN, data)\n",
    "\n",
    "print('P(X1 = 1) = {}'.format(res[0]))\n",
    "print('P(X1 = 0) = {}'.format(res[1]))\n",
    "print('P(X2 = 0) = {}'.format(res[2]))\n",
    "print('P(X2 = 1) = {}'.format(res[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Conditional Probabilities\n",
    "\n",
    "Assume that we know that $X_1 = 1$. Then we might query for the probability of $X_2 = 1, X_3 = 0$, given the fact that $X_1 = 1$ holds. Therefore we want to compute the conditional probability:\n",
    "\n",
    "\\begin{align}\n",
    "P(X_2 = 1, X_3 = 0 \\mid X_1 = 1)\n",
    "\\end{align}\n",
    "\n",
    "This query can be done by using the definition of conditional probabilities:\n",
    "\\begin{align}\n",
    "P(X = x \\mid Y = y) = \\frac{P(X = x, Y = y)}{P(Y = y)} \n",
    "\\end{align}\n",
    "\n",
    "In our context this means:\n",
    "\\begin{align}\n",
    "P(X_2 = 1, X_3 = 0 \\mid X_1 = 1) = \\frac{P(X_1 = 1, X_2 = 1, X_3 = 0)}{P(X_2 = 1, X_3 = 0)} \n",
    "\\end{align}\n",
    "\n",
    "\n",
    "Thus we can compute P(X_2 = 1, X_3 = 0) in an upward pass through the network while marginalizing out $X_1$ (summing all possible instantiations of $X_1$), then proceed by computing $P(X_1 = 1, X_2 = 1, X_3 = 0)$ as a sinlge upward pass and then divide the gained probabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input for P(X1 = 1, X2 = 1, X3 = 0)\n",
    "input_data = np.array([1, 1, 0]).reshape(1, 3)\n",
    "\n",
    "# Input for P(X2 = 1, X3 = 0)\n",
    "input_data2 = np.array([np.nan, 1, 0]).reshape(1, 3)\n",
    "\n",
    "p_xy = likelihood(SPN, input_data)\n",
    "p_y = likelihood(SPN, input_data2)\n",
    "\n",
    "print(p_xy / p_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling from the SPN\n",
    "\n",
    "For a fixed SPN, we can also generate samples from the distribution the SPN represents. This is the reason why SPNs are called \"Generative Models\". There exist many other types of generative models and there is major interest in such models, since they are promising for tasks as image completion or similar tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# number if samples\n",
    "N = 10000\n",
    "\n",
    "data_empty = np.array([ np.nan, np.nan, np.nan ] * N).reshape(-1, 3)\n",
    "\n",
    "# Generate \n",
    "samples = sample_instances(SPN, data_empty, RandomState(0))\n",
    "\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if the empiric occurences match the probabilities the SPN computes. If we count all samples that have $X_1 = 1$ in them, then we should sum to 0.8, since it is the marginal distribution of the SPN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_ones = 0\n",
    "count_zeros = 0\n",
    "for s in samples:\n",
    "    if np.isclose(s[0], 1.0):\n",
    "        count_ones = count_ones + 1\n",
    "    elif np.isclose(s[0], 0.0):\n",
    "        count_zeros = count_zeros + 1\n",
    "    else:\n",
    "        # Should never happen!\n",
    "        print(\"Error!\")\n",
    "        print(s)\n",
    "        print()\n",
    "        \n",
    "total_count = count_ones + count_zeros\n",
    "print(\"relative occurence for X1 = 1:  \" + str(count_ones / total_count))\n",
    "print(\"relative occurence for X1 = 0:  \" + str(count_zeros / total_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the relative occurences of the variables match the marginal distribution of the SPN. If we just count the occurences of a single variable constellation or instantiation, e.g. $(X_1, X_2, X_3) = (1, 1, 1)$, then we should get the probability that the SPN computes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "count_other = 0\n",
    "for s in samples:\n",
    "    if np.array_equal(s, np.array([1, 1, 1]).reshape(3,)):\n",
    "        count = count + 1\n",
    "    else:\n",
    "        count_other = count_other + 1\n",
    "        \n",
    "total_count = count + count_other\n",
    "\n",
    "print(\"relative occurence for X = (1, 1, 1):  \" + str(count / total_count))\n",
    "print(\"relative occurence for other X:        \" + str(count_other / total_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the value 0.1432 is approximately $P(X_1 = 1, X_2 = 1, X_3 = 1) = 1.44$, which fits our expectations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Probable Explanation (MPE)\n",
    "\n",
    "Let's try the Most Probable Explanation (MPE) Inference in our network. If we set $X_1 = 1$, then we should be able to complete $X2$ and $X3$ with MPE inference, as explained in the spn lecture. The MPE algorithm in SPNs does the following:\n",
    "\n",
    "1. Replace all sums with max nodes. The weights are kept!\n",
    "2. Compute an upward pass where unknown variables (in this case $X_2$ and $X_3$) are marginalize out\n",
    "3. Do a backward pass and on eahc max node chose the child with the highest upward value. On Products, go down to every child!\n",
    "\n",
    "If the SPN is valid, then this leads to a variable assignment which is not ambiguous and therefore to a valid \"explanation\" of the observed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([1.0, np.nan, np.nan]).reshape(-1, 3)\n",
    "print(\"Input data:\")\n",
    "print(data)\n",
    "print()\n",
    "\n",
    "# Perform MPE Inference.\n",
    "completed = mpe(SPN, data)\n",
    "\n",
    "print(\"Completed data\")\n",
    "print(completed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the most likely explanation when we make the observation $X_1 = 1$ is that the unonserved variables $X_2, X_3$\n",
    "have the values $(X_2, X_3) = (0, 1)$. In this case this is the correct answer, since probability of the assignment $(X_1, X_2, X_3) = (1, 0, 1)$ equals $P(X_1 = 1, X_2 = 0, X_3 = 1) = 0.336$, which is the highest probability value when we set $X_1$ as fixed. It is even the highest probability in the computed distribution table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excersice 6 \n",
    "What is the most probable explanation for $X_2 = 0, X_3 = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spflow offers a lot more than you have seen in this exercises. For instance an implementation of the structure learn algorithm LeanrSPN is included as well, which is quite easy to use in simple scenarios. Additional information here:\n",
    "https://github.com/SPFlow/SPFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "Sum Product Networks provide:\n",
    "- A fully probabilistic learning and inference model\n",
    "- Efficient inference algorithms\n",
    "    - Computation of probabilities\n",
    "    - Computation of conditional probabilities\n",
    "    - Computation of marginal probabilities\n",
    "    - Approximate most probable explanation (MPE)\n",
    "    - Sampling \n",
    "- Parameter Learning\n",
    "    - Expectation Maximization\n",
    "    - Gradient Descent, Hard Gradient Descent\n",
    "        - Generative vs. Discriminative\n",
    "- Structure Learning \n",
    "    - Greedy Cluster and Split algorithm "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_ml",
   "language": "python",
   "name": "venv_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
