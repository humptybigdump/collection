{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coin Flip\n",
    "\n",
    "![Coin flip](coin_flip.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates the obligatory coin flip example for a Bayesian model setup and inference. It is structured as follows:\n",
    "\n",
    "1. Description of the problem setting\n",
    "2. Initial model setup with code\n",
    "3. Investigation of different prior distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary libraries, in particular the binomial and Beta distributions from Scipy\n",
    "import numpy as np\n",
    "from scipy.stats import binom, beta\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Interactive plotting and style\n",
    "%matplotlib widget\n",
    "plt.close('all')\n",
    "plt.style.use('bmh')\n",
    "\n",
    "# Layout of our slider and text box widgets\n",
    "slider_layout = {'style': {'description_width': 'initial'},\n",
    "                 'layout': widgets.Layout(width='35%'),\n",
    "                 'continuous_update': True} \n",
    "\n",
    "textbox_layout = {'style': {'description_width': 'initial'},\n",
    "                  'layout': widgets.Layout(width='20%'),\n",
    "                  'continuous_update': False}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Setting\n",
    "\n",
    "We encounter a weird-looking coin, for which we wonder if it is \"fair\", meaning that heads and tails occur equally often. The law of large numbers tells us that we can find this *bias-weighting* by flipping the coin infinitely often and analyzing the ratio of heads/tails. Let us see what we can infer in a Bayesian setting from flipping the coin a finite number of times.\n",
    "\n",
    "More mathematically, this is a **Bernoulli** trial experiment. For $n$ independent flips of a coin with bias-weighting $\\theta$, the probability of observing $y$ heads follows a **binomial** distribution,\n",
    "\n",
    "$$ p(y | n, \\theta) = Bin(y | n,\\theta) \\propto \\theta^y (1-\\theta)^{n-y}, $$\n",
    "\n",
    "where the constant of proportionality does not depend on $y$.\n",
    "\n",
    "Let us visualize such a distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to plot binomial pmf on given axis object\n",
    "def plot_binomial_pmf(num_samples, success_probability, mpl_axis):\n",
    "    sample_space = np.arange(0, num_samples+1)\n",
    "    # Compute the probability mass function\n",
    "    pmf_values = binom.pmf(sample_space, num_samples, success_probability)\n",
    "\n",
    "    mpl_axis.clear()\n",
    "    mpl_axis.set_title(rf'Binomial Distribution: $n = {num_samples}$, $\\theta = {success_probability}$')\n",
    "    mpl_axis.set_xlabel(r'$y$')\n",
    "    mpl_axis.set_ylabel(r'$P_{bin}(y | n,\\theta)$')\n",
    "    mpl_axis.set_xlim(-0.5, num_samples + 0.5)\n",
    "    mpl_axis.set_ylim(0, 1.1*np.max(pmf_values))\n",
    "    mpl_axis.plot(sample_space, pmf_values, marker='o', linestyle='', color='royalblue')\n",
    "\n",
    "# Construct sliders for interactive visualization\n",
    "slider_num_samples = widgets.IntSlider(value=10, min=0, max=100, step=1,\n",
    "                                       description='Number of samples n:',\n",
    "                                       **slider_layout)\n",
    "slider_success_probability = widgets.FloatSlider(value=0.5, min=0, max=1, step=0.05,\n",
    "                                                 description='Success probability \\u03B8:',\n",
    "                                                 **slider_layout)\n",
    "\n",
    "# Generate interactive plot\n",
    "_, ax = plt.subplots()\n",
    "interactive_plot = widgets.interact(plot_binomial_pmf,\n",
    "                                    num_samples=slider_num_samples,\n",
    "                                    success_probability=slider_success_probability,\n",
    "                                    mpl_axis=widgets.fixed(ax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Model formulation\n",
    "\n",
    "Initially, we assume that we do not know anything about the suspicious coin. This means we assign a **uniform prior distribution**,\n",
    "\n",
    "$$ p(\\theta) = Uni(0,1) $$\n",
    "\n",
    "We have further seen that the **likelihood** of observing $y$ heads (our data) out of $n$ flips follows a binomial distribution. Hence, we may write\n",
    "\n",
    "$$ p(y | \\theta) \\propto \\theta^y (1-\\theta)^{n-y}. $$\n",
    "\n",
    "Note that we have omitted $n$ in the explicit dependency formulation of the likelihood. This is because we assume $n$ to be a fixed parameter or *covariate* of the Bayesian model.\n",
    "\n",
    "Invoking Bayes theorem, we can construct a **posterior** distribution\n",
    "\n",
    "$$ p(\\theta | y) \\propto p(y | \\theta) p(\\theta) \\propto \\theta^y (1-\\theta)^{n-y},\\quad \\theta\\in [0,1], $$\n",
    "\n",
    "where the constant of proportionality does not depend on $\\theta$. Note that in contrast to the discrete binomial distribution, the posterior is defined in terms of the continuous variable $\\theta$. More specifically, it represents a $\\beta$-distribution, which generally reads\n",
    "\n",
    "$$ Beta(\\theta | a, b) \\propto \\theta^{a-1} (1-\\theta)^{b-1} .$$\n",
    "\n",
    "Let us again visualize this distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to plot beta pdf on given axis object\n",
    "def plot_beta_pdf(param_a, param_b, mpl_axis):\n",
    "    sample_space = np.linspace(0.01, 0.99, num=1001, endpoint=True)\n",
    "    # Compute probability density function\n",
    "    pdf_values = beta.pdf(sample_space, param_a, param_b)\n",
    "\n",
    "    mpl_axis.clear()\n",
    "    mpl_axis.set_title(rf'Beta Distribution: $a = {param_a:.1f}$, $b = {param_b:.1f}$')\n",
    "    mpl_axis.set_xlabel(r'$\\theta$')\n",
    "    mpl_axis.set_ylabel(r'$p_{beta}(\\theta | a, b)$')\n",
    "    mpl_axis.set_xlim(0, 1)\n",
    "    mpl_axis.set_ylim(0, 1.1 * np.max(pdf_values))\n",
    "    mpl_axis.plot(sample_space, pdf_values, color='royalblue')\n",
    "    \n",
    "# Construct sliders for interactive visualization\n",
    "slider_param_a = widgets.FloatSlider(value=1, min=0.1, max=10, step=0.1,\n",
    "                                     description=\"Parameter a:\",\n",
    "                                     **slider_layout)\n",
    "\n",
    "slider_param_b = widgets.FloatSlider(value=1, min=0.1, max=10, step=0.1,\n",
    "                                     description=\"Parameter b:\",\n",
    "                                     **slider_layout)\n",
    "\n",
    "# Generate interactive plot\n",
    "_, ax = plt.subplots()\n",
    "interactive_plot = widgets.interact(plot_beta_pdf,\n",
    "                                    param_a=slider_param_a,\n",
    "                                    param_b=slider_param_b,\n",
    "                                    mpl_axis=widgets.fixed(ax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, we can identify the posterior as $Beta(\\theta | a=y+1, b=n-y+1)$.\n",
    "With this result, we can have a look at what we can learn from repeated coin flips. Let us therefore assume we have data for a coin with $\\theta=0.4$. We can explore how our knowledge of theta develops with increasing sample size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data representing 1000 coin flips with bias-weighting 0.4\n",
    "NUM_SAMPLES_MAX = 1000\n",
    "BIAS_WEIGHTING = 0.4\n",
    "\n",
    "trial_data_raw = binom.rvs(n=1, p=BIAS_WEIGHTING, size=NUM_SAMPLES_MAX)\n",
    "trial_data_accumulated = np.cumsum(trial_data_raw)\n",
    "trial_data_accumulated = np.insert(trial_data_accumulated, 0, 0)\n",
    "\n",
    "# Plot function for the posterior with a given sample size\n",
    "def plot_posterior_pdf_uniform_prior(num_samples, trial_data_accumulated, mpl_axis):\n",
    "    sample_space = np.linspace(0.01, 0.99, num=1000, endpoint=True)\n",
    "    trial_successes = trial_data_accumulated[num_samples]\n",
    "    pdf_values = beta.pdf(sample_space, trial_successes+1, num_samples-trial_successes+1)\n",
    "\n",
    "    mpl_axis.clear()\n",
    "    mpl_axis.set_title(rf'Posterior Distribution: $n = {num_samples}$')\n",
    "    mpl_axis.set_xlabel(r'$\\theta$')\n",
    "    mpl_axis.set_ylabel(r'$p_{post}(\\theta | y)$')\n",
    "    mpl_axis.set_xlim(0, 1)\n",
    "    mpl_axis.set_ylim(0, 1.1 * np.max(pdf_values))\n",
    "    mpl_axis.plot(sample_space, pdf_values, color='royalblue')\n",
    "    mpl_axis.axvline(BIAS_WEIGHTING, color='black', linestyle='--', alpha=0.5)\n",
    "    mpl_axis.text(BIAS_WEIGHTING+0.01, 1.035, 'true value')\n",
    "\n",
    "# Create an interactive textbox for sample size adjustment\n",
    "textbox_num_samples = widgets.BoundedIntText(value=0, min=0, max=NUM_SAMPLES_MAX, step=1,\n",
    "                                             description='Number of samples n:',\n",
    "                                             **textbox_layout)\n",
    "\n",
    "# Generate interactive plot\n",
    "_, ax = plt.subplots()\n",
    "interactive_plot = widgets.interact(plot_posterior_pdf_uniform_prior,\n",
    "                                    num_samples=textbox_num_samples,\n",
    "                                    trial_data_accumulated = widgets.fixed(trial_data_accumulated),\n",
    "                                    mpl_axis=widgets.fixed(ax))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially, meaning without the inclusion of any data, $\\theta$ is uniformly distributed as prescribed through the prior. With the inclusion of an increasing number of samples, we obtain a curve with a bell-like curve. The more data we include, the closer (ideally) the center of the distribution gets to the true $\\theta$. Moreover, the variance is reduced through the introduction of additional data samples."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
