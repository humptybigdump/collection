{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your own logistic regression model\n",
    "\n",
    "This time it's your turn to create a logistic regression model. The [dataset](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)), that we're going to work with, contains diagnostic information about breast cancer. The medical features of individual tumors like size, shape and smoothness were measured and were labeled as maligant(0) or benign(1).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
      "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
      "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
      "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
      "       'smoothness error', 'compactness error', 'concavity error',\n",
      "       'concave points error', 'symmetry error', 'fractal dimension error',\n",
      "       'worst radius', 'worst texture', 'worst perimeter', 'worst area',\n",
      "       'worst smoothness', 'worst compactness', 'worst concavity',\n",
      "       'worst concave points', 'worst symmetry', 'worst fractal dimension'],\n",
      "      dtype='object')\n",
      "15    0\n",
      "16    0\n",
      "17    0\n",
      "18    0\n",
      "19    1\n",
      "Name: target, dtype: int32\n",
      "['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "data = load_breast_cancer(as_frame=True)\n",
    "features = data[\"data\"]\n",
    "feature_names = data[\"feature_names\"]\n",
    "labels = data[\"target\"]\n",
    "label_names = data[\"target_names\"]\n",
    "\n",
    "print(features.columns)\n",
    "print(labels[15:20])\n",
    "print(label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data exploration\n",
    "\n",
    "Let's have a closer look on the distribution of the data. How many tumors are there in the dataset overall? Also find out how many tumors were classified as malignant and how many as benign. Is this a well balanced dataset or is one kind overrepresented?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we should deal with the features and decide if we have to preprocess them or use them as they are. What are the datatypes of the features? If they are non-numerical we need to convert them to quantify them. Are there any missing values or NaNs(not-a-number)? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at a specific column. What is the mean and the standard deviation of the \"mean radius\" of the tumors? Can you test if there is a correlation between \"mean radius\", \"mean perimeter\" and \"mean area\"?\n",
    "\n",
    "Hint: You can access a sub-dataframe of a pandas-dataframe by giving it a list of columns as its index:\n",
    "\n",
    "```my_subframe = my_dataframe[[\"column1\",\"column2\",\"column3\"]]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "To validate your model in the end you will need a separate test-set. Therefore you should split your data in two random subset for training and testing now. Your test-set should contain 15% of your total dataset. Also make sure, that your subsets have the expected sample-size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize the training-data and the test-data with the mean and the standard-deviation of the training-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training\n",
    "\n",
    "Now it's finally time to create your model and fit it to the data in your training-set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate your model by a metric of your choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally visualize the results of your prediction in a confusion-matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now we classify the tumors straight up according to which one has the higher probability, the decision-treshold is 0.5, which makes sense in most cases. In other cases we can improve the model by adjusting the decision-threshold, e.g. a tumor has to have a probability of 90% to be classified as benign otherwise we will classify it as malignant. This might even make sense, if it lowers the accuracy of the model, especially in this example. Why?\n",
    "\n",
    "The next code-box offers a way to play around with different decision-thresholds. Uncomment the variables and update them with your variable-names have a look at how the threshold affects the prediction outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_scaled = your_X_test_scaled\n",
    "# y_test = your_test_scaled\n",
    "# model = your_model\n",
    "\n",
    "\n",
    "pred_proba = model.predict_proba(X_test_scaled)\n",
    "threshold_list = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "for i in threshold_list:\n",
    "    print (f\"\\n******** For i = {i: .1f} ******\")\n",
    "    Y_test_pred = (pred_proba[:,1] > i).astype(int)\n",
    "    test_accuracy = metrics.accuracy_score(y_test, Y_test_pred)\n",
    "    print(f\"Our testing accuracy is {test_accuracy: .2f}\")\n",
    "\n",
    "    print(confusion_matrix(y_test, Y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Congratulations on building your own logistic regression model!**"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "09479eb26e9c2dfedc5b750a5f4404419e7e88fc081728cd256fd3e13a96b5b1"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
