{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e42763e",
   "metadata": {},
   "source": [
    "# Stochastic Simulation\n",
    "\n",
    "*Winter Semester 2024/25*\n",
    "\n",
    "17.01.2025\n",
    "\n",
    "Prof. Sebastian Krumscheid<br>\n",
    "Assistants: Stjepan Salatovic, Louise Kluge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5187ec",
   "metadata": {},
   "source": [
    "<h3 align=\"center\">\n",
    "Exercise sheet 09\n",
    "</h3>\n",
    "\n",
    "---\n",
    "\n",
    "<h1 align=\"center\">\n",
    "QMC and LH sampling\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f636d6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from scipy.special import erf\n",
    "from scipy.special import factorial\n",
    "from scipy.stats.qmc import Sobol\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import linregress\n",
    "from typing import Callable, Tuple\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from ipywidgets import interact\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a82b0a91-6d0f-436d-bc1e-bfc75cc60fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('axes', labelsize=14)     # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=12)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=12)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=14)    # legend fontsize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce01de2-1535-48d7-a583-b3390d3f377b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "**On randomized QMC formulas**\n",
    "\n",
    "Let $P=\\{X_1,\\dots,X_N\\}$, $X_i\\in \\mathbb{R}^d$, be a low-discrepancy sequence and denote the QMC quadrature by $\\hat{\\mu}_{QMC}=\\frac{1}{N}\\sum_{i=1}^N\\psi(X_i)$. We are interested in estimating the error $|\\mu-\\hat{\\mu}_{QMC}|$. Notice that since the points $X_i$ are _not_ i.i.d., we can't use a variance estimator or a CLT as in MC. In order to be able to do this, we can _randomize_ the QMC formula. Let $U_j\\overset{iid}{\\sim}\\mathcal{U}([0,1]^d)$, $j=1,\\dots,K$. If the set of points $P$ is a low discrepancy point set, so is the _randomly shifted point set_ $P_{U,j}:=\\{ \\{X_1+U_j\\},\\dots,\\{X_N+U_j\\}\\}$, where $\\{\\cdot\\}$ represents the fractional part. Moreover, since $U_j\\overset{iid}{\\sim}\\mathcal{U}([0,1]^d)$, so is $\\{X_i+U_j\\}$ for any $i=1,\\dots,N$. Thus, we can apply a Monte Carlo estimator on $\\hat{\\mu}_{QMC}$, by computing $K$ independent estimators $\\hat{\\mu}_{QMC}^{j}$ for each of the randomly shifted point sets $P_{U,j},$ and then averaging out the estimators. This in turn results in an unbiased estimator $\\hat{\\hat{\\mu}}_{QMC}$ of $\\mu$, for which we can use the standard variance estimator and CLT results. C.f the lecture notes for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0da9850-c739-4399-beb0-a06ee083f726",
   "metadata": {},
   "source": [
    "**On generating low-discrepany sequences**\n",
    "\n",
    "To use the Sobol sequence generator from [`scipy.stats.qmc`](https://docs.scipy.org/doc/scipy/reference/stats.qmc.html), you can create an instance of the [`Sobol`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.qmc.Sobol.html) class with the desired dimension, and then use its `random` method to generate samples. Here's an example of how to use it:\n",
    "\n",
    "```python\n",
    "# Create a Sobol sequence generator\n",
    "sobol = Sobol(d=2)\n",
    "\n",
    "# Generate samples\n",
    "N = 1000  # Number of samples\n",
    "samples = sobol.random(N)\n",
    "```\n",
    "\n",
    "**Note:** The Sobol sequence is automatically randomized through the use of the `scramble` keyword argument for the [`Sobol`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.qmc.Sobol.html) class. By default, this is set to `True`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c2314d-54c4-4ad9-9b30-48b5d1337362",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "Consider the problem of approximating the integral\n",
    "\\begin{equation*}\n",
    "I_d(f) = \\int_{{[0,1]}^d}f(\\mathbf{x})\\,d\\mathbf{x}\\;,\n",
    "\\end{equation*}\n",
    "for some given function $f\\colon{[0,1]}^d\\to \\mathbb{R}$. In this exercise we\n",
    "will investigate the approximation qualities of different estimators\n",
    "of $I_d(f)$ for various functions $f$, which differ mainly by their\n",
    "regularity. Specifically, for each function listed below address to the\n",
    "following points. Perform all computations at least for $d=2$ and\n",
    "$d=20$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c7dbc4-189d-4c4a-ac4a-46f869a7fa39",
   "metadata": {},
   "source": [
    "**List of functions**\n",
    "\n",
    "Investigate the approximation techniques for $I_d(f)$ mentioned above\n",
    "for the following functions $f\\colon {[0,1]^d}\\to \\mathbb{R}$, with\n",
    "$\\mathbf{x} = (x_1,\\dots, x_d)$. Please note that a testing suite with several of the function definitions listed below can be found [here](https://people.math.sc.edu/Burkardt/c_src/testpack/testpack.html).\n",
    "\n",
    "1. **Oscillatory function:**\n",
    "\t$f(\\mathbf{x}) = \\cos\\left( 2\\pi w_1 + \\sum_{j=1}^d c_j x_j\\right)$, with\n",
    "\t$c_j=9/d$, $w_1=\\frac{1}{2}$.\n",
    "\n",
    "\tExact solution:\n",
    "\t\\begin{equation*}\n",
    "\tI_d(f) = \\Re\\left(e^{i2\\pi w_1}\\prod_{j=1}^d \\frac{1}{ic_j}(e^{ic_j}-1)\\right)\\;,\n",
    "\t\\end{equation*}\n",
    "\twhere $i$ denotes the imaginary unit and $\\Re(z)$ the real part of\n",
    "\t$z\\in\\mathbb{C}$.\n",
    "\n",
    "2. **Product peak:**\n",
    "\t$f(\\mathbf{x}) = \\prod_{j=1}^d \\left( c_j^{-2} + \\left( x_j - w_j\n",
    "\t\\right)^2\\right)^{-1}$, with $c_j=7.25/d$ and $w_j=\\frac{1}{2}$.\n",
    "\n",
    "\tExact solution:\n",
    "\t\\begin{equation*}\n",
    "\tI_d(f) = \\prod_{j=1}^d c_j\\left(\\arctan(c_j(1-w_j)) + \\arctan(c_jw_j)\\right)\\;.\n",
    "\t\\end{equation*}\n",
    "\n",
    "3. **Gaussian:**\n",
    "\t$f(\\mathbf{x}) = \\exp\\left( - \\sum_{j=1}^d c_j^2 (x_j - w_j)^2 \\right)$,\n",
    "\twith $c_j=7.03/d$ and $w_j=\\frac{1}{2}$.\n",
    "\n",
    "\tExact solution:\n",
    "\t\\begin{equation*}\n",
    "\tI_d(f) =  \\prod_{j=1}^d \\frac{\\sqrt{\\pi}}{2c_j} \\Bigl(\\text{erf}\\bigl(c_j (1-w_j)\\bigr) + \\text{erf}(c_j w_j)\\Bigr)\\;.\n",
    "\t\\end{equation*}\n",
    "\n",
    "4. **Continuous function:**\n",
    "\t$f(\\mathbf{x}) = \\exp\\left( - \\sum_{j=1}^d c_j |x_j - w_j| \\right)$, with\n",
    "\t$c_j=2.04/d$ and $w_j=\\frac{1}{2}$.\n",
    "\n",
    "\tExact solution:\n",
    "\t\\begin{equation*}\n",
    "\tI_d(f) = \\prod_{j=1}^d \\frac{1}{c_j}\\left(2-e^{-c_j w_j}-e^{-c_j(1-w_j)}\\right)\\;.\n",
    "\t\\end{equation*}\n",
    "\n",
    "5. **Discontinuous function:** \n",
    "\t\\begin{equation*}\n",
    "\tf(\\mathbf{x}) =\n",
    "\t\\begin{cases} \n",
    "\t0 & \\text{if } x_1 > w_1 \\text{ or } x_2 > w_2 \\\\\n",
    "\t\\exp\\left( \\sum_{j=1}^d c_j x_j \\right) & \\text{otherwise},\n",
    "\t\\end{cases}\n",
    "\t\\end{equation*}\n",
    "\twith $c_j=4.3/d$,  $w_1=\\frac{\\pi}{4}$, and $w_2=\\frac{\\pi}{5}$.\n",
    "\n",
    "\tExact solution:\n",
    "\t\\begin{equation*}\n",
    "\tI_d(f) = \\frac{\\prod_{j=3}^d (e^{c_j}-1)}{\\prod_{j=1}^d c_j}(e^{c_1 w_1}-1)(e^{c_2 w_2}-1)\\;.\n",
    "\t\\end{equation*}\n",
    "\n",
    "6. **Volume of the simplex:** \n",
    "\t\\begin{equation*}\n",
    "\tf(\\mathbf{x}) =\n",
    "\t\\begin{cases} 1 & \\text{if } \\sum_{j=1}^d x_j \\leq 1 \\\\\n",
    "\t0 & \\text{otherwise.}\n",
    "\t\\end{cases} \n",
    "\t\\end{equation*}\n",
    "\n",
    "\tExact solution:\n",
    "\t\\begin{equation*}\n",
    "\tI_d(f) = \\frac{1}{d!}\\;.\n",
    "\t\\end{equation*}\n",
    "\n",
    "We have implemented all of the functions listed above using Python [classes](https://docs.python.org/3/tutorial/classes.html). Each class has a `function()` method (which evaluates $f$) and an `exact_solution()` method (which yields the exact solution $I_d(f)$).\n",
    "Here's a quick example of how to use them:\n",
    "\n",
    "```python\n",
    "# Create an instance of the Oscillatory problem for d=2\n",
    "problem = Oscillatory(d=2)\n",
    "\n",
    "# Evaluate the function at x=[0.1, 0.2]\n",
    "print(problem.function([0.1, 0.2]))\n",
    "\n",
    "# ... or at N=1000 random points\n",
    "N = 1000\n",
    "print(problem.function(np.random.rand(N, 2)))\n",
    "\n",
    "# Compute the exact solution\n",
    "print(problem.exact_solution())\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ae16932-7674-4e92-8e8f-40b23af3a24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Oscillatory:\n",
    "    def __init__(self, d, w1=0.5):\n",
    "        self.d = d\n",
    "        self.w1 = w1\n",
    "        self.c = 9.0 / d * np.ones(d)\n",
    "\n",
    "    def function(self, x):\n",
    "        x = np.atleast_2d(x)\n",
    "        return np.cos(2 * np.pi * self.w1 + np.sum(self.c * x, axis=1))\n",
    "\n",
    "    def exact_solution(self):\n",
    "        return np.real(np.exp(1j * 2 * np.pi * self.w1) * np.prod(1 / (1j * self.c) * (np.exp(1j * self.c) - 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ae49f22-ec3f-48fb-abb4-4dc9f15d52c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductPeak:\n",
    "    def __init__(self, d, w=0.5):\n",
    "        self.d = d\n",
    "        self.w = w\n",
    "        self.c = 7.25 / d * np.ones(d)\n",
    "\n",
    "    def function(self, x):\n",
    "        x = np.atleast_2d(x)\n",
    "        return np.prod(self.c**(-2) + (x - self.w)**2, axis=1)**(-1)\n",
    "\n",
    "    def exact_solution(self):\n",
    "        return np.prod(self.c * (np.arctan(self.c * (1 - self.w)) + np.arctan(self.c * self.w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dcb470cb-4ca6-48cb-a0bf-19d8d04f49d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gaussian:\n",
    "    def __init__(self, d, w=0.5):\n",
    "        self.d = d\n",
    "        self.w = w\n",
    "        self.c = 7.03 / d * np.ones(d)\n",
    "\n",
    "    def function(self, x):\n",
    "        x = np.atleast_2d(x)\n",
    "        return np.exp(-np.sum(self.c**2 * (x - self.w)**2, axis=1))\n",
    "\n",
    "    def exact_solution(self):\n",
    "        return np.prod(np.sqrt(np.pi) / (2 * self.c) * (erf(self.c * (1 - self.w)) + erf(self.c * self.w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e8374ae-0653-45f4-8f05-2763afacdffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Continuous:\n",
    "    def __init__(self, d, w=0.5):\n",
    "        self.d = d\n",
    "        self.w = w\n",
    "        self.c = 2.04 / d * np.ones(d)\n",
    "\n",
    "    def function(self, x):\n",
    "        x = np.atleast_2d(x)\n",
    "        return np.exp(-np.sum(self.c * np.abs(x - self.w), axis=1))\n",
    "\n",
    "    def exact_solution(self):\n",
    "        return np.prod(1 / self.c * (2 - np.exp(-self.c * self.w) - np.exp(-self.c * (1 - self.w))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e9e633b-dfbb-47ee-a53a-2b745fa6f598",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discontinuous:\n",
    "    def __init__(self, d, w1=np.pi/4, w2=np.pi/5):\n",
    "        self.d = d\n",
    "        self.w1 = w1\n",
    "        self.w2 = w2\n",
    "        self.c = 4.3 / d * np.ones(d)\n",
    "\n",
    "    def function(self, x):\n",
    "        x = np.atleast_2d(x)\n",
    "        return np.exp(np.sum(self.c * x, axis=1)) * (1 - ((x[:, 0] > self.w1) | (x[:, 1] > self.w2)))\n",
    "\n",
    "    def exact_solution(self):\n",
    "        return np.prod((np.exp(self.c) - 1)[2:]) / np.prod(self.c) * (np.exp(self.c[0] * self.w1) - 1) * (np.exp(self.c[1] * self.w2) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70a88b24-65ab-4d2e-ae61-9ddee5cd54e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplexVolume:\n",
    "    def __init__(self, d):\n",
    "        self.d = d\n",
    "\n",
    "    def function(self, x):\n",
    "        x = np.atleast_2d(x)\n",
    "        return (np.sum(x, axis=1) <= 1).astype(int)\n",
    "\n",
    "    def exact_solution(self):\n",
    "        return 1 / factorial(self.d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b7b953-f002-4db3-8502-5b3c231a7fb7",
   "metadata": {},
   "source": [
    "1. Implement a _crude Monte Carlo_ estimator to approximate the integral $I_d(f)$.\n",
    "Estimate the error using the central limit theorem (CLT). Plot both\n",
    "the exact error (c.f. exact solutions) and the CLT-based\n",
    "error estimate as functions of the number of used samples $M$, say,\n",
    "and estimate the convergence rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8ee00f7-9357-4180-b85c-52c19be75ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crude_monte_carlo(func: Callable, d: int, M: int) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Approximates the integral of a function over a d-dimensional unit hypercube using the crude Monte Carlo method.\n",
    "\n",
    "    Args:\n",
    "        func (callable): The function to integrate. It should accept a numpy array with shape (M, d) where M is the number of points and d is the dimension.\n",
    "        d (int): The dimension of the domain of integration.\n",
    "        M (int): The number of random points to generate for the Monte Carlo simulation.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the integral approximation and the standard error estimate.\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a7d112-599b-433c-a2a9-7b4fc587108d",
   "metadata": {},
   "source": [
    "2. Implement a _Latin Hypercube Sampling_ estimator using $N$\n",
    "points in the hypercube to approximate $I_d(f)$. Estimate the error using a sample variance estimator based on $K$\n",
    "repetitions of the Latin Hypercube Sampling estimator. Again, plot\n",
    "both the exact error and an asymptotic confidence interval based\n",
    "error estimate as functions of the number of points $N$, say, and\n",
    "estimate the convergence rate.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae394a77-425b-42ff-bb4b-2ca6d6dcd49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lhs(d: int, N: int) -> np.array:\n",
    "    \"\"\"\n",
    "    Generate a Latin Hypercube Sampling (LHS) design.\n",
    "\n",
    "    Args:\n",
    "        d (int): The number of dimensions or variables.\n",
    "        N (int): The number of sampling points.\n",
    "\n",
    "    Returns:\n",
    "        np.array: A numpy array of size N by d, where each row represents a sample and each column represents a dimension.\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "406f9bf2-b6d2-4a9d-a888-92714195c86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def latin_hypercube_sampling(func: Callable, d: int, N: int, K: int=20) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Approximates the integral of a function using the Latin Hypercube Sampling method.\n",
    "\n",
    "    Args:\n",
    "        func (callable): The function to integrate.\n",
    "        d (int): The dimension of the domain.\n",
    "        N (int): The number of LHS points to use.\n",
    "        K (int): The number of repetitions for error estimation.\n",
    "\n",
    "    Returns:\n",
    "        tuple: The integral approximation and the error estimate.\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78407540-a746-487b-a4d3-40ea3d021c3d",
   "metadata": {},
   "source": [
    "3. Implement a _Quasi Monte Carlo_ (QMC) estimator to\n",
    "approximate the integral $I_d(f)$. Use SciPy's Sobol method (hint on the top of this notebook) to\n",
    "generate Sobol sequences. Estimate the error using the CLT by estimating the variance with a\n",
    "_randomized QMC_. Once again, plot both the exact error and estimated error based on random shifts as functions of the number of $N$ and estimate the convergence rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "baffd751-86ae-4486-98b7-7d4c9677cc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quasi_monte_carlo(func: Callable, d: int, N: int, K: int=20) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Approximates the integral of a function using the Quasi Monte Carlo method with Sobol sequences.\n",
    "\n",
    "    Args:\n",
    "        func (callable): The function to integrate.\n",
    "        d (int): The dimension of the domain.\n",
    "        N (int): The number of Sobol sequence points to use.\n",
    "        K (int): The number of repetitions for error estimation.\n",
    "\n",
    "    Returns:\n",
    "        tuple: The integral approximation and the error estimate.\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e0d45d-76b7-4947-b09d-edfef6690da1",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "Consider the random boundary value problem (BVP)\n",
    "\\begin{equation*}\n",
    "  \\left\\{\n",
    "  \\begin{aligned}\n",
    "    \\bigl(a(x,\\omega) u'(x,\\omega)\\bigr)^\\prime &= 0\\;,\\quad \\text{in }(0,L)\\;,\\\\\n",
    "    u(0,\\cdot) &= 0\\;,\\\\\n",
    "    a(L,\\cdot) u'(L,\\cdot) &= 1\\;,\n",
    "  \\end{aligned}\n",
    "  \\right.\n",
    "\\end{equation*}\n",
    "where $\\omega$ represents an elementary random event, so that\n",
    "$a\\equiv a(x,\\omega)$ is a random field. The BVP is a simplified model\n",
    "for a linear beam of length $L$, which is fixed on one side ($x=0$)\n",
    "and free on the other at which a unit load is applied. Here, the\n",
    "random field $a$ models the beam's spatially varying uncertain\n",
    "material properties. We are interested in quantifying the resulting\n",
    "uncertainty on the beam's displacement at the free\n",
    "end-point. Specifically, we are interested in studying the expected\n",
    "value of the random variable\n",
    "\\begin{equation*}\n",
    "  Z\\equiv Z(\\omega) := u(L,\\omega) = \\int_0^L\\frac{1}{a(x,\\omega)}\\,dx\\;.\n",
    "\\end{equation*}\n",
    "However, $Z$ is usually not computable for a general elasticity\n",
    "coefficient $a$. Instead, we consider the computable, approximate\n",
    "random quantity of interest $Z_I$, which is obtained by approximating\n",
    "the integral by the midpoint rule on a uniform grid,\n",
    "\\begin{equation*}\n",
    "  Z_I \\equiv Z_I(\\omega) := h\\sum_{i=1}^{I-1}\\frac{1}{a\\bigl(x_i+\\frac{h}{2},\\omega\\bigr)}\\;,\n",
    "\\end{equation*}\n",
    "with $x_i = ih$, $i=0,\\dots, I\\in\\mathbb{N}$, and $h = L/I$.\n",
    "\n",
    "We are interested in approximating $\\mathbb{E}[Z_I]$ for $L=1$\n",
    "for two different elasticity coefficients:\n",
    "\n",
    "1. For $\\mu=1$ and $\\sigma=4$, let\n",
    "$$\n",
    "a_1(x,\\omega) = \\mu + \\frac{\\sigma}{\\pi^2}\\sum_{n=1}^d\\frac{\\cos(\\pi n x)}{n^2}Y_n(\\omega)\\;,\\quad\n",
    "    Y_n(\\omega)\\sim U(-1,1)\\text{ i.i.d.}\n",
    "$$\n",
    "\n",
    "\n",
    "2. For $a_2(x,\\omega) = \\exp\\bigl(\\kappa(x,\\omega)\\bigr)$, let\n",
    "$$\n",
    "\\kappa(x,\\omega) = x + \\sqrt{2}\\sum_{n=1}^d\\frac{\\sin\\bigl((n-\\frac{1}{2})\\pi x\\bigr)}{(n-\\frac{1}{2})\\pi} Y_n(\\omega)\\;,\\quad Y_n(\\omega)\\sim \\mathcal{N}(0,1)\\text{ i.i.d.}\n",
    "$$\n",
    "\n",
    "To that end, approximate $\\mathbb{E}[Z_I]$ for various values of $d$ and\n",
    "for various sub-divisions $I$ using (a) a crude Monte Carlo method, (b) Latin Hybercube Sampling (LHS) and (c) Quasi Monte Carlo (QMC) sampling.\n",
    "Use repeated LHS and randomized QMC to estimate the error and provide asymptotic confidence intervals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "76e82d62-ad6a-40d8-92aa-1c9d414fcd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def a1(x: np.array, w: np.array, mu: float=1, sigma: float=4) -> np.array:\n",
    "    \"\"\"\n",
    "    Elasticity coefficient a_1.\n",
    "\n",
    "    Args:\n",
    "        x (np.array): Quadrature grid, a numpy array of size I + 1.\n",
    "        w (np.array): Samples, a numpy array of size (N, d).\n",
    "        mu (float, optional): A scaling factor, defaults to 1.\n",
    "        sigma (float, optional): Another scaling factor, defaults to 4.\n",
    "\n",
    "    Returns:\n",
    "        np.array: Coefficient evaluated on the grid for the N samples, a numpy array of size (N, I + 1).\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5a4638-2b03-428d-a986-b9c7b6b3e9b7",
   "metadata": {},
   "source": [
    "Here's a small checkpoint to test whether your function is imlemeted correctly. If the assert statement doesn't throw an error, your function is implemented correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3ab652f2-d88a-4a57-9ae7-4e6fe7fd0b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1(x, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb74009-eff3-4171-86da-55c3b042c612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECKPOINT\n",
    "\n",
    "x = np.linspace(-1, 1, 5)\n",
    "w = np.arange(1, 7).reshape(3, 2) / 7\n",
    "expected = np.array(\n",
    "    [\n",
    "        [1.24606573, 1.04342336, 0.66708754, 1.04342336, 1.24606573],\n",
    "        [1.07237227, 0.98552555, 0.95657664, 0.98552555, 1.07237227],\n",
    "        [0.89867882, 0.92762773, 1.24606573, 0.92762773, 0.89867882]\n",
    "    ]\n",
    ")\n",
    "assert np.allclose(a1(x, w), expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4a664e21-34a8-4b4b-9dc5-a875d01168d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def a2(x: np.array, w: np.array) -> np.array:\n",
    "    \"\"\"\n",
    "    Elasticity coefficient a_2.\n",
    "\n",
    "    Args:\n",
    "        x (np.array): Quadrature grid, a numpy array of size I + 1.\n",
    "        w (np.array): Samples, a numpy array of size (N, d).\n",
    "\n",
    "    Returns:\n",
    "        np.array: Coefficient evaluated on the grid for the N samples, a numpy array of size (N, I + 1).\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bc38da-0d5a-4d61-9097-bc59f54a07de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECKPOINT\n",
    "\n",
    "x = np.linspace(-1, 1, 5)\n",
    "w = np.arange(1, 7).reshape(3, 2) / 7\n",
    "expected = np.array(\n",
    "    [\n",
    "        [0.81164424, 1.34950057, 1.        , 0.74101488, 1.23206689],\n",
    "        [0.45661749, 0.65468546, 1.        , 1.52745107, 2.19001684],\n",
    "        [0.30448019, 0.33728072, 1.        , 2.96488935, 3.28428587]\n",
    "    ]\n",
    ")\n",
    "assert np.allclose(a2(x, w), expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "950af239-af58-46fc-ab49-939aa26c3af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Z(w: np.array, a: Callable, I: int=50) -> np.array:\n",
    "    \"\"\"\n",
    "    Quadrature approximation of the quantity of interest `Z`.\n",
    "\n",
    "    Args:\n",
    "        w (np.array): Samples used as an argument for the elasticity coeeficient `a`, a numpy array of size (N, d).\n",
    "        a (Callable): Elasticity coefficient function, `a1` or `a2`.\n",
    "        I (int, optional): The number of grid points to use in the quadrature approximation, defaults to 50.\n",
    "\n",
    "    Returns:\n",
    "        np.array: The quadrature approximation of `Z` for each sample, a numpy array of size N.\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
