{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small Noise Limit in the Linear Gaussian Setting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we investigate the small noise limit for a special class of inverse problems.\n",
    "Suppose we intend to infer unknowns $u\\in\\mathbb{R}^d$ from data $y\\in\\mathbb{R}^k$. We further\n",
    "assume the following restrictions on the inverse problem:\n",
    "\n",
    "1. Linear forward model: $G(u)=Au,\\ A\\in\\mathbb{R}^{k\\times d}$\n",
    "2. Gaussian prior: $u \\sim \\mathcal{N}(u_{pr}, C_{pr})$\n",
    "3. Gaussian additive noise: $\\eta =\\gamma\\eta_0,\\ \\eta_0\\sim\\mathcal{N}(0,\\Gamma_{noise}),\\ \\gamma\\in\\mathbb{R}^+$\n",
    "4. Forward solution and noise are independent: $u \\perp \\eta$\n",
    "\n",
    "It follows immediately that the likelihood is given as a normal distribution,\n",
    "$$ y|u \\sim \\mathcal{N}(y-Au, \\gamma^2\\Gamma_{noise}) $$\n",
    "\n",
    "Furthermore, the posterior density is a product of (independent) Gaussians, meaning that it is\n",
    "again Gaussian. In particular, we have that\n",
    "$$ \n",
    "\\begin{gather*}\n",
    "\\pi_y(u) \\sim \\mathcal{N}(u_{post}, C_{post}), \\\\\n",
    "m_{post} = (A^T\\Gamma_{noise}^{-1}A + \\gamma^2 C_{pr}^{-1})^{-1}(A^T\\Gamma_{noise}^{-1}y + \\gamma^2 C_{pr}^{-1}u_{pr}), \\\\\n",
    "C_{post} = \\gamma^2(A^T\\Gamma_{noise}^{-1}A + \\gamma^2C_{pr}^{-1})^{-1}\n",
    "\\end{gather*}\n",
    "$$\n",
    "\n",
    "In this **linear Gaussian Setting**, we want to explore how the posterior behaves for $\\gamma\\to 0$ for different\n",
    "scenarios of the forward model and data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary libraries\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Interactive plotting and style\n",
    "%matplotlib widget\n",
    "plt.close('all')\n",
    "plt.style.use('bmh')\n",
    "\n",
    "# Layout of our slider and textbox widgets\n",
    "slider_layout = {'style': {'description_width': 'initial'},\n",
    "                 'layout': widgets.Layout(width='35%'),\n",
    "                 'continuous_update': True} \n",
    "\n",
    "textbox_layout = {'style': {'description_width': 'initial'},\n",
    "                  'layout': widgets.Layout(width='20%'),\n",
    "                  'continuous_update': False}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We firstly define some general routines that we need for our calculations. The function `generate_observations`\n",
    "produces data in the variables in the form of normally distributed random variables. It takes the noise scale $\\gamma$,\n",
    "the underlying true value $m_{true}$ and the forward matrix $A$ as inputs. We define $\\Gamma_{noise} = I$ and\n",
    "further choose $C_{pr} = c_{pr} I$ for some (positive) scalar $c_{pr}$.\n",
    "The function `compute_posterior_parameters` utilizes the above relations to compute the mean and covariance of the posterior,\n",
    "given $\\gamma, y, m_{pr}, c_{pr}$ and $A$.\n",
    "\n",
    "\n",
    "**Exercise : Fill out the below function bodies or implement your own versions for the generation of noise and computation\n",
    "of the posterior under the above assumptions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Generate data for given noise scale, true parameter and forward matrix\n",
    "def generate_observations(noise_scale, true_parameter, forward_matrix, seed=123456):\n",
    "\n",
    "    # observations should be a 1D numpy array\n",
    "    # Tip: Use the scipy stats module to generate multivariate normal random variables\n",
    "\n",
    "    return observations\n",
    "\n",
    "# 2) Compute mean vector and covariance matrix of the Gaussian posterior\n",
    "def compute_posterior_parameters(noise_scale,\n",
    "                                 observations,\n",
    "                                 prior_mean,\n",
    "                                 prior_cov,\n",
    "                                 forward_matrix):\n",
    "    \n",
    "    # mean_posterior should be 1D array, cov_posterior a 2D array\n",
    "    \n",
    "    return mean_posterior, cov_posterior"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overdetermined Case\n",
    "\n",
    "We firstly consider the overdetermined case $d < k$. In particular, a scalar unknown $u$ and 2D data $y$. The forward model matrix a is given as $A=\\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$. Clearly, we have that Null(A)=0."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise: Compute and visualize the posterior for the overdetermined case and different noise scales $\\gamma$.\n",
    "You can use the code in below cell that uses the functions `generate_observations` and `compute_posterior_parameters`.\n",
    "What are your observations?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "TRUE_PARAMETER_OVERDETERMINED = 1\n",
    "FORWARD_MATRIX_OVERDETERMINED = np.array(((1,),(1,)))\n",
    "\n",
    "# Visualize posterior\n",
    "def visualize_posterior_overdetermined(noise_scale,\n",
    "                                       true_parameter,\n",
    "                                       prior_mean,\n",
    "                                       prior_cov,\n",
    "                                       forward_matrix,\n",
    "                                       mpl_axis):\n",
    "    prior_mean = np.array((prior_mean,))\n",
    "\n",
    "    # First function enters here\n",
    "    observations = generate_observations(noise_scale,\n",
    "                                         true_parameter,\n",
    "                                         forward_matrix)\n",
    "    \n",
    "    # Second function enters here\n",
    "    mean, cov = compute_posterior_parameters(noise_scale,\n",
    "                                             observations,\n",
    "                                             prior_mean,\n",
    "                                             prior_cov,\n",
    "                                             forward_matrix)\n",
    "\n",
    "    sample_space = np.linspace(-2, 2, 1000, endpoint=True)\n",
    "    posterior_pdf = multivariate_normal.pdf(sample_space, mean, cov)\n",
    "\n",
    "    mpl_axis.clear()\n",
    "    mpl_axis.set_title(rf'Posterior for $\\gamma = {noise_scale}$')\n",
    "    mpl_axis.set_xlabel(r'$u$')\n",
    "    mpl_axis.set_ylabel(r'$p(u|y)$')\n",
    "    mpl_axis.set_xlim(np.min(sample_space), np.max(sample_space))\n",
    "    mpl_axis.set_ylim(0, 1.1*np.max(posterior_pdf))\n",
    "    mpl_axis.plot(sample_space, posterior_pdf, color='royalblue')\n",
    "    mpl_axis.axvline(true_parameter, color='black', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Sliders for parameter variations\n",
    "slider_noise_scale = widgets.FloatSlider(value=1, min=0.01, max=1, step=0.01,\n",
    "                                       description='Noise scale:',\n",
    "                                       **slider_layout)\n",
    "slider_prior_mean = widgets.FloatSlider(value=0, min=-1, max=1, step=0.05,\n",
    "                                       description='Prior mean:',\n",
    "                                       **slider_layout)\n",
    "slider_prior_cov = widgets.FloatSlider(value=1, min=0.1, max=10, step=0.05,\n",
    "                                       description='Prior covariance:',\n",
    "                                       **slider_layout)\n",
    "\n",
    "# Start interactive visualization\n",
    "_, ax = plt.subplots()\n",
    "interactive_plot = widgets.interact(visualize_posterior_overdetermined,\n",
    "                                    true_parameter=widgets.fixed(TRUE_PARAMETER_OVERDETERMINED),\n",
    "                                    forward_matrix=widgets.fixed(FORWARD_MATRIX_OVERDETERMINED),\n",
    "                                    noise_scale=slider_noise_scale,\n",
    "                                    prior_mean=slider_prior_mean,\n",
    "                                    prior_cov=slider_prior_cov,\n",
    "                                    mpl_axis=widgets.fixed(ax))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Underdetermined case\n",
    "\n",
    "Secondly, we investigate the undetermined case with d > k. We consider a 2D variable $u$ with model matrix $A=\\begin{pmatrix} 1 & 0 \\end{pmatrix}$, along with a 1D data point $y$. Note that Null(A) $\\neq$ 0, in a way that only the first component of the unknown affects the model output. This implies that the data can not inform the posterior regarding the second component of the unknown."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise: Compute and visualize the posterior for the underdetermined case and different noise scales $\\gamma$.\n",
    "You can use the code in below cell that uses the functions `generate_observations` and `compute_posterior_parameters`.\n",
    "What can you observe this time?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "TRUE_PARAMETER_UNDERDETERMINED = np.array((1, 1))\n",
    "FORWARD_MATRIX_UNDERDETERMINED = np.array(((1, 0),))\n",
    "\n",
    "# Visualize posterior\n",
    "def visualize_posterior_underdetermined(noise_scale,\n",
    "                                        true_parameter,\n",
    "                                        prior_mean_1,\n",
    "                                        prior_mean_2,\n",
    "                                        prior_cov,\n",
    "                                        forward_matrix,\n",
    "                                        mpl_axes):\n",
    "    prior_mean = np.array((prior_mean_1, prior_mean_2,))\n",
    "    true_parameter = np.array(true_parameter)\n",
    "\n",
    "    # First function enters here\n",
    "    observations = generate_observations(noise_scale,\n",
    "                                         true_parameter,\n",
    "                                         forward_matrix)\n",
    "    \n",
    "    # Second function enters here\n",
    "    mean, cov = compute_posterior_parameters(noise_scale,\n",
    "                                             observations,\n",
    "                                             prior_mean,\n",
    "                                             prior_cov,\n",
    "                                             forward_matrix)\n",
    "    \n",
    "    sample_space_x = np.linspace(-2, 2, 1000, endpoint=True)\n",
    "    sample_space_y = np.linspace(-2, 2, 1000, endpoint=True)\n",
    "    samples_x, samples_y = np.meshgrid(sample_space_x, sample_space_y, indexing='xy')\n",
    "    posterior_pdf = multivariate_normal.pdf(np.dstack((samples_x, samples_y)), mean, cov)\n",
    "\n",
    "    marginal_pdf_x = np.mean(posterior_pdf, axis=0)\n",
    "    marginal_pdf_y = np.mean(posterior_pdf, axis=1)\n",
    "    \n",
    "    for ax in (mpl_axes[0, 0], mpl_axes[1, 0], mpl_axes[1, 1]):\n",
    "        ax.clear()\n",
    "    mpl_axes[1, 0].contourf(samples_x, samples_y, posterior_pdf, cmap='Blues')\n",
    "    mpl_axes[1, 0].axvline(true_parameter[0], color='black', linestyle='--', alpha=0.5)\n",
    "    mpl_axes[1, 0].axhline(true_parameter[1], color='black', linestyle='--', alpha=0.5)\n",
    "    mpl_axes[1, 0].plot(true_parameter[0], true_parameter[1], marker=\"o\", markersize=10, color='firebrick')\n",
    "    mpl_axes[1, 0].grid('on', linestyle='--')\n",
    "    mpl_axes[1, 0].set_xlabel(r'$u_1$')\n",
    "    mpl_axes[1, 0].set_ylabel(r'$u_2$')\n",
    "    mpl_axes[1, 0].text(1.1, 1.7, r'$p(u_1, u_2 | y)$')\n",
    "\n",
    "    mpl_axes[0, 0].plot(sample_space_x, marginal_pdf_x, color='tab:blue')\n",
    "    mpl_axes[1, 1].plot(marginal_pdf_y, sample_space_y, color='tab:blue')\n",
    "    mpl_axes[0, 1].axis('off')\n",
    "\n",
    "    for ax in (mpl_axes[0, 0], mpl_axes[1, 1]):\n",
    "        ax.tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)\n",
    "    for pos in ['left', 'right', 'top']:\n",
    "        mpl_axes[0, 0].spines[pos].set_visible(False)\n",
    "    for pos in ['bottom', 'right', 'top']:\n",
    "        mpl_axes[1, 1].spines[pos].set_visible(False)\n",
    "\n",
    "# Sliders for parameter variations\n",
    "slider_noise_scale = widgets.FloatSlider(value=1, min=0.01, max=1, step=0.01,\n",
    "                                       description='Noise scale:',\n",
    "                                       **slider_layout)\n",
    "slider_prior_mean_1 = widgets.FloatSlider(value=0, min=-1, max=1, step=0.05,\n",
    "                                          description='Prior mean 1:',\n",
    "                                          **slider_layout)\n",
    "slider_prior_mean_2 = widgets.FloatSlider(value=0, min=-1, max=1, step=0.05,\n",
    "                                          description='Prior mean 2:',\n",
    "                                          **slider_layout)\n",
    "slider_prior_cov = widgets.FloatSlider(value=1, min=0.1, max=10, step=0.05,\n",
    "                                       description='Prior covariance:',\n",
    "                                       **slider_layout)\n",
    "\n",
    "# Start interactive visualization\n",
    "plt.style.use('default')\n",
    "fig, axs = plt.subplots(2, 2, figsize=(7, 7),\n",
    "                        gridspec_kw={'width_ratios': [3, 1], \n",
    "                                     'height_ratios': (1, 3),\n",
    "                                     'wspace': 0.1,\n",
    "                                     'hspace': 0.1})\n",
    "\n",
    "interactive_plot = widgets.interact(visualize_posterior_underdetermined,\n",
    "                                    true_parameter=widgets.fixed(TRUE_PARAMETER_UNDERDETERMINED),\n",
    "                                    forward_matrix=widgets.fixed(FORWARD_MATRIX_UNDERDETERMINED),\n",
    "                                    noise_scale=slider_noise_scale,\n",
    "                                    prior_mean_1=slider_prior_mean_1,\n",
    "                                    prior_mean_2=slider_prior_mean_2,\n",
    "                                    prior_cov=slider_prior_cov,\n",
    "                                    mpl_axes=widgets.fixed(axs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayesian_inference_ss23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
