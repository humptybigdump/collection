{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "keCaHIBcGxr5"
   },
   "source": [
    "# Hidden Markov Modelle (HMM): "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction:\n",
    "Consider a stochastic process $X(t)$ that can assume $N$ different states: $s_1, s_2, ... ,s_N$ with first-order Markov chain dynamics. Let us also suppose that we cannot observe the state of $X(t)$, but we have access to another process $O(t)$, connected to $X(t)$, which produces observable outputs (often known as emissions). The resulting process is called a Hidden Markov Model (HMM).\n",
    "\n",
    "A first-order hidden Markov model instantiates two simplifying assumptions:\n",
    "1. **First-Order Markov Chain:** the probability of a particular state depends only on the previous state:\n",
    "$$P(x_i|x_{1},...,x_{i−1}) = P(x_{i}|x_{i−1})$$\n",
    "2. **Output Independence:** the probability of an output observation $o_i$ depends only on the state that produced the observation $x_i$ and not on any other states or any other observations.\n",
    "$$P(o_i|x_1, ..., x_i,...,x_T ,o_1,...,o_i,...,o_T ) = P(o_i|x_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QchBtzk4edRj"
   },
   "source": [
    "## Hidden Markov Model (HMM):\n",
    "HMM has no input, and the probability distribution for the output should be given. An HMM is a five-tuple $\\lambda = \\{S,V,A,B,\\Pi\\} $\n",
    "\n",
    "with:\n",
    "\n",
    "* **State Vector:** $S= \\{0,\\ldots,N\\}$\n",
    "* **Output Vector:** $V= \\{0,\\ldots,M\\}$\n",
    "* **Matrix of transition probabilities:** $ A = (a_{ij}) $,  where  $ a_{ij} $ is the probability $s_j $ comes after $s_i $\n",
    "* **Matrix of emission probabilities:** $ B $, where $b_i(k)$ is the probability to observe $v_k$ in the state $ s_i $\n",
    "* **Initial state distribution:** $ \\Pi $. where $ \\pi_i $ is the probability that $ s_i $  is the intial  state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three fundamental problems should characterize the hidden Markov models:\n",
    "\n",
    "* **Problem 1 (Likelihood):** Given an HMM λ = (A, B) and an observation sequence O, determine the likelihood P(O|λ ).\n",
    "* **Problem 2 (Decoding):** Given an observation sequence O and an HMM λ = (A, B), discover the best-hidden state sequence X.\n",
    "* **Problem 3 (Learning):** Given an observation sequence O and the set of states in the HMM, learn the HMM parameters A and B."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-SE53mkz0CPs"
   },
   "source": [
    "## Example:\n",
    "The purpose of this example is to use the observations of how much ice cream Karam ate each day this summer to estimate the temperature on each day. To simplify this weather task, we assume that there are only two days: cold (C) and hot (H).\n",
    "\n",
    "The two hidden states ($s_1= H$ and $s_2 = C$) correspond to hot and cold weather, and the observations $O = \\{1, 2, 3\\}$ correspond to the number of ice creams eaten by Karam on a given day.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hmmlearn:\n",
    "`hmmlearn` implements the Hidden Markov Models (HMMs). Three models are available in `hmmlearn`\n",
    "\n",
    "* `hmm.GaussianHMM` Hidden Markov Model with Gaussian emissions.\n",
    "* `hmm.GMMHMM` Hidden Markov Model with Gaussian mixture emissions.\n",
    "* `hmm.MultinomialHMM` Hidden Markov Model with multinomial (discrete) emissions.\n",
    "\n",
    "To install this library in your virtual environment, you can use the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hmmlearn in /Users/karamdaaboul/.env/venv_ml/lib/python3.8/site-packages (0.2.4)\n",
      "Requirement already satisfied: numpy>=1.10 in /Users/karamdaaboul/.env/venv_ml/lib/python3.8/site-packages (from hmmlearn) (1.19.5)\n",
      "Requirement already satisfied: scikit-learn>=0.16 in /Users/karamdaaboul/.env/venv_ml/lib/python3.8/site-packages (from hmmlearn) (0.24.1)\n",
      "Requirement already satisfied: scipy>=0.19 in /Users/karamdaaboul/.env/venv_ml/lib/python3.8/site-packages (from hmmlearn) (1.6.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/karamdaaboul/.env/venv_ml/lib/python3.8/site-packages (from scikit-learn>=0.16->hmmlearn) (1.0.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/karamdaaboul/.env/venv_ml/lib/python3.8/site-packages (from scikit-learn>=0.16->hmmlearn) (2.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.3.3; however, version 21.0 is available.\n",
      "You should consider upgrading via the '/Users/karamdaaboul/.env/venv_ml/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "## Install the library\n",
    "!pip install hmmlearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries:\n",
    "first we will import all the packages that are required for this exercise. \n",
    "- [numpy](www.numpy.org) is the main package for scientific computing with Python.\n",
    "- [matplotlib](http://matplotlib.org) is a library to plot graphs in Python.\n",
    "- np.random.seed(1) is used to keep all the random function calls consistent\n",
    "- `hmmlearn` implements the Hidden Markov Models (HMMs). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from hmmlearn import hmm\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMM(hmm.MultinomialHMM):\n",
    "    def __init__(self,A,B,pi,**kwargs): #  keyword argument \n",
    "        n_components        = A.shape[0]\n",
    "        super().__init__(n_components,**kwargs)\n",
    "        self.transmat_     = A\n",
    "        self.emissionprob_ = B\n",
    "        self.startprob_    = pi\n",
    "        \n",
    "    def likelihood(self,obs_seq):\n",
    "        if len(obs_seq.shape)==1:\n",
    "            obs_seq = obs_seq.reshape(-1, 1)\n",
    "        # logprob -> probability\n",
    "        return np.exp(self.score(obs_seq))\n",
    "         \n",
    "    def decoding(self,obs_seq):\n",
    "        if len(obs_seq.shape)==1:\n",
    "            obs_seq = obs_seq.reshape(-1, 1)\n",
    "        # logprob -> probability\n",
    "        logprob, seq = self.decode(obs_seq)\n",
    "        return np.exp(logprob), seq\n",
    "    \n",
    "    def learning(self,obs_seq):\n",
    "        if len(obs_seq.shape)==1:\n",
    "            obs_seq = obs_seq.reshape(-1, 1)\n",
    "            \n",
    "        self.fit(obs_seq)\n",
    "    \n",
    "    def show_model(self):\n",
    "        np.set_printoptions(precision=4, suppress=True)\n",
    "        print('A: Transition probability matrix')\n",
    "        print(self.transmat_)\n",
    "        print('------------------------------')\n",
    "        print('B: Emission probability matrix')\n",
    "        print(self.emissionprob_)\n",
    "        print('-------------------------------')\n",
    "        print('pi: Initital state distribution')\n",
    "        print(self.startprob_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/4HLwgVN.png\" style=\"width:600px;height:200px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10400000000000004\n"
     ]
    }
   ],
   "source": [
    "# Prob(O | pi, A, B) = 0.1040\n",
    "Tag1 = 0.8 * 0.2 + 0.2 * 0.5\n",
    "Tag1_2 = 0.8*0.6*0.4 + 0.8*0.4*0.4 + 0.2*0.5*0.4 + 0.2*0.5*0.4\n",
    "print(Tag1_2*Tag1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZRAA72QWefVm"
   },
   "outputs": [],
   "source": [
    "states = ('Hot', 'Cold')\n",
    " \n",
    "observations = ('1','2','3')\n",
    " \n",
    "start_probability = {'Hot': 0.8, 'Cold': 0.2}\n",
    " \n",
    "transition_probability = {\n",
    "   'Hot' : {'Hot': 0.6, 'Cold': 0.4},\n",
    "   'Cold': {'Hot': 0.5, 'Cold': 0.5},\n",
    "   }\n",
    " \n",
    "emission_probability = {\n",
    "   'Hot' : {'1': 0.2, '2': 0.4, '3': 0.4},\n",
    "   'Cold': {'1': 0.5, '2': 0.4, '3': 0.1},\n",
    "   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: Transition probability matrix\n",
      "[[0.6 0.4]\n",
      " [0.5 0.5]]\n",
      "------------------------------\n",
      "B: Emission probability matrix\n",
      "[[0.2 0.4 0.4]\n",
      " [0.5 0.4 0.1]]\n",
      "-------------------------------\n",
      "pi: Initital state distribution\n",
      "[0.8 0.2]\n"
     ]
    }
   ],
   "source": [
    "# Define the Multinomial HMM\n",
    "pi= np.array([0.8, 0.2])  # initial probability  \n",
    "A = np.array([[0.6, 0.4],\n",
    "              [0.5, 0.5]]) # transmition probability\n",
    "B = np.array([[0.2, 0.4, 0.4],\n",
    "              [0.5, 0.4, 0.1]]) # Emission probability\n",
    "\n",
    "model = HMM(A,B,pi)   # n_components: number of state\n",
    "model.show_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 1 (Likelihood):** Given an HMM $λ = (A, B)$ and an observation sequence $O$, determine the likelihood $P(O|λ )$\n",
    "\n",
    "**Note:** The log likelihood is provided from calling `.likelihood.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How likely is a given sequence?\n",
    "* $ O= \\{1\\}$\n",
    "* $ O= \\{2\\}$\n",
    "* $ O= \\{3\\}$\n",
    "* $ O= \\{1,2,3\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prob(O | pi, A, B) = 0.2600\n"
     ]
    }
   ],
   "source": [
    "# O= {1}\n",
    "obs_seq = np.array([0])\n",
    "print(\"Prob(O | pi, A, B) = {:0.4f}\".format(model.likelihood(obs_seq)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability of the first observation being “only one ice” equals to the multiplication of the initial state distribution and emission probability matrix. 0.8 x 0.2 + 0.2 x 0.5 = 0.26 (26%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prob(O | pi, A, B) = 0.4000\n"
     ]
    }
   ],
   "source": [
    "# O= {2}\n",
    "obs_seq = np.array([1])\n",
    "print(\"Prob(O | pi, A, B) = {:0.4f}\".format(model.likelihood(obs_seq)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prob(O | pi, A, B) = 0.3400\n"
     ]
    }
   ],
   "source": [
    "# O= {3}\n",
    "obs_seq = np.array([2])\n",
    "print(\"Prob(O | pi, A, B) = {:0.4f}\".format(model.likelihood(obs_seq)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prob(O | pi, A, B) = 0.1040\n"
     ]
    }
   ],
   "source": [
    "# O= {1,2,3}\n",
    "obs_seq = np.array([0,1])\n",
    "print(\"Prob(O | pi, A, B) = {:0.4f}\".format(model.likelihood(obs_seq)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 2 (Decoding):** Given an observation sequence {O} and an HMM {λ = (A, B)}, discover the best-hidden state sequence {X}.\n",
    "\n",
    "The **Viterbi algorithm** is one of most common decoding algorithms for HMM. Its goal is to find the most likely hidden state sequence corresponding to a series of observations. \n",
    "\n",
    "**Note:** The decoding is provided from calling `.decoding.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the most probable “path” for generating a given sequence?\n",
    "* $ O= \\{1\\}$\n",
    "* $ O= \\{2\\}$\n",
    "* $ O= \\{3\\}$\n",
    "* $ O= \\{1,2,3\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most likely state sequence:  [0]\n",
      "Probability: 0.160000\n"
     ]
    }
   ],
   "source": [
    "# O= {1}\n",
    "obs_seq = np.array([0])\n",
    "prob,state_seq = model.decoding(obs_seq)\n",
    "print (\"Most likely state sequence: \", state_seq)\n",
    "print(\"Probability: {:0.6f}\".format(prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the known model and the observation “only one ice”, the state  was most likely “Hot” with ~1.6% probability.\n",
    "\n",
    "* Probability for “Hot”  : 0.8 x 0.2 = 0.16 (16%)\n",
    "* Probability for “Cold” : 0.2 x 0.5 = 0.1 (10%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most likely state sequence:  [0]\n",
      "Probability: 0.320000\n"
     ]
    }
   ],
   "source": [
    "obs_seq = np.array([1])\n",
    "prob,state_seq = model.decoding(obs_seq)\n",
    "print (\"Most likely state sequence: \", state_seq)\n",
    "print(\"Probability: {:0.6f}\".format(prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most likely state sequence:  [0]\n",
      "Probability: 0.320000\n"
     ]
    }
   ],
   "source": [
    "obs_seq = np.array([2])\n",
    "prob,state_seq = model.decoding(obs_seq)\n",
    "print (\"Most likely state sequence: \", state_seq)\n",
    "print(\"Probability: {:0.6f}\".format(prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most likely state sequence:  [0 0 0]\n",
      "Probability: 0.009216\n"
     ]
    }
   ],
   "source": [
    "obs_seq = np.array([0,1,2])\n",
    "prob,state_seq = model.decoding(obs_seq)\n",
    "print (\"Most likely state sequence: \", state_seq)\n",
    "print(\"Probability: {:0.6f}\".format(prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 3 (Learning):** Given an observation sequence O and the set of states in the HMM, learn the HMM parameters A and B.\n",
    "\n",
    "But first, we need to generate data that can with a high probability result from our HMM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The HMM is a generative probabilistic model, in which a sequence of observable $O$ variables is generated by a sequence of internal hidden states $X$. \n",
    "\n",
    "**Note:** The decoding is provided from calling .sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 10 observations in the sequence :  [[2 1 0 1 1 2 2 2 1 0]]\n"
     ]
    }
   ],
   "source": [
    "# Generate the dataset a sequence of 100 measurements\n",
    "O, _ = model.sample(100)\n",
    "print(\"The first 10 observations in the sequence : \", O[:10].transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5929450181935767e-48"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.likelihood(O)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:**  In machine learning sense, observation is our training data, and the number of hidden states is our hyper parameter for our model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define an intial model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: Transition probability matrix\n",
      "[[0.6 0.4]\n",
      " [0.5 0.5]]\n",
      "------------------------------\n",
      "B: Emission probability matrix\n",
      "[[0.2 0.4 0.4]\n",
      " [0.5 0.4 0.1]]\n",
      "-------------------------------\n",
      "pi: Initital state distribution\n",
      "[0.8 0.2]\n"
     ]
    }
   ],
   "source": [
    "model.show_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 506,
     "status": "ok",
     "timestamp": 1547395723601,
     "user": {
      "displayName": "karam daaboul",
      "photoUrl": "https://lh5.googleusercontent.com/-pIJAbmNh3Dg/AAAAAAAAAAI/AAAAAAAACqQ/EH7noOZ8y3U/s64/photo.jpg",
      "userId": "10489733265214992802"
     },
     "user_tz": -60
    },
    "id": "Lw8VXg2D5OUA",
    "outputId": "7b8cc249-92a9-48e4-f640-2863f39b96c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: Transition probability matrix\n",
      "[[0.5 0.5]\n",
      " [0.6 0.4]]\n",
      "------------------------------\n",
      "B: Emission probability matrix\n",
      "[[0.1 0.4 0.5]\n",
      " [0.6 0.3 0.1]]\n",
      "-------------------------------\n",
      "pi: Initital state distribution\n",
      "[0.5 0.5]\n"
     ]
    }
   ],
   "source": [
    "# Define the intial HMM\n",
    "pi_init = np.array([0.5, 0.5])  # initial probability  \n",
    "A_init  = np.array([[0.5, 0.5],\n",
    "                    [0.6, 0.4]]) # transmition probability\n",
    "B_init  = np.array([[0.1, 0.4, 0.5],\n",
    "                    [0.6, 0.3, 0.1]]) # Emission probability\n",
    "\n",
    "model2 = HMM(A_init,B_init,pi_init,\n",
    "                           init_params='', \n",
    "                           n_iter=100, \n",
    "                           tol=0.05)   # n_components: number of state\n",
    "model2.show_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we learn the HMM parameters given a set of observations sequence?\n",
    "\n",
    "**Note:** The learning is provided from calling `.learning.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "model2.learning(O)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: Transition probability matrix\n",
      "[[0.5425 0.4575]\n",
      " [0.5543 0.4457]]\n",
      "------------------------------\n",
      "B: Emission probability matrix\n",
      "[[0.0868 0.4293 0.4839]\n",
      " [0.5408 0.3638 0.0954]]\n",
      "-------------------------------\n",
      "pi: Initital state distribution\n",
      "[0.9996 0.0004]\n"
     ]
    }
   ],
   "source": [
    "model2.show_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: Transition probability matrix\n",
      "[[0.6 0.4]\n",
      " [0.5 0.5]]\n",
      "------------------------------\n",
      "B: Emission probability matrix\n",
      "[[0.2 0.4 0.4]\n",
      " [0.5 0.4 0.1]]\n",
      "-------------------------------\n",
      "pi: Initital state distribution\n",
      "[0.8 0.2]\n"
     ]
    }
   ],
   "source": [
    "model.show_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HMM_tasks",
   "provenance": [
    {
     "file_id": "1mfViZ-KLDqy53fDyC1KJtqCZKowmd9lq",
     "timestamp": 1547395875532
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
