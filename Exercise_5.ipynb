{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jKMKjg-RauNO"
   },
   "source": [
    "## ***Uncertainty Quantification***\n",
    "\n",
    "Prof. Dr. M. Frank 2021\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "#### **EXERCISE SHEET 5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fVEj7uc6cuCC"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.integrate as integrate\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import scipy.linalg\n",
    "import scipy.special"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YBTSq9_hbU_0"
   },
   "source": [
    "**EXERCISE 1)**\n",
    "\n",
    "Recall the ODE with uncertainties from the last exercise sheet:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\frac{du}{dt}(t,Z) = -\\alpha(Z)u(t,Z),\\quad u(0,Z) = \\beta(Z).\n",
    "\\end{equation*}\n",
    "\n",
    "Assume that $\\alpha$ is Gaussian normal distributed and $\\beta$ is deterministic (independent of Z).\n",
    "\n",
    "(a) Derive and solve the Stochastic Galerkin system numerically. Fill in the gaps below to plot the expectation value and variance of $u(t,Z)$ as a function of the gPC approximation order $N$. What do you observe when you increase the time $t$?\n",
    "\n",
    "*Hint*: For Hermite polynomials, $E[H_k^2]=k!$ and $$E[H_iH_jH_k] = e_{ijk} = \\frac{i!j!k!}{(s-i)!(s-j)!(s-k)!}$$ for $2s := i+j+k$ even and $s \\geq i,j,k$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P3uOAcanbXHq"
   },
   "outputs": [],
   "source": [
    "## Function definitions ## \n",
    "\n",
    "def CoeffsAlpha(N):\n",
    "  mu = 0\n",
    "  sigma = 1\n",
    "  a = np.zeros((N+1,1))\n",
    "  a[0]=mu\n",
    "  a[1]=sigma\n",
    "  return a\n",
    "\n",
    "def CoeffsBeta(N):\n",
    "  mu=1\n",
    "  b = np.zeros((N+1,1))\n",
    "  b[0]=mu\n",
    "  return b\n",
    "\n",
    "def epsilon(i,j,k):\n",
    "  y=0\n",
    "  if ((i+j+k)%2)==0:\n",
    "    s=(i+j+k)/2\n",
    "    if (s>=i and s>=j and s>=k):\n",
    "      y = math.factorial(i)*math.factorial(j)*math.factorial(k)/math.factorial(s-i)/math.factorial(s-j)/math.factorial(s-k)\n",
    "  return y\n",
    "\n",
    "def gamma(k):\n",
    "  return math.factorial(k)\n",
    "\n",
    "\n",
    "CoeffsAlpha=np.vectorize(CoeffsAlpha)\n",
    "CoeffsBeta=np.vectorize(CoeffsBeta)\n",
    "epsilon=np.vectorize(epsilon)\n",
    "gamma=np.vectorize(gamma)\n",
    "\n",
    "##  Compute Expectation and Standard deviation ##\n",
    "\n",
    "#gPC order\n",
    "Nmax=10\n",
    "#Time\n",
    "t=1\n",
    "\n",
    "Expectation = np.empty((Nmax,))\n",
    "StdDev = np.empty((Nmax,))\n",
    "\n",
    "#Plot for different order\n",
    "for N in range(1,Nmax+1):\n",
    "  #Assemble SG matrix\n",
    "  a = CoeffsAlpha(N)\n",
    "  A = np.zeros((N+1,N+1))\n",
    "\n",
    "  for j in range(N+1):\n",
    "    for k in range(N+1):\n",
    "      A[j,k]=0\n",
    "      for i in range(N+1):\n",
    "        A[j,k] = A[j,k] - 1/gamma(k)*a[i]*epsilon(i,j,k)\n",
    "  \n",
    "  b = CoeffsBeta(N)\n",
    "  u = np.dot(scipy.linalg.expm(t*A.transpose()),b)\n",
    "\n",
    "  #Fill in formulas for expectation value and standard deviation\n",
    "  Expectation[N-1] = #...\n",
    "  StdDev[N-1] = #...\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(np.arange(1,Nmax+1),Expectation,color='blue',label=r'$\\mu$')\n",
    "plt.plot(np.arange(1,Nmax+1),Expectation+StdDev,color='red',label=r'$\\mu \\pm \\sigma$')\n",
    "plt.plot(np.arange(1,Nmax+1),Expectation-StdDev,color='red')\n",
    "plt.title(\"Expectation value and variance as a function of gPC order\")\n",
    "plt.xlabel(\"Order N\")\n",
    "_=plt.legend(shadow=True, fancybox=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kqUpWHnUcQTF"
   },
   "source": [
    "(b) Select a grid in $Z$ and derive a reconstruction of $u(t,Z)$ by interpolation. What do you obtain for the derived quantities like the expectation value? Solve the Stochastic Collocation system numerically. (Fill in the gaps or adjust the code below according to your choices/derivations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YH_21_2XcRN0"
   },
   "outputs": [],
   "source": [
    "#Normal distribution\n",
    "def f(x,mu,sigma):\n",
    "  return 1/np.sqrt(2*math.pi)*np.exp(-(x-mu)**2/2/sigma)\n",
    "\n",
    "#ODE parameters\n",
    "t=1.0\n",
    "beta=1.0\n",
    "\n",
    "#Quadrature tolerance \n",
    "QuadTol = 1e-10\n",
    "\n",
    "#Gaussian parameters\n",
    "mu=0.0\n",
    "sigma=1\n",
    "\n",
    "#Grid\n",
    "Nmax=10\n",
    "alphal=mu-4*sigma\n",
    "alphar=mu+4*sigma\n",
    "\n",
    "Expectation = np.zeros((Nmax,))\n",
    "StdDev = np.zeros((Nmax,))\n",
    "\n",
    "for N in range(1,Nmax+1):\n",
    "  alpha = np.linspace(alphar,alphal,N)    #Swap upper and lower bound, so that upper bound is chosen for N=1\n",
    "  \n",
    "  #TO DO:\n",
    "  #Fill in Solution\n",
    "  y = #...\n",
    "  #Fill in Interpolation\n",
    "  p = #...\n",
    "\n",
    "  #Expectation\n",
    "  def fun_exp(x):\n",
    "    return np.multiply(np.polyval(p,x),f(x,mu,sigma))\n",
    "  Expectation[N-1],_ = integrate.quadrature(fun_exp,alphal,alphar,tol=QuadTol)\n",
    "  #Variance\n",
    "  def fun_var(x):\n",
    "    return np.multiply((np.polyval(p,x) - Expectation[N-1])**2,f(x,mu,sigma))\n",
    "  StdDev[N-1],_ = np.sqrt(integrate.quadrature(fun_var,alphal,alphar,tol=QuadTol))\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(np.arange(1,Nmax+1),Expectation,color='blue',label=r'$\\mu$')\n",
    "plt.plot(np.arange(1,Nmax+1),Expectation+StdDev,color='red',label=r'$\\mu \\pm \\sigma$')\n",
    "plt.plot(np.arange(1,Nmax+1),Expectation-StdDev,color='red')\n",
    "plt.title(\"Expectation value and variance as a function of collocation points\")\n",
    "plt.xlabel(\"Collocation points N\")\n",
    "_=plt.legend(shadow=True, fancybox=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eH6HNWTYca9a"
   },
   "source": [
    "(c) Compare, also with Monte-Carlo sampling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8_wHilXBcfkZ"
   },
   "outputs": [],
   "source": [
    "#Function definitions\n",
    "\n",
    "#TO DO:\n",
    "#Sampling\n",
    "def InverseTransformSampling(N,mu,sigma):\n",
    "  #\n",
    "  #implement inverse transform sampling with the help of the inverse distribution function Finv\n",
    "  #\n",
    "  return \n",
    "\n",
    "#TO DO:\n",
    "#Inverse distribution function\n",
    "def Finv(y,mu,sigma):\n",
    "  #\n",
    "  return #fill in inverse distribution function of y here\n",
    "\n",
    "#Averaging\n",
    "def avg(x):\n",
    "  return 0.5*(x[1:]+x[0:np.size(x)])\n",
    "\n",
    "#ODE parameters \n",
    "t=1.0\n",
    "beta=1.0\n",
    "#Samples\n",
    "N=np.hstack((np.arange(1e3,1e4+1,1e3),np.arange(2e4,1e5+1,1e4),np.arange(2e5,1e6+1,1e5)))\n",
    "#Gaussian parameters\n",
    "mu=0.0\n",
    "sigma=1\n",
    "\n",
    "Expectation=np.empty((np.size(N),))\n",
    "StdDev=np.empty((np.size(N),))\n",
    "\n",
    "for i in range(np.size(N)):\n",
    "  #Sample\n",
    "  #TO DO:\n",
    "  alpha = #...\n",
    "  #Result\n",
    "  y = #...\n",
    "  Expectation[i] = #...\n",
    "  StdDev[i]= #...\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.semilogx(N,Expectation,color='blue',label=r'$\\mu$')\n",
    "plt.semilogx(N,Expectation-StdDev,color='red',label=r'$\\mu \\pm \\sigma$')\n",
    "plt.semilogx(N,Expectation+StdDev,color='red')\n",
    "plt.title(\"Expectation value and variance as a function of samples\")\n",
    "plt.xlabel(\"Samples N\")\n",
    "_=plt.legend(shadow=True, fancybox=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rfONnHNJdNpZ"
   },
   "source": [
    "**EXERCISE 3)**\n",
    "\n",
    "Consider the code block below. \n",
    "\n",
    "(a) The code implements a simple example of gPC approximation. Which one? \n",
    "\n",
    "(b) How would you evaluate the quality of the approximation for the probability density function and cumulative density function?\n",
    "\n",
    "(c) What can you observe for different orders of approximation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G8ChS3X9dQl6"
   },
   "outputs": [],
   "source": [
    "def legendre(n,X) :\n",
    "  res = []\n",
    "  for m in range(n+1):\n",
    "    res.append(scipy.special.lpmv(m,n,X))\n",
    "  res =np.array(res)\n",
    "  if res.ndim==1:\n",
    "    res=np.expand_dims(res,axis=1)\n",
    "  return res\n",
    "\n",
    "def Pn(n,x):\n",
    "  if n == 0:\n",
    "      return  1\n",
    "  elif n==1:\n",
    "      return  x\n",
    "  elif n>1:\n",
    "      return  (2*n-1)/n * x * P(n-1,x) - (n-1)/n * P(n-2,x)\n",
    "\n",
    "Pn = np.vectorize(Pn)\n",
    "\n",
    "#Evaluate gPC approximation\n",
    "def YN(z,N,gamma,alpha):\n",
    "  y=0\n",
    "  for k in range(N+1):\n",
    "    y = y + alpha[k]/gamma[k]*phi(k,z) #Assemble polynomial\n",
    "  return y\n",
    "\n",
    "#Inverse distribution for Y\n",
    "def FYinv(y):\n",
    "  return scipy.special.erfinv(2*y-1) #Gaussian\n",
    "\n",
    "#Distribution for Y\n",
    "def FY(y):\n",
    "  return 1/2*(1+scipy.special.erf(y)) #Gaussian\n",
    "\n",
    "def fY(y):\n",
    "  return 1/np.sqrt(math.pi)*np.exp(-y**2) #Gaussian\n",
    "\n",
    "#Distribution for Z\n",
    "def FZ(z):\n",
    "  return (z+1)/2 #Uniform/Legendre\n",
    "\n",
    "#Density for Z\n",
    "def fZ(z):\n",
    "  return 1/2*(z>=-1 and z<=1) #Uniform/Legendre\n",
    "\n",
    "#Compute orthogonal polynomials\n",
    "def phi(n,x):\n",
    "  P = legendre(n,x)\n",
    "  return P[0,:]\n",
    "\n",
    "#Averaging\n",
    "def avg(x):\n",
    "  return 0.5*(x[1:]+x[0:np.size(x)-1])\n",
    "\n",
    "fZ = np.vectorize(fZ)\n",
    "\n",
    "#Integration tolerance\n",
    "QuadTol = 1e-10\n",
    "\n",
    "#Order of approximation\n",
    "N=3\n",
    "\n",
    "#Domain of support and plot parameters\n",
    "#gPC reconstruction\n",
    "z0 = -1\n",
    "z1 = 1\n",
    "nz = 100\n",
    "z = np.linspace(z0,z1,nz)\n",
    "#pdf of gPC reconstruction\n",
    "y0 = -2 \n",
    "y1 = 2\n",
    "ny = 100\n",
    "y = np.linspace(y0,y1,ny)\n",
    "dy = (y1-y0)/ny\n",
    "\n",
    "gamma = np.empty((N+1,))\n",
    "alpha = np.empty((N+1,))\n",
    "\n",
    "#Compute coefficients\n",
    "for k in range(N+1):\n",
    "  def f1(z):\n",
    "    return np.multiply(phi(k,z)**2,fZ(z))\n",
    "  def f2(z):\n",
    "    return np.multiply(FYinv(FZ(z)),np.multiply(phi(k,z),fZ(z)))\n",
    "  gamma[k],_ = integrate.quad_vec(f1,z0,z1,epsabs=QuadTol)\n",
    "  alpha[k],_ = integrate.quad_vec(f2,z0,z1,epsabs=QuadTol)\n",
    "\n",
    "#Plot gPC reconstruction\n",
    "fig, ax = plt.subplots(nrows=1,ncols=2,figsize=(16,8))\n",
    "ax[0].plot(z,YN(z,N,gamma,alpha))\n",
    "ax[0].set_xlabel('Z')\n",
    "ax[0].set_ylabel('Y')\n",
    "ax[0].set_title('Y_N as function of Z')\n",
    "\n",
    "#Determine pdf of gPC reconstruction\n",
    "FYN = np.empty((ny,))\n",
    "for i in range(np.size(y)):\n",
    "  def f3(z):\n",
    "   return np.multiply((YN(z,N,gamma,alpha)<=y[i]),fZ(z))\n",
    "  FYN[i],_ = integrate.quad_vec(f3,z0,z1,epsabs=QuadTol)\n",
    "\n",
    "ax[1].plot(y,FYN,label='cdf of Y_N')\n",
    "ax[1].set_xlabel('y')\n",
    "ax[1].set_ylabel('FYN(y)')\n",
    "ax[1].plot(y,FY(y),linestyle='dotted',label='cdf of Y')\n",
    "ax[1].plot(avg(y),np.diff(FYN)/dy,color='red',label='pdf of Y_N')\n",
    "ax[1].plot(avg(y),fY(avg(y)),linestyle='dotted',color='red',label='pdf of Y')\n",
    "_=ax[1].legend(shadow=True, fancybox=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LFYckApkjtFP"
   },
   "source": [
    "&nbsp;\n",
    "\n",
    "**EXERCISE 4)**\n",
    "\n",
    "Reproduce and possibly extend the results in either of the following papers (you can also use a paper of your choice):\n",
    "\n",
    "- R. Pulch, *Stochastic Galerkin methods for analyzing equilibria of random dynamical systems,* SIAM/ASA J. Uncertainty Quantification 1(1), 408-430 (2013).\n",
    "- R. Pulch and D. Xiu, *Generalised polynomial chaos for a class of linear conservation laws,* J. Sci. Comput. 51(2), 293-312 (2012).\n",
    "- D. Gottlieb and D. Xiu, *Galerkin Method for Wave Equations with Uncertain Coefficients,* Comm. Comput. Phys. 3(2), 505-518 (2008). \n",
    "- D. Xiu and G.E. Karniadakis, *Supersensitivity Due to Uncertain Boundary Conditions,* Int. J. Numer. Meth. Engng. 61(12), 2114-2138 (2004).\n",
    "- D. Xiu and G.E. Karniadakis, *Modeling Uncertainty in Steady State Diffusion Problems via Generalized Polynomial Chaos,* Comput. Methods Appl. Mech. Engrg. 191, 4927-4948 (2002). \n",
    "\n",
    "&nbsp;\n",
    "\n",
    "All papers can be found in ILIAS or via internet search.\n",
    "Use the following general strategy:\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;(a) Implement an efficient solver for the deterministic problem.  \n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;(b) Implement Monte-Carlo sampling. (Possibly keep it running in the background) Also try quasi-MC or MLMC.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;(c) Implement a tensorized quadrature method.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;(d) Reproduce the derivation of the stochastic Galerkin system. Implement a solver following the guidelines in each of the papers.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;(e) Compare and discuss.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Exercise5_solution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
