{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Machine Vision - Assignment 7: Deep Learning\n",
    "\n",
    "In this exercises you will apply different concepts of deep learning in order to classify images of traffic signs. While working through this notebook, different links to official web-sites or blog-posts are provided for additional information.\n",
    "This exercise uses the Pytorch framework, which is one of the most popular deep learning frameworks.\n",
    "If you are new to pytorch please follow this introduction: [PyTorch Introduction](https://pytorch.org/tutorials/beginner/basics/intro.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import torchvision\n",
    "from torchvision.transforms import v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### Preparation\n",
    "\n",
    "##### German Traffic Sign Recognition Benchmark\n",
    "\n",
    "The German Traffic Sign Recognition Benchmark [(GTSRB)](https://benchmark.ini.rub.de/) is a competition that was held at the IJCNN 2011. In this competition images of traffic signs should be classified.\n",
    "You will implement your own neural network to classify a subset of the GTSRB dataset. This subset consists of `12` different classes, which are shown in the figures below. However, you are free to extend your solution to the full dataset.\n",
    "\n",
    "\n",
    "|---|------------------------------|-------------------------------|-------------------------------|-------------------------------|-------------------------------|-------------------------------|-------------------------------|-------------------------------|-------------------------------|--------------------------------|--------------------------------|--------------------------------|\n",
    "|  ![Class 0](res/images/0.png) | ![Class 1](res/images/6.png) | ![Class 2](res/images/16.png) | ![Class 3](res/images/17.jpg) | ![Class 4](res/images/19.png) | ![Class 5](res/images/22.jpg) | ![Class 6](res/images/28.png) | ![Class 7](res/images/29.png) | ![Class 8](res/images/32.png) | ![Class 9](res/images/33.png) | ![Class 10](res/images/38.png) | ![Class 11](res/images/40.png) |\n",
    "<br></br>\n",
    "\n",
    "In order to simplify this exercise, the raw GTSRB images are already transformed into a dataset, where each image has the shape of `[C,H,W]` (Height x Width x Channels) with values ranging from `0-1`.\n",
    "Furthermore, the dataset is split into a train-, validation- and test-dataset, where the train- and validation-datasets are provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 12\n",
    "\n",
    "train_ds = torchvision.datasets.ImageFolder(\"data_train\", transform=v2.Compose([\n",
    "    v2.PILToTensor(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "]))\n",
    "\n",
    "val_ds = torchvision.datasets.ImageFolder(\"data_val\", transform=v2.Compose([\n",
    "    v2.PILToTensor(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "]))\n",
    "\n",
    "train_dl = DataLoader(dataset=train_ds, batch_size=16, shuffle=True)\n",
    "val_dl = DataLoader(dataset=val_ds, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Which means, that each label is a vector of 12 entries, where only the entry of the class has the value $1$ and all others values are $0$The `torchvision.datasets.ImageFolder` is a simple way to represent classification datasets. For more information you can read it up here: [ImageFolder](https://pytorch.org/vision/stable/generated/torchvision.datasets.ImageFolder.html)\n",
    "\n",
    "Furthermore, the standard pytorch dataloader class is used to create an iterator based on an `torch.utils.data.Dataset` class.\n",
    "Each iteration, the dataloader returns a batch of `x = [Bx3x32x32]` images and `y = [Bx12]` class labels, where B is the batch size.\n",
    "\n",
    "There are different approaches to encode the class label. For further information you can read this blog entry [integer- or one-hot-encoding](https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/).\n",
    "In this exercise the labels are encoded in the integer format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_batch, y_batch = next(iter(train_dl))\n",
    "\n",
    "# @student print the image and label shape of a batch\n",
    "\n",
    "# @student show one image of the batch and its label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### Execution\n",
    "\n",
    "In order to compare models against each other metrics are calculated on an unseen test dataset.\n",
    "(It will be uploaded during the exam session)\n",
    "\n",
    "In this exercise you should try to develop your own model.\n",
    "If you are new to pytorch, this section of the introduction is about creating your model [PyTorch Create A Model](https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# @student implement your model here (nn.Module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "For inspiration you can take a look at these ground-breaking publications:\n",
    "[LeNet](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf)\n",
    "[AlexNet](https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf)\n",
    "[GoogLeNet](https://arxiv.org/pdf/1409.4842.pdf)\n",
    "[ResNet](https://arxiv.org/pdf/1512.03385.pdf)\n",
    "[Vit](https://arxiv.org/abs/2010.11929)\n",
    "\n",
    "Additionally, you can also add data augmentation to the training data in order to improve the generalization of your model.\n",
    "[Torchvision Augmentation](https://pytorch.org/vision/stable/transforms.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = ...\n",
    "print(model)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Below is the training process of the model.\n",
    "If your machine supports gpu acceleration uncomment line 6."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    print(f\"epoch {epoch+1}\")\n",
    "    pbar = tqdm(enumerate(train_dl))\n",
    "    running_loss = []\n",
    "    for i, (imgs, labels) in pbar:\n",
    "        # @student: uncomment if your machine has GPU support\n",
    "        #imgs, labels = imgs.to(\"cuda\"), labels.to(\"cuda\")\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        preds = model(imgs)\n",
    "        loss = loss_fn(preds, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss.append(loss.detach().numpy())\n",
    "        pbar.set_description(f\"loss {np.mean(running_loss):.3} - \" )\n",
    "        pbar.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### From Logits to Labels\n",
    "\n",
    "Your network will output logits and not the final predictions.\n",
    "Hence, you further need to calculate the predicted label based on the logits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def eval(model, dl):\n",
    "    y_labels = []\n",
    "    pred_labels = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (imgs, labels) in enumerate(dl):\n",
    "            logits = model(imgs)\n",
    "\n",
    "            # @student: calculate class predictions based on the logits\n",
    "            preds = ...\n",
    "\n",
    "            pred_labels.extend(preds.detach().numpy())\n",
    "            y_labels.extend(labels.detach().numpy())\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "    cm = confusion_matrix(y_labels, pred_labels)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"f1: {f1_score(y_labels, pred_labels, average='macro')}, p: {precision_score(y_labels, pred_labels, average='macro')}, r: {recall_score(y_labels, pred_labels, average='macro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval(model, val_dl)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Once you feel confident with your model evaluate it one last time on the test set.\n",
    "The test set will be uploaded during the exercise session."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# @student: final check of your fully trained model\n",
    "test_ds = torchvision.datasets.ImageFolder(\"data_test\", transform=v2.Compose([\n",
    "    v2.PILToTensor(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "]))\n",
    "test_dl = DataLoader(dataset=test_ds, batch_size=16, shuffle=False)\n",
    "\n",
    "eval(model, test_dl)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
