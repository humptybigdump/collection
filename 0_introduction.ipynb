{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organization\n",
    "This exercise demonstrates some basic operations we will need for this course.\n",
    "Find a group, get familiar with the setup, then submit this exercise following the instructions below.\n",
    "\n",
    "Most exercises will provide you with an incomplete algorithm, and you and are required to fill in missing methods and functions.\n",
    "These incomplete segments are marked with **TODO** statements, and often contain hints on what exactly needs to be done.\n",
    "\n",
    "## Find a group\n",
    "We highly recommend doing the exercises in groups of up to three students.\n",
    "You can use the \"[Looking for a group](https://ilias.studium.kit.edu/ilias.php?baseClass=ilrepositorygui&cmdNode=xe:mm&cmdClass=ilObjForumGUI&cmd=viewThread&ref_id=2518240&thr_pk=294528&page=0)\" forum to find other students.\n",
    "You are able to define who is in your group during the process of submitting the homework via Ilias.\n",
    "\n",
    "## Submission guidelines\n",
    "For the submission of the exercise please follow these steps:\n",
    "1. Make sure that every cell is executed and that your plots are properly displayed and saved.\n",
    "2. Create a .zip file of your filled-in notebook, any pen & paper solution, if applicable (for some exercises only), and the folder containing your saved plots.\n",
    "By default, the plot folder will be in your Google Drive in `rl_ws24/exercise_i/date` for the i-th exercise.\n",
    "3. Rename your zip file with the following naming convention: `group_uxxxx_uxxxx_uxxxx`, where `uxxxx` is the KIT user id from each group member.\n",
    "4. Upload the zip file to Ilias.\n",
    "\n",
    "This submission is only for getting familiar with jupyter notebooks and the submission procedure, it will not be graded.\n",
    "\n",
    "\n",
    "## Jupyter Notebooks and Google Colab\n",
    "\n",
    "### Jupyter Notebooks\n",
    "Usually, each coding exercise will provide you with a Jupyter notebook.\n",
    "These notebooks contain markdown/text cells (such as this one), and python code cells (like the ones further below).\n",
    "Each code cell can be run separately, and access a global state for the whole notebook.\n",
    "Code that has been compiled in one cell (such as functions, classes or imports) is available in other cells.\n",
    "It is also possible to use $\\LaTeX$ equations inside the markdown environment.\n",
    "You can freely edit the code in the code-cells, and then run a cell by clicking on the arrow next to it.\n",
    "\n",
    "### Google Colab and local IDEs\n",
    "You have the option to either run Jupyter notebook either locally using an IDE, or in the cloud using Google Colab.\n",
    "Google Colab will directly save logs and recordings to a designated folder in your Google Drive.\n",
    "\n",
    "Alternatively, you may want to use an IDE on your PC instead.\n",
    "This requires a little more setup effort, but may make debugging easier.\n",
    "For this, we recommend using either [PyCharm](https://www.jetbrains.com/pycharm/) or [Visual Studio Code](https://code.visualstudio.com/).\n",
    "As a student, you can get educational licenses for both from the [KIT Software Shop](https://www.scc.kit.edu/dienste/4800.php).\n",
    "We recommend using conda (or mamba) for managing a virtual environment with all the Python packages required for the exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries\n",
    "This section introduces the tools that we will be working with in this course.\n",
    "You will find the actual exercise in the Section \"Exercise 0\" below.\n",
    "\n",
    "## Python, Numpy and PyTorch\n",
    "Deep Reinforcement Learning algorithms often require carefully designed and complex training routines. Practitioners usually use a range of tools to deal with this complexity.\n",
    "We list the ones that we will focus on during the lecture below, and strongly encourage you to familiarize yourself with them if you have not heard of them before.\n",
    "\n",
    "### Python\n",
    "All programming exercises for this course are based on [Python](https://www.python.org/downloads/).\n",
    "Python is a programming language focused around easy syntax and quick development.\n",
    "It has a lot of infrastructure for Deep Reinforcement Learning and more generally Machine Learning applications.\n",
    "\n",
    "### Numpy\n",
    "[NumPy](https://numpy.org/) is a library for scientific computing in Python. It is structured around the *ndarray*, which is a multidimensional container that allows for easy and efficient operations on high-dimensional arrays.\n",
    "* An introduction to NumPy can be found [here](https://numpy.org/doc/stable/user/quickstart.html)\n",
    "\n",
    "### PyTorch\n",
    "[PyTorch](https://pytorch.org/) is an automatic differentiation framework that builds on NumPy. It offers a wide range of tools and pre-build blocks for different machine learning approaches. We will mainly use PyTorch for the *deep* part of Deep Reinforcement Learning, i.e., to build and train deep neural networks.\n",
    "* To get started with PyTorch, we recommend [this tutorial](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)\n",
    "* For a quick primer on PyTorch Tensors, see [this tutorial](https://pytorch.org/tutorials/beginner/basics/intro.html)\n",
    "* For more information on automatic differentiation in Pytorch, see this [this tutorial](https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Setup\n",
    "\n",
    "If you prefer to work locally, see the following instructions for setting up Python in a virtual environment.\n",
    "You can then ignore the instructions in \"Colab Setup\".\n",
    "\n",
    "If you haven't yet, create a [conda](https://docs.conda.io/projects/conda/en/latest/user-guide/install/index.html) environment using:\n",
    "```\n",
    "conda create --name rl_exercises\n",
    "conda activate rl_exercises\n",
    "```\n",
    "Torch recommends installation using conda rather than pip, so run:\n",
    "```\n",
    "conda install pytorch cpuonly -c pytorch\n",
    "```\n",
    "If you have a CUDA-enabled GPU and would like to use it, visit [the installation page](https://pytorch.org/get-started/locally/) to see the options available for different CUDA versions.\n",
    "The remaining dependencies can be installed with pip:\n",
    "```\n",
    "pip install matplotlib numpy ipykernel\n",
    "```\n",
    "\n",
    "Even if you are running the Jupyter notebook locally, please run the code cells in **Colab Setup**, because they define some global variables required later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colab Setup\n",
    "\n",
    "Google Colab provides you with a temporary environment for python programming.\n",
    "While this conveniently works on any platform and internally handles dependency issues and such, it also requires you to set up the environment from scratch every time.\n",
    "The \"Colab Setup\" section below will be part of **every** exercise and contains utility that is needed before getting started.\n",
    "\n",
    "There is a timeout of about ~12 hours with Colab while it is active (and less if you close your browser window).\n",
    "Any changes you make to the Jupyter notebook itself should be saved to your Google Drive.\n",
    "We also save all recordings and logs in it by default so that you won't lose your work in the event of an instance timeout.\n",
    "However, you will need to re-mount your Google Drive and re-install packages with every new instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Your work will be stored in a folder called `rl_ws24` by default to prevent Colab \n",
    "instance timeouts from deleting your edits.\n",
    "We do this by mounting your google drive on the virtual machine created in this colab \n",
    "session. For this, you will likely need to sign in to your Google account and allow\n",
    "access to your Google Drive files.\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/gdrive\")\n",
    "    COLAB = True\n",
    "except ImportError:\n",
    "    COLAB = False\n",
    "\n",
    "# Create paths in your google drive\n",
    "if COLAB:\n",
    "    DATA_ROOT = Path(\"/content/gdrive/My Drive/rl_ws24\")\n",
    "    DATA_ROOT.mkdir(exist_ok=True)\n",
    "else:\n",
    "    DATA_ROOT = Path.cwd() / \"rl_ws24\"\n",
    "\n",
    "# Install **python** packages\n",
    "if COLAB:\n",
    "    %pip install matplotlib numpy torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 0: Introduction\n",
    "\n",
    "This section specifies the actual exercise.\n",
    "For exercise 0, it just contains some simple tasks using numpy and pytorch.\n",
    "Later exercises will deal with more complex algorithms but will follow a similar structure.\n",
    "\n",
    "All homeworks are self-contained.\n",
    "They can be completed in their respective notebooks.\n",
    "Please fill in the missing code marked with `##TODO##` statements.\n",
    "To edit and re-run code, you can simply edit and restart the code cells below.\n",
    "When you are finished, you will need to submit the notebook as well as all saved figures as a zip file via Ilias.\n",
    "\n",
    "We start by importing all the necessary python modules and defining some helper functions which you do not need to change.\n",
    "Still, make sure you are aware of what they do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from IPython import display\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# specify the path to save the recordings of this run to.\n",
    "DATA_PATH = DATA_ROOT / \"exercise_0\" / time.strftime(\"%Y-%m-%d_%H-%M\")\n",
    "\n",
    "def save_figure(fig: plt.Figure, save_name: str) -> None:\n",
    "    \"\"\"Saves a figure into your google drive folder or local directory\"\"\"\n",
    "    DATA_PATH.mkdir(parents=True, exist_ok=True)\n",
    "    path = DATA_PATH / (save_name + \".png\")\n",
    "    fig.savefig(str(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1: Matrices and Vectors in Python\n",
    "As mentioned, we will use Python for the coding exercise.\n",
    "Additionally, for this and all following exercise we will use NumPy, one of the most fundamental python libraries,\n",
    "designed to efficiently create and operate on multi-dimensional arrays (vectors, matrices and higher order tensors).\n",
    "\n",
    "\n",
    "#### Create Matrices and Vectors in Python\n",
    "We first create a matrix\n",
    "\\begin{align*}A =\n",
    "\\begin{pmatrix}\n",
    "    1 & 2 & 3 \\\\\n",
    "    4 & 2 & 6 \\\\\n",
    "    7 & 3 & 8\n",
    "\\end{pmatrix}\n",
    "\\end{align*}\n",
    "and two vectors\n",
    "\n",
    "\\begin{align*} v =\n",
    "\\begin{pmatrix}\n",
    "    3  \\\\\n",
    "    1  \\\\\n",
    "    2\n",
    "\\end{pmatrix}, ~w =\n",
    "\\begin{pmatrix}\n",
    "    1  \\\\\n",
    "    1  \\\\\n",
    "    2\n",
    "\\end{pmatrix}\n",
    "\\end{align*}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us create a matrix A and vectors v and w:\n",
    "A = np.array([[1, 2, 3],\n",
    "              [4, 2, 6],\n",
    "              [7, 3, 8]])\n",
    "v = np.array([3, 1, 2])\n",
    "w = np.array([1, 1, 2])\n",
    "\n",
    "print(f\"Matrix A:\\n{A}\")\n",
    "print(f\"Vector v:\\n{v}\")\n",
    "print(f\"Vector w:\\n{w}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Operations with Vectors and Matrices\n",
    "\n",
    "Implement the  v + w and 2 $\\cdot$ A. Print out your results and verify that they are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can perform general element-wise operations:\n",
    "\n",
    "## TODO ##\n",
    "elem_wise_sum = ...  # do the element-wise sum v+w here\n",
    "## END ##\n",
    "print(elem_wise_sum)\n",
    "print(\"----------\")\n",
    "\n",
    "## TODO ##\n",
    "elem_wise_mult = ...  # do the element-wise multiplication 2*A here\n",
    "## END ##\n",
    "print(elem_wise_mult)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the matrix vector product A $\\cdot$ v. Print out your result and verify that the result is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To perform a matrix multiplication, use either np.dot or just the \"@\" symbol:\n",
    "\n",
    "## TODO ##\n",
    "matrix_vector_prod = ...  # do the matrix vector product A*v here\n",
    "## END ##\n",
    "print(matrix_vector_prod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the matrix matrix product A $\\cdot$ A. Print out your result and verify that the result is correct.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two matrices can be multiplied in the same fashion:\n",
    "\n",
    "## TODO ##\n",
    "matrix_matrix_prod = ...  # do the matrix matrix product A*A here\n",
    "## END ##\n",
    "print(matrix_matrix_prod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2: Sampling from a Gaussian\n",
    "In Machine Learning, it is often necessary to sample from a probability distribution.\n",
    "To sample from a Gaussian distribution (https://en.wikipedia.org/wiki/Normal_distribution).\n",
    "\n",
    "Sample 1000 samples from a Gaussian distribution with mean $\\mu = -2$ and standard deviation $\\sigma=0.5$.\n",
    "We also visualize the samples. For this we use matplotlib, a python package for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, sigma = -2, 0.5  # mean and standard deviation\n",
    "\n",
    "## TODO ##\n",
    "samples = ...  # do the sampling from the normal distribution here\n",
    "## END ##\n",
    "\n",
    "# plot the histogram of the samples\n",
    "count, bins, ignored = plt.hist(samples, 40, density=True)\n",
    "\n",
    "# plot the density function\n",
    "plt.plot(\n",
    "    bins,\n",
    "    1 / (sigma * np.sqrt(2 * np.pi)) * np.exp(-((bins - mu) ** 2) / (2 * sigma**2)),\n",
    "    linewidth=2,\n",
    "    color=\"r\",\n",
    ")\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do the same thing in Pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO ##\n",
    "samples = ...  # do the sampling from the normal distribution here\n",
    "## END ##\n",
    "\n",
    "# plot the histogram of the samples\n",
    "count, bins, ignored = plt.hist(samples.numpy(), 40, density=True)\n",
    "\n",
    "# plot the density function\n",
    "plt.plot(\n",
    "    bins,\n",
    "    1 / (sigma * np.sqrt(2 * np.pi)) * np.exp(-((bins - mu) ** 2) / (2 * sigma**2)),\n",
    "    linewidth=2,\n",
    "    color=\"r\",\n",
    ")\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3: Solving a Linear Equation\n",
    "\n",
    "You are given the linear equation\n",
    "\\begin{align*}\n",
    "Ax=v.\n",
    "\\end{align*}\n",
    "We want to find the vector x. Assume that the matrix A and the vector v are given as in Exercise 1.1.\n",
    "Find the solution for x. Hint: Use the function `np.linalg.solve`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To solve the linear equation system A x = v, you may use the np.linalg.solve function.\n",
    "# In other words we can use np.linalg.solve for inverting any matrix which does not stand\n",
    "# alone.\n",
    "\n",
    "## TODO ##\n",
    "x = ...  # solve for x here\n",
    "## END ##\n",
    "\n",
    "print(f\"Solution: {x=}\")\n",
    "print(f\"Test: {A@x=} is the same as {v=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.4: PyTorch\n",
    "\n",
    "PyTorch is strikingly similar to Numpy in terms of its API.\n",
    "While there are small differences (such as using *dim* instead of *axis* to specify a\n",
    "certain dimension), most numpy code is straightforward to convert into PyTorch code.\n",
    "\n",
    "The main point of PyTorch is that it allows for automatic differentiation. Whenever\n",
    "you perform some differentiable operation on its *Tensor* objects, the gradient of\n",
    "this operation is automatically tracked. This can be used for (and is at the core of)\n",
    "modern Deep and Reinforcement Learning.\n",
    "\n",
    "Below you find a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([2.0, 3.0], requires_grad=True)\n",
    "b = torch.tensor([6.0, 4.0], requires_grad=True)\n",
    "c = 3 * a**3 - b**2\n",
    "objective = c.sum()\n",
    "\n",
    "## TODO ##\n",
    "\"\"\"\n",
    "Perform a backward pass on the objective here. This can be done by calling the `backward` method of the `objective` Tensor.\n",
    "The backward pass will automatically compute the gradients for everything that went into the objective, such as a, b and c\n",
    "\"\"\"\n",
    "## END ##\n",
    "\n",
    "print(f\"Gradient of objective with respect to a: {a.grad}\")\n",
    "print(f\"Gradient of objective with respect to b: {b.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.5: PyTorch\n",
    "\n",
    "Now that you are familiar with the way that PyTorch tracks gradients through operations,\n",
    "it is time to fit your first model.\n",
    "For this, we create a torch *module* that represents the quadratic function\n",
    "\\begin{align*}\n",
    "f(x)=w_1x^2+w_2x+w_3\\text{,}\n",
    "\\end{align*}\n",
    "\n",
    "and fit it to a training function\n",
    "\\begin{align*}\n",
    "f(x)=3x^2-2x+5\n",
    "\\end{align*}\n",
    "\n",
    "using Stochastic Gradient Descent and a Mean Squared Error loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import MSELoss\n",
    "from torch.optim import SGD\n",
    "\n",
    "def target_function(positions: torch.Tensor) -> torch.Tensor:\n",
    "    targets = 3 * positions**2 - 2 * positions + 5\n",
    "    return targets\n",
    "\n",
    "def train_model(model, DATA_SIZE, NUM_EPOCHS):\n",
    "\n",
    "    loss_fn = MSELoss()  # mean squared error\n",
    "    optimizer = SGD(model.parameters(), lr=0.05)  # stochastic gradient descent\n",
    "\n",
    "    test_positions = torch.linspace(0, 1, 200)\n",
    "    test_targets = target_function(test_positions)\n",
    "\n",
    "    # setup plotting\n",
    "    fig, (ax_loss, ax_fit) = plt.subplots(1, 2)\n",
    "    fig.tight_layout()\n",
    "    ax_loss.set_xlim(0, NUM_EPOCHS)\n",
    "    ax_loss.set_yscale(\"log\")\n",
    "    ax_loss.set(title=\"Learning Curve\", xlabel=\"Epoch\", ylabel=\"Loss\")\n",
    "    line_loss, *_ = ax_loss.plot([], [], color=\"k\")\n",
    "    ax_fit.set(title=\"Model Fit\", xlabel=\"x\", ylabel=\"f(x)\")\n",
    "    ax_fit.plot(test_positions, test_targets, \"r\", label=\"Ground truth\")\n",
    "    line_prediction, *_ = ax_fit.plot([], [], \"b\", label=\"Model prediction\")\n",
    "    ax_fit.legend(loc=\"upper left\")\n",
    "\n",
    "    epoch_losses = []\n",
    "    for _ in range(NUM_EPOCHS):\n",
    "        try:\n",
    "            # draw data\n",
    "            positions = torch.rand((DATA_SIZE,))\n",
    "            targets = target_function(positions)\n",
    "\n",
    "            epoch_loss = 0  # reset loss for logging purposes\n",
    "            for position, target in zip(positions, targets):\n",
    "                prediction = model(position)  # compute outputs of neural network\n",
    "                loss = loss_fn(prediction, target)  # compute the loss for the predicted values\n",
    "                loss.backward()  # accumulate gradients in the model parameters\n",
    "\n",
    "                optimizer.step()  # increment the weights one step according to the gradients\n",
    "                optimizer.zero_grad()  # clear the gradients for the next iteration\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "            \n",
    "            epoch_loss = epoch_loss / DATA_SIZE\n",
    "            epoch_losses.append(epoch_loss)\n",
    "\n",
    "            # compare target function with current model\n",
    "            with torch.no_grad():  # perform a forward pass without a computation graph\n",
    "                test_predictions = model(torch.Tensor(test_positions)).numpy()\n",
    "            \n",
    "            # update plots\n",
    "            display.clear_output(wait=True)\n",
    "            line_loss.set_xdata(np.arange(len(epoch_losses)) + 1)\n",
    "            line_loss.set_ydata(epoch_losses)\n",
    "            ax_loss.relim()  # Recompute the data limits\n",
    "            ax_loss.autoscale_view()  # Autoscale to fit new data\n",
    "            line_prediction.set_xdata(test_positions)\n",
    "            line_prediction.set_ydata(test_predictions)\n",
    "            display.display(fig)\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            break\n",
    "\n",
    "    else:\n",
    "        # if training was not stopped via keyboard interrupt\n",
    "        save_figure(fig, \"loss_and_fit\")\n",
    "        display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuadraticFunction(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()  # required for any subclass of torch.nn.Module\n",
    "        self.coeffs = torch.nn.Parameter(torch.zeros(3))\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute a function of the form w1*x**2 + w2*x + w3\n",
    "        \"\"\"\n",
    "        ## TODO ##\n",
    "        # use the weights of the network to represent a quadratic function of the input x.\n",
    "        # you can access the coefficients with self.coeffs[0], self.coeffs[1] and self.coeffs[2]\n",
    "        prediction = ...\n",
    "        ## END ##\n",
    "        return prediction\n",
    "\n",
    "data_size = 1000\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "model = QuadraticFunction()\n",
    "\n",
    "train_model(model, data_size, NUM_EPOCHS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you implemented things correctly, you should now be able to fit the model to the ground truth\n",
    "function using the cell below. The cells below that measure the training loss and show a plot\n",
    "of your function next to the ground truth respectively."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
