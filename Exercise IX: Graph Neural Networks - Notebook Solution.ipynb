{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Science and AI for Energy Systems** \n",
    "\n",
    "Karlsruhe Institute of Technology\n",
    "\n",
    "Institute of Automation and Applied Informatics\n",
    "\n",
    "Summer Term 2024\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise IX: Graph Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark:** Use the updated docker image with version 1.0.1 (or arm-1.0.1) from this exercise onwards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch \n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from torch_geometric.data import Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils import to_networkx, to_dense_adj\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "from torchmetrics import R2Score\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem IX.2 (programming) - Dynamic Stability Assessment of Power Grids using Graph Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this programming task, we look into the dynamic stability assessment of power grids using graph neural networks. Specifically, we are interested in predicting the single-node basin stability (SNBS). The SNBS quantifies the probability that the system recovers following a perturbation.\n",
    "Here we use a dataset excerpt and code adapted from [Nauck et al.](https://pubs.aip.org/aip/cha/article/33/10/103103/2914062/Toward-dynamic-stability-assessment-of-power-grid). We want to predict the nodal SNBS using the adjacency matrix $A$ and the injected power $P$ per node as inputs. The prediction is purely based on the structure and topology of the grid. We compare results to a ground truth obtained by computationally intensive dynamical simulations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**(a) Load the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset class inheriting from torch_geometric.data.Dataset\n",
    "# the saved .pt files contain dataset instances of this class\n",
    "class SNBSDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        super(SNBSDataset, self).__init__()\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def get(self, index):\n",
    "        return self.data[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can load the datasets from the ```.pt``` files using ```torch.load()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torch.load('train_set.pt')\n",
    "valid_set = torch.load('valid_set.pt')\n",
    "test_set = torch.load('test_set.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**(b) Pick a single sample from the training set. For this sample:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_set[0]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(i) Print the adjacency matrix of the graph.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*hint: use ```to_dense_adj()``` from ```torch_geometric.utils``` to get the adjacency matrix from ```data.edge_index```*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = to_dense_adj(data.edge_index)\n",
    "adj_matrix = adj.squeeze(0)\n",
    "\n",
    "print(adj_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(ii) Visualize the graph and colour the nodes by their injected power.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*hint: you can use ```to_networkx``` from ```torch_geometric.utils``` to convert the graph to a networkx graph and then plot via the draw function in networkx. The node features are accessible via the ```.x``` attribute of a single sample.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = to_networkx(data, to_undirected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the node feature for each node\n",
    "node_labels = {i: f'{data.x[i, 0].item():.2f}' for i in range(data.num_nodes)}\n",
    "\n",
    "# Plot the graph with node features as labels\n",
    "plt.figure(figsize=(10, 10))\n",
    "nx.draw(G, labels=node_labels, node_color=data.x[:, 0], cmap=plt.get_cmap('coolwarm'), node_size=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(iii) Power grids are sparsely connected. According to [Schultz et al.](https://link.springer.com/article/10.1140/epjst/e2014-02279-6) their degree distribution has a local maximum at small degrees, an exponentially decaying tail, and a mean of around 2.8. Plot the degree distribution of this sample and compare it to these characteristics.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*hint: use the ```.degree()``` attribute of the networkx graph from the previous task*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot degree distribution\n",
    "degrees = [val for (node, val) in G.degree()]\n",
    "plt.hist(degrees, bins=20)\n",
    "plt.xlabel('Degree')\n",
    "plt.ylabel('# of nodes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_degree = sum(dict(G.degree()).values()) / G.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_degree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**(c) Complete the code for the GCN implementation in PyTorch geometric**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration dictionary\n",
    "cfg = {}\n",
    "\n",
    "# dataset batch sizes\n",
    "cfg[\"train_set::batchsize\"] = 19\n",
    "cfg[\"test_set::batchsize\"] = 500\n",
    "cfg[\"valid_set::batchsize\"] = 500\n",
    "\n",
    "# model settings\n",
    "cfg[\"num_layers\"] = 3\n",
    "cfg[\"num_channels\"] = [1, 20, 20, 1]\n",
    "\n",
    "cfg[\"activation\"] = [\"relu\",\"relu\",\"None\"]\n",
    "\n",
    "# training settings\n",
    "cfg[\"manual_seed\"] = 1\n",
    "cfg[\"epochs\"] = 400\n",
    "\n",
    "# threshoold for evaluation accuracy\n",
    "cfg[\"eval::threshold\"] = .1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start building the model with implementing the Graph Convolution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConvolutionModule(torch.nn.Module):\n",
    "    def __init__(self, num_channels_in, num_channels_out, activation):\n",
    "        super(GraphConvolutionModule, self).__init__()\n",
    "        self.activation = activation\n",
    "        self.conv = GCNConv(num_channels_in, num_channels_out, improved=False)\n",
    "\n",
    "    def forward(self, data, x):\n",
    "        x = self.conv(x, edge_index=data.edge_index)\n",
    "        if self.activation == \"relu\":\n",
    "            return F.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we implement the Graph Convolutional Network as ```torch.nn.Module``` and use the Graph Convolution as building block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConvolutionNetwork(torch.nn.Module):\n",
    "    def __init__(self, num_layers, num_channels, activation):\n",
    "        super(GraphConvolutionNetwork, self).__init__()\n",
    "\n",
    "\n",
    "        self.convlist = nn.ModuleList()\n",
    "        for i in range(0, num_layers):\n",
    "            num_c_in = num_channels[i]\n",
    "            num_c_out = num_channels[i+1]\n",
    "            conv = GraphConvolutionModule(\n",
    "                num_channels_in=num_c_in, num_channels_out=num_c_out, activation=activation[i])\n",
    "            self.convlist.append(conv)\n",
    "        self.endSigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = data.x\n",
    "        for i, _ in enumerate(self.convlist):\n",
    "            x = self.convlist[i](data, x)\n",
    "        x = self.endSigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**(d) Train a model and assess its performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNmodule(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(GNNmodule, self).__init__()\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = torch.device(\"cuda:0\")\n",
    "            self.cuda = True\n",
    "            print(\"cuda availabe:: send model to GPU\")\n",
    "        else:\n",
    "            self.cuda = False\n",
    "            self.device = torch.device(\"cpu\")\n",
    "            print(\"cuda unavailable:: train model on cpu\")\n",
    "\n",
    "        # seeds\n",
    "        torch.manual_seed(config[\"manual_seed\"])\n",
    "        torch.cuda.manual_seed(config[\"manual_seed\"])\n",
    "        np.random.seed(config[\"manual_seed\"])\n",
    "\n",
    "        if self.cuda:\n",
    "            torch.backends.cudnn.deterministic = True\n",
    "            torch.backends.cudnn.benchmark = False\n",
    "\n",
    "        model = GraphConvolutionNetwork(num_layers=config[\"num_layers\"], num_channels=config[\"num_channels\"], activation=config[\"activation\"])\n",
    "\n",
    "        model.to(self.device)\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "        # criterion\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.criterion.to(self.device)\n",
    "\n",
    "        # set optimizer\n",
    "        self.optimizer = optim.SGD(model.parameters(), lr=0.3, momentum=.9, weight_decay=1e-9)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # compute model prediction\n",
    "        y = self.model(x)\n",
    "        return y\n",
    "\n",
    "    def train_epoch_regression(self, data_loader, threshold):\n",
    "        self.model.train()\n",
    "        loss = 0.\n",
    "        correct = 0\n",
    "        all_labels = torch.Tensor(0).to(self.device)\n",
    "        all_predictions = torch.Tensor(0).to(self.device)\n",
    "        for _, (batch) in enumerate(data_loader):\n",
    "            batch.to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "            output = torch.squeeze(self.model.forward(batch))\n",
    "            labels = batch.y\n",
    "            temp_loss = self.criterion(output, labels)\n",
    "            temp_loss.backward()\n",
    "            self.optimizer.step()\n",
    "            correct += torch.sum((torch.abs(output - labels) < threshold))\n",
    "            loss += temp_loss.item()\n",
    "            all_labels = torch.cat([all_labels, labels])\n",
    "            all_predictions = torch.cat([all_predictions, output])\n",
    "        r2score = R2Score().to(self.device)\n",
    "        R2 = r2score(all_predictions, all_labels)\n",
    "        # accuracy\n",
    "        accuracy = 100 * correct / all_labels.shape[0]\n",
    "        return loss, accuracy.item(), R2.item()\n",
    "\n",
    "    def eval_model_regression(self, data_loader, threshold):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            loss = 0.\n",
    "            correct = 0\n",
    "            all_labels = torch.Tensor(0).to(self.device)\n",
    "            all_predictions = torch.Tensor(0).to(self.device)\n",
    "            for batch in data_loader:\n",
    "                batch.to(self.device)\n",
    "                labels = batch.y\n",
    "                output = torch.squeeze(self.model(batch))\n",
    "                temp_loss = self.criterion(output, labels)\n",
    "                loss += temp_loss.item()\n",
    "                correct += torch.sum((torch.abs(output - labels) < threshold))\n",
    "                all_predictions = torch.cat([all_predictions, output])\n",
    "                all_labels = torch.cat([all_labels, labels])\n",
    "            accuracy = 100 * correct / all_labels.shape[0]\n",
    "        r2score = R2Score().to(self.device)\n",
    "        R2 = r2score(all_predictions, all_labels)\n",
    "        return loss, accuracy.item(), R2.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model\n",
    "gnnmodule = GNNmodule(cfg)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_set, batch_size=cfg[\"train_set::batchsize\"], shuffle=True)\n",
    "valid_loader = DataLoader(\n",
    "    train_set, batch_size=cfg[\"valid_set::batchsize\"], shuffle=False)\n",
    "test_loader = DataLoader(\n",
    "    test_set, batch_size=cfg[\"test_set::batchsize\"], shuffle=False)\n",
    "\n",
    "train_loss_all_epochs = []\n",
    "train_accu_all_epochs = []\n",
    "train_R2_all_epochs = []\n",
    "\n",
    "test_loss_all_epochs = []\n",
    "test_accu_all_epochs = []\n",
    "test_R2_all_epochs = []\n",
    "\n",
    "epochs = cfg[\"epochs\"]\n",
    "for epoch in range(1,epochs):\n",
    "    print(f\"Epoch {epoch}/{epochs}.. \")\n",
    "    train_loss, train_accu, train_R2 = gnnmodule.train_epoch_regression(train_loader, cfg[\"eval::threshold\"])\n",
    "    train_loss_all_epochs.append(train_loss)\n",
    "    train_accu_all_epochs.append(train_accu)\n",
    "    train_R2_all_epochs.append(train_R2)\n",
    "    test_loss, test_accu, test_R2 = gnnmodule.eval_model_regression(test_loader, cfg[\"eval::threshold\"])\n",
    "    test_loss_all_epochs.append(test_loss)\n",
    "    test_accu_all_epochs.append(test_accu)\n",
    "    test_R2_all_epochs.append(test_R2)\n",
    "    print('train R2: ''{:3.2f}'.format(100 * train_R2) + '%')\n",
    "    print('train accu: ''{:3.2f}'.format(train_accu) + '%')\n",
    "    print('test R2: ''{:3.2f}'.format(100 * test_R2) + '%')\n",
    "    print('test accu: ''{:3.2f}'.format(test_accu) + '%')\n",
    "print(\"finished\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "language": "python",
   "name": ""
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
