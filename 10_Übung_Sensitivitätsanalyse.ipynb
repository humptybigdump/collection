{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geodatenanalyse 1\n",
    "\n",
    "## Übung 10: Sensitivitätsanalyse - Lösung"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 1: Contribution-to-Variance\n",
    "\n",
    "Als Anwendungsbeispiel für eine Sensitivitätsanalyse werden wir das Model und die Unsicherheitsanalyse aus der letzten Übung verwenden. Kopiert daher zuerst das Skript mit der MC Simulation in dieses Notebook, damit ihr alle Input- und Outputwerte als Variablen zur Verfügung habt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [1]\n",
    "# Monte-Carlo Simulation zur Bestimmung der Abbaurate von O-Xylol\n",
    "\n",
    "\n",
    "# number of MC simulations \n",
    "\n",
    "# input data \n",
    "# isotope shift delta 13C [o/oo], truncated to (3.8, 4.8)\n",
    "\n",
    "# isotope enrichment factor epsilon [-]\n",
    "\n",
    "# distance [m]\n",
    "\n",
    "# effective porosity [-], trunctaed to (0.12, 0.30)\n",
    "\n",
    "# time, truncated to (3e8, 3.3e8)\n",
    "\n",
    "# hydraulic gradient [-]\n",
    "\n",
    "# analytical model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für die Contribution-to-Variance Analyse und die Berechnung von Kovarianzen und Korrelationen ist es praktisch, alle benötigten Werte in einem Pandas DataFrame zusammenzufassen, um sicherzustellen, dass die Dimensionen, Ausrichtung von Spalten usw. alle stimmen. \n",
    "\n",
    "Das Generieren eines DataFrame erfolgt über die Funktion `pandas.DataFrame()`, mit dem Syntax: \"data = pd.DataFrame({'column_name': column_value, ...})\". Die Spalten und Namen könnt Ihr aus dem Output des Monte Carlo Codes zusammensetzen. \n",
    "\n",
    "Berechnet anschließend die Kovarianzen (`data.cov()`) und Korrelationen nach Pearson (`data.corr()`) für den DataFrame. Welches Maß macht hier mehr Sinn für eine Betrachtung der Sensitivitäten? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [2] \n",
    "# pandas package importieren\n",
    "\n",
    "# DataFrame generieren\n",
    "\n",
    "# Kovarianzen und Korrelation berechnen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stellt nun die Ergebnisse für die Sensitivitätsanalyse, sowohl für den kf-Wert als auch die Abbaurate mit Hilfe der Funktion `subplot` in `matplotlib` graphisch in einem Tornadoplot dar. Am einfachsten geht das über ein horizontales Blaknediagramm mit `matplotlib.pyplot.barh()`. \n",
    "\n",
    "Überlegt Euch auch genau welche Werte aus der Korrelations-, bzw- Kovarianzmatrix, in dem Plot dargestellt werden sollen, \n",
    "\n",
    "Fügt in der Abbildung schließlichen auch einen Titel (`title()`) und Achsenbeschrfitungen (`labels()`) ein.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [3] \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 2: Sobol Indizes\n",
    "\n",
    "Für fortgeschrittene Sensitivitätsanalysen gibt es in Python das Package `SALib` (https://salib.readthedocs.io/en/latest/index.html), in dem viele gängige Methoden (z.B. Morris Method, Sobol Indices) und die benötigten Sampling-Strategien implementiert sind. Um dieses benutzen zu können müsst ihr es zuerst in euer Python-Environment installieren. \n",
    "\n",
    "Zur Bestimmung der Sobol Indizes werden zwei Algorithmen aus SALib benötigt: Mit `SALib.sample.saltelli.sample()` erfolgt das Generieren der Input-Wertematrix, danach werden mit diesen Inputs die Modelloutputs erzeugt, und mit `SALib.analyze.sobol.analyze()` erfolgt schließlich die Bestimmung der Sobol-Indizes. \n",
    "\n",
    "`SALib.sample.saltelli.sample()` benötigt als Input-Argument ein Python Dictionary mit der folgenden Angaben: \n",
    "\n",
    "'{'num_vars': Anzahl_unsichere_Parameter, 'names': [Name1, Name2, ...], 'bounds':[[min1, max1], [min2, max2], ...]}'\n",
    "\n",
    "Definiert nun zuerst ein Python Dictionary mit den entsprechenden Angaben zu dem analytischen Abbaumodell aus den letzten Übungen, und erzeugt Euch dann mit `SALib.sample.saltelli.sample()` einen Inputdatensatz für das analytische Modell. \n",
    "\n",
    "Inspiziert anschließend den generierten Inputdatensatz um die  Sampling Strategie nachzuvollziehen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [4] \n",
    "# benötigtes Package importieren\n",
    "\n",
    "# Dictionary erzeugen\n",
    "\n",
    "# Inputmatrix erzeugen\n",
    "\n",
    "# Datensatz inspizieren\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Venwendet nun die eben erzeugten Modell-Inputs, um mit einer `for` Schleife und dem analytischen Modell der letzten Übungen die entsprechenden Outputs (hydraulische Leitfähigkeit und biologische Abbaurate) zu berechnen (siehe Übung 8 Monte Carlo Methoden). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [5]\n",
    "# Packages laden\n",
    "\n",
    "\n",
    "# Anzahl der Modelldurchläufe sowie leere Arrays für Outputs definieren \n",
    "\n",
    "\n",
    "# mit for-Schleife und analytischem Modell Outputs erzeugen\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als Inputs für `SALib.analyze.sobol.analyze()` sind das Eingangs-Dictionary, sowie die Modell-Ouputs erforderlich. Mit der zusätzlichen Angabe von \"print_to_console=True\" könnt Ihr Euch die Indizes direkt ausgeben lassen. \n",
    "\n",
    "Schaut Euch die Werte an, und vergleicht sie mit den Ergebnissen der Morris Method und Contribution-to-Variance Analyse. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[6]\n",
    "# Packages laden\n",
    "\n",
    "\n",
    "# Sobol Indizes berechnen\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um die Effekte Erster Ordnung und Totalen Effekte zu vergleichen, visualisiert diese abschließend in einer Graphik. Vergleicht dabei die verschiedenen Effekte in Bezug auf die einzelnen Parameter und interpretiert diese. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[7]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ende\n",
    "\n",
    "### Referenzen: \n",
    "\n",
    "Würth et al. (2021): Quantifying biodegradation rate constants of o-xylene by combining compound-specific isotope analysis and groundwater dating. Journal of Contaminant Hydrology, 238, 103757"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "e4cce46d6be9934fbd27f9ca0432556941ea5bdf741d4f4d64c6cd7f8dfa8fba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
