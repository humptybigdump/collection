{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be64febb",
   "metadata": {},
   "source": [
    "# ID3 from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f11159e",
   "metadata": {},
   "source": [
    "Let us import some libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a3716a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset loader utility for OpenML\n",
    "from openml.datasets import get_dataset\n",
    "# Working with data frames\n",
    "import pandas as pd\n",
    "# Matrices, n-dimensional arrays etc.\n",
    "import numpy as np\n",
    "# Encoder for labels --> integers\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3fdf26",
   "metadata": {},
   "source": [
    "Different data sets have different IDs on OpenML\n",
    "- we can load a dataset based on its id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65776f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "MUSHROOM = 24\n",
    "TICTACTOE = 50  # We are using this dataset today\n",
    "MONK1 = 333\n",
    "MONK2 = 334"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3011a9f1",
   "metadata": {},
   "source": [
    "## Utility functions and definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287fe99f",
   "metadata": {},
   "source": [
    "Shuffle dataframe by sampling from it with `frac=1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5aeba2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_df(df: pd.DataFrame):\n",
    "    return df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0710ad",
   "metadata": {},
   "source": [
    "### Decision tree utilities\n",
    "\n",
    "Utilities for checking \n",
    "1. if all values in a series are the same\n",
    "2. what the most common value in the given series is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69f8708f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_homogeneous(values: pd.Series):\n",
    "    return len(np.unique(values)) == 1\n",
    "\n",
    "\n",
    "def most_common_label(values: pd.Series):\n",
    "    values, counts = np.unique(values, return_counts=True)\n",
    "    most_frequent_index = np.argmax(counts)\n",
    "    return values[most_frequent_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede4d301",
   "metadata": {},
   "source": [
    "Entropy and information gain calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b457acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(values: pd.Series):\n",
    "    num_values = len(values)\n",
    "    unique_vals = np.unique(values)\n",
    "    probabilities = [\n",
    "        np.sum(values == this_value) / num_values\n",
    "        for this_value in unique_vals\n",
    "    ]\n",
    "    entropy = 0\n",
    "    for probability in probabilities:\n",
    "        entropy -= probability * np.log2(probability)\n",
    "    return entropy\n",
    "\n",
    "\n",
    "def information_gain(data: pd.DataFrame, attribute: str):\n",
    "    entropy_total =  entropy(data[\"class\"])\n",
    "    split_entropy = 0\n",
    "    for att_value, partition in data.groupby(attribute):\n",
    "        weight = len(partition) / len(data)\n",
    "        split_entropy += weight * entropy(partition[\"class\"])\n",
    "    return entropy_total - split_entropy\n",
    "\n",
    "\n",
    "def find_split_attribute(data: pd.DataFrame):\n",
    "        attributes = data.columns[data.columns != \"class\"].to_numpy()\n",
    "        IG_all_splits = [\n",
    "            information_gain(data, attribute) for attribute in attributes\n",
    "        ]\n",
    "        att_index = np.argmax(IG_all_splits)\n",
    "        return attributes[att_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2609a720",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "\n",
    "- our fundamental class is an `ID3` node in our decision tree\n",
    "- each node has\n",
    "    - children (if not a leaf node)\n",
    "    - some data (we may discard after building the tree)\n",
    "    - the assigned label (if a leaf node)\n",
    "    - a flag indicating if the node is a leaf\n",
    "    \n",
    "Note that ID3 works only with categorical data. Newer methods also can handle numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5a42f05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOLABEL = -1\n",
    "\n",
    "class ID3:\n",
    "    def __init__(self):\n",
    "        self.children = {}  # an empty dict, will take the form {att_value: child}\n",
    "        self.split_attribute = None\n",
    "        self.is_leaf = False\n",
    "        self.label = NOLABEL\n",
    "        self.default_prediction = None\n",
    "\n",
    "    def fit(self, data: pd.DataFrame):\n",
    "        # ID3 algorithm\n",
    "        labels = data[\"class\"].to_numpy()\n",
    "        attributes = data.columns[data.columns != \"class\"].to_numpy()\n",
    "        # check if this node should be a leaf node\n",
    "        if is_homogeneous(labels):\n",
    "            self.is_leaf = True\n",
    "            self.label = labels[0]\n",
    "        if len(attributes) == 0:\n",
    "            self.is_leaf = True\n",
    "            self.label = most_common_label(labels)\n",
    "        else:\n",
    "            self.split_attribute = find_split_attribute(data)\n",
    "            for att, partition in data.groupby(self.split_attribute):\n",
    "                # remove split attribute of this node from remaining partition\n",
    "                partition_wo_split_attribute = partition.drop(self.split_attribute, axis=1)\n",
    "                new_node = ID3()\n",
    "                if len(partition) == 0:\n",
    "                    label = most_common_label(labels)\n",
    "                    new_node.label = label\n",
    "                    new_node.is_leaf = True\n",
    "                else:\n",
    "                    # expand tree\n",
    "                    new_node = ID3()\n",
    "                    new_node.fit(partition_wo_split_attribute)\n",
    "                    self.children[att] = new_node\n",
    "                    self.default_prediction = most_common_label(data[\"class\"])\n",
    "\n",
    "    def predict(self, data: pd.DataFrame):\n",
    "        return np.array([\n",
    "            self.predict_instance(x) for _, x in data.iterrows()\n",
    "        ])\n",
    "            \n",
    "            \n",
    "    def predict_instance(self, x: pd.Series):\n",
    "        if self.is_leaf:\n",
    "            return self.label\n",
    "        else:\n",
    "            att_value = x[self.split_attribute]\n",
    "            if att_value in self.children.keys():\n",
    "                return self.children[att_value].predict_instance(x)\n",
    "            else:\n",
    "                return self.default_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b3e947",
   "metadata": {},
   "source": [
    "## Running our algorithm\n",
    "- define dataset\n",
    "- preprocess data\n",
    "- build tree\n",
    "- evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c41b876",
   "metadata": {},
   "source": [
    "We first load the data from OpenML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "60b32ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_dataset(dataset_id=TICTACTOE).get_data()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87664223",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "1. shuffle data\n",
    "2. rename target column (some are \"Class\" instead of \"class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4987c7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = shuffle_df(data)\n",
    "data.rename({\"Class\": \"class\"}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57856ad",
   "metadata": {},
   "source": [
    "Encode labels as integers (zeros and ones for binary classification)\n",
    "- we use the label encoder from scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6945dbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"class\"] = LabelEncoder().fit_transform(data[\"class\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafffccf",
   "metadata": {},
   "source": [
    "Split the data into 10 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f4279984",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "n_folds = 10\n",
    "folds = KFold(n_splits=n_folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da72395b",
   "metadata": {},
   "source": [
    "### Building the tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b8aadb",
   "metadata": {},
   "source": [
    "Fitting the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3526e70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = {\"ID3\": ID3()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bad0a6e",
   "metadata": {},
   "source": [
    "- Evaluate on training and test data\n",
    "- Store data in a nested list (we will afterwards convert to a data frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "59c0ce4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Data</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">ID3</th>\n",
       "      <th>Test</th>\n",
       "      <td>0.858081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Accuracy\n",
       "Algorithm Data           \n",
       "ID3       Test   0.858081\n",
       "          Train  1.000000"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_columns = [\"Algorithm\", \"Fold\", \"Data\", \"Accuracy\"]\n",
    "result = []\n",
    "for i, (train_indices, test_indices) in enumerate(folds.split(data)):\n",
    "    train, test = data.iloc[train_indices], data.iloc[test_indices]\n",
    "    for alg_name, algorithm in algorithms.items():\n",
    "        algorithm.fit(train)\n",
    "        \n",
    "        y_pred_test = algorithm.predict(test.drop(\"class\", axis=1))\n",
    "        correct_test = y_pred_test == test[\"class\"]\n",
    "        acc_test = np.mean(correct_test)\n",
    "        \n",
    "        y_pred_train = algorithm.predict(train.drop(\"class\", axis=1))\n",
    "        correct_train = y_pred_train == train[\"class\"]\n",
    "        acc_train = np.mean(correct_train)\n",
    "        \n",
    "        result.append([alg_name, i, \"Train\", acc_train])\n",
    "        result.append([alg_name, i, \"Test\", acc_test])\n",
    "        \n",
    "result_df = pd.DataFrame(result, columns=df_columns)\n",
    "result_df.groupby([\"Algorithm\", \"Data\"]).mean().drop(\"Fold\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd22fee",
   "metadata": {},
   "source": [
    "- we see that this tree overfits to the train data, its performance on test is much lower than on train.\n",
    "    - how can we solve this?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "E2_kernel",
   "language": "python",
   "name": "e2_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
