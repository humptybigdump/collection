{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# Teacing Maximum Likelihood via Applications\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "- (A) **Detecting ARCH effects**\n",
    "\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "- (B) **Fitting AR(1)-ARCH(1) using 2pass regressions**\n",
    "\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "- (C) **Fitting AR(1)-ARCH(1) using MLE**\n",
    "\n",
    "\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "- (D) **Fitting AR(1)-GARCH(1,1) using MLE**\n",
    "\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "- (E) **Comparison of Local and Global Optimization Routines**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Detecting ARCH Effects  \n",
    "\n",
    "We check whether there is evidence for heteroscedasticity in returns. For that, we fit an AR(1) to the return series and ask whether the resulting squared residuals show evidence of auto-correlation of order up to m. Note: You could fit any other mean equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Necessary Python packages\n",
    "import pandas as pd\n",
    "import pylab as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We load ES 50 return panel** \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_d = pd.read_csv('r_ES50_d_cleaned_realized_Nov2020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_d.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**we select one time series, say the equal-weight portfolio's return to ask whether there is evidence for time-variation in the second moment of that time-series**\n",
    "\n",
    "We answer this question by applying the Portmanteau Test to the squared residuals of an AR(1) fit to chosen return time-series. Notice: It is very unlikely that the conclusion depends on the  lag structure of the mean equation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Portmanteau test checks whether there is sufficient evidence for auto-correlation of lag length m in squared residuals. From our vol class you know already that squared residuals are a noisy proxy for variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_t = r_d[\"1/N\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portmanteau Test on Squared AR(1) Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.defs.Helper_TestingForARCHEffects import Portmanteau_Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PT = Portmanteau_Test(r_t.values, p, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PT_pvl = PT[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(PT_pvl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "    \n",
    "- **We reject $H_0$ of a constant vol in $r_t$**\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "- **We conclude $r_t$ is heteroscedastic**\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "- **We now have to think about how best to account for stochastic volatility in returns**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Fitting AR(1)-ARCH(1) using 2-Pass Regression\n",
    "\n",
    "- **Quick and a little dirty approach**\n",
    "\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "- **Yet, it is robust and provides good starting values for MLE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import math\n",
    "import scipy.optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Pass 1\":  Fit AR(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to fit mean equation and to get residuals.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = r_t.iloc[1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.ones((y.shape[0], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:,1] = r_t.iloc[:-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar1 = sm.OLS(y,X).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = ar1.resid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**summary stats of regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ar1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "    \n",
    "- **Daily equity returns are NOT predictable**\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "- **R2 of 0**\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "- **AR(1) coefficient of -0.0017 with a t-stat of -0.1**\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "- **Semi-strong Form of Market Efficiency: \"Current and past information does not help to predict future prices\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Pass 2\":  Fit ARCH(1)\n",
    "\n",
    "by fitting an AR(1) to squared AR(1) residuals of mean equation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize Squared Residuals of Mean Equation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(eps**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**fit ARCH(1) part**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = eps[1:]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.ones((y.shape[0], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:,1] = eps[:-1]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch_1 = sm.OLS(y, X).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**summary stats of ARCH(1) regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(arch_1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "- **AR(1) coefficient in eps^2 is significant (t-stat of 9.3)**\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "- **R2 is low (noisy variance measurement)**\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "- **Huge kurtosis and sizeable positive skew**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Are ARCH(1) Residuals Homoscedastic? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( Portmanteau_Test(arch_1.resid, 1, 10)[1]) #p-value of H_0 of homoscedastic innovations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**\n",
    "\n",
    "- **ARCH(1) residuals do still exhibit heteroscedasticity**\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "- **Ergo (1): ARCH(1) was not sufficient to eliminate all heteroscedasticity**\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "- **Ergo (2): ARCH(m), m>1 might be successful. MU: I doubt it (see skew and high excess kurtosis)**\n",
    " $$\n",
    "\\\\\n",
    "$$\n",
    "     \n",
    "- **Ergo (3): GARCH(m,s) might be successful. MU: I doubt it (see skew and high excess kurtosis)**\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "        \n",
    "- **What to Do? Depends on the precise question. If you want to get residuals to be homoscedastic, you need likely upward jumps in vol (skew) and vol in vol (excess kurtosis)**\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "- **.... But why do you really need homoscedastic residuals?**\n",
    "\n",
    "    - coefficients of linear regression ('return forecasting etc') remain unbiased (i.e. use Newey-West or other robust standard errors)\n",
    "    $$\n",
    "    \\\\\n",
    "    $$\n",
    "    \n",
    "    - for trading vol or careful risk management you need a precise vol estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(arch_1.resid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. Fitting AR(1)-ARCH(1) using MLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember: assuming Gaussian innovations one ends up with\n",
    "\n",
    "$$\n",
    "L_T(\\phi_0, \\phi_1, \\alpha_0, \\alpha_1) = \\prod_{t=2}^T \\frac{1}{\\sqrt{ 2 \\pi (\\alpha_0 + \\alpha_1 \\epsilon^2_{t-1})}} \\times \\exp\\left( -\\frac{(r_t - [\\phi_0 + \\phi_1 r_{t-1}])^2}{2 (\\alpha_0 + \\alpha_1 \\epsilon^2_{t-1})} \\right)\n",
    "$$\n",
    "\n",
    "Remember:\n",
    "$$\n",
    "\\ln (L_T(.)) = \\sum_{t=2}^T -\\frac{1}{2} \\ln(2\\pi [\\alpha_0 + \\alpha_1 \\epsilon^2_{t-1}]) - \\frac{1}{2}  \\frac{(r_t - [\\phi_0 + \\phi_1 r_{t-1}])^2}{2 (\\alpha_0 + \\alpha_1 \\epsilon^2_{t-1})} \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -ln( L_T(.) )\n",
    "\n",
    "def Neg_loglikelihood_ar1_arch1(parameters):   # Parameters is a list of model parameters, here: [\\phi_0, phi_1, alpha_0, alpha_1   ]  \n",
    "    phi_0   = parameters[0]\n",
    "    phi_1   = parameters[1]\n",
    "    alpha_0 = parameters[2]\n",
    "    alpha_1 = parameters[3]\n",
    "\n",
    "    means = phi_0 + phi_1 * r_t.iloc[:-1].values\n",
    "    eps   = r_t.iloc[1:].values - means\n",
    "    vars_  = alpha_0 + alpha_1 * eps[:-1]**2\n",
    "       \n",
    "    loglikeli = np.sum(-0.5 * np.log(2 * math.pi * vars_) - (r_t.iloc[2:].values - means[1:])**2 / (2 * vars_))\n",
    "\n",
    "    return -loglikeli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical Optimization of AR(1)-ARCH(1)- ln (L_T(.)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Smart Starting Values: here from 2-pass estimation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar1_arch1_params_start = [ar1.params[0], ar1.params[1], arch_1.params[0], arch_1.params[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ar1_arch1_params_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nelder-Mead (Local) Optimization\n",
    "i.e. https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar1_arch1_params_optimal = scipy.optimize.minimize(Neg_loglikelihood_ar1_arch1, ar1_arch1_params_start, method = 'Nelder-Mead', options={'disp':True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print optimal AR(1)-ARCH(1) params**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ar1_arch1_params_optimal.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  D. Fitting AR(1)-GARCH(1,1) using MLE\n",
    "\n",
    "Note: assuming Gaussian innovations one ends up with\n",
    "\n",
    "$$\n",
    "L_T(\\phi_0, \\phi_1, \\alpha_0, \\alpha_1, \\beta_1, \\sigma_1) = \\prod_{t=2}^T \\frac{1}{\\sqrt{ 2 \\pi (\\alpha_0 + \\alpha_1 \\epsilon^2_{t-1} + \\beta_1 \\sigma^2_{t-1})}} \\times \\exp\\left( -\\frac{(r_t - [\\phi_0 + \\phi_1 r_{t-1}])^2}{2 (\\alpha_0 + \\alpha_1 \\epsilon^2_{t-1}+ \\beta_1 \\sigma^2_{t-1})} \\right)\n",
    "$$\n",
    "with $\\sigma^2_t = \\alpha_0 + \\alpha_1 \\epsilon^2_{t-1} + \\beta_1 \\sigma^2_{t-1}, s.t. \\sigma^2_1 = \\text{known parameter}$\n",
    "\n",
    "Note:\n",
    "$$\n",
    "\\ln (L_T(.)) = \\sum_{t=2}^T -\\frac{1}{2} \\ln(2\\pi [\\alpha_0 + \\alpha_1 \\epsilon^2_{t-1}+ \\beta_1 \\sigma^2_{t-1}]) - \\frac{1}{2}  \\frac{(r_t - [\\phi_0 + \\phi_1 r_{t-1}])^2}{2 (\\alpha_0 + \\alpha_1 \\epsilon^2_{t-1}+ \\beta_1 \\sigma^2_{t-1})} \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate sigma^2_t parametrically using the GARCH(1,1) recursion\n",
    "\n",
    "def garch11_variance(alpha_0, alpha_1, beta_1, sigma2_1, epsilon):\n",
    "    sigma2 = np.zeros(epsilon.shape[0] - 1)\n",
    "    sigma2[0] = alpha_0 + alpha_1 * epsilon[0]**2 + beta_1 * sigma2_1 \n",
    "    for i in range(1, sigma2.shape[0]):\n",
    "        sigma2[i] = alpha_0 + alpha_1 * epsilon[i]**2 + beta_1 * sigma2[i-1]\n",
    "    \n",
    "    return sigma2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -ln( L_T(.) )\n",
    "\n",
    "def Neg_loglikelihood_ar1_Garch11(parameters):   # Parameters is a list of model parameters, here: [\\phi_0, phi_1, alpha_0, alpha_1, beta_1, sigma2_1]\n",
    "    phi_0   = parameters[0]\n",
    "    phi_1   = parameters[1]\n",
    "    alpha_0 = parameters[2]\n",
    "    alpha_1 = parameters[3]\n",
    "    beta_1  = parameters[4]\n",
    "    sigma2_1= parameters[5]\n",
    "    \n",
    "    means = phi_0 + phi_1 * r_t.iloc[:-1].values\n",
    "    eps   = r_t.iloc[1:].values - means\n",
    "    vars_  = garch11_variance(alpha_0, alpha_1, beta_1, sigma2_1, eps)\n",
    "       \n",
    "    loglikeli = np.sum(-0.5 * np.log(2 * math.pi * vars_) - (r_t.iloc[2:].values - means[1:])**2 / (2 * vars_))\n",
    "\n",
    "    return -loglikeli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical Optimization of AR(1)-GARCH(1,1)- ln (L_T(.)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Smart Starting Values: here: AR(1)-ARCH(1) 2-pass Estimates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar1_Garch11_params_start = [ar1.params[0], ar1.params[1], arch_1.params[0], arch_1.params[1], 0.01,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ar1_Garch11_params_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nelder-Mead (Local Optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar1_Garch11_params_optimal = scipy.optimize.minimize(Neg_loglikelihood_ar1_Garch11, ar1_Garch11_params_start, method = 'Nelder-Mead', options={'disp':True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print Optimal AR(1)-GARCH(1,1) Params**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ar1_Garch11_params_optimal.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E. Comparing Optimization Routines, applied to AR(1)-GARCH(1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3 (4) Local Routines**\n",
    "\n",
    "- Nelder Mead\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "- SLSQP\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "- BFGS\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "- Python Package for ARMA-GARCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2 Global Routines**\n",
    "\n",
    "- Dual Annealing\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "- Evolutionary Algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**package to add bounds to local optimization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import Bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E.1 Local Optimization: SLSQP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar1_Garch11_params_optimal_constr = scipy.optimize.minimize(Neg_loglikelihood_ar1_Garch11,\n",
    "                                                            ar1_Garch11_params_start, method='SLSQP',\n",
    "                                                            bounds=Bounds(np.zeros(6),np.ones(6)*1), options={'disp':True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E.2 Local Optimization: Quasi-Newton of Broyden, Fletcher, Goldfarb, Shanno (BFGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar1_Garch11_params_optimal_constr_bfgs_x, f_bgfs, _ = scipy.optimize.fmin_l_bfgs_b(Neg_loglikelihood_ar1_Garch11, x0=ar1_Garch11_params_start, bounds=[(0,1)]*6, approx_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E.3 Python's ARCH Package\n",
    "\n",
    "$$r_t=const+ \\phi r_{t-1}+\\epsilon_t$$\n",
    "$$\\sigma^2_t = \\omega + \\alpha \\epsilon_{t-1}^2 +\\beta \\sigma^2_{tâˆ’1}$$\n",
    "$$\\epsilon_t= \\sigma_t e_t,\\ e_t \\sim \\mathcal{N}(0,1)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arch import arch_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate the AR(1)-GARCH(1,1) Model\n",
    "am = arch_model(r_t, lags=1, mean=\"AR\", vol=\"Garch\", dist=\"Normal\", rescale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the AR(1)-GARCH(1,1)\n",
    "res = am.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E.4 Global Optimization: DUAL ANNEALING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar1_Garch11_params_optimal_constr_go_ann = scipy.optimize.dual_annealing(Neg_loglikelihood_ar1_Garch11, [(0,1)]*6, x0=ar1_Garch11_params_start,  seed=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E.5 Global Optimization: Evolutionary Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar1_Garch11_params_optimal_constr_go_de = scipy.optimize.differential_evolution(Neg_loglikelihood_ar1_Garch11, [(0,1)]*6, seed=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E.6 Compare L_opt for AR(1)-GARCH(1,1) Across Optimization Routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Lopt = pd.DataFrame({\"BFGS: Quasi-Newton\": -f_bgfs,\n",
    "                   \"Dual Annealing\": -ar1_Garch11_params_optimal_constr_go_ann.fun ,\n",
    "                   \"arch_pckge\": res.loglikelihood,\n",
    "                  \"Nelder-Mead \": -ar1_Garch11_params_optimal.fun,\n",
    "                   \"Evolut.Algo\" : -ar1_Garch11_params_optimal_constr_go_de.fun ,\n",
    "                   \"SLSQP\": -ar1_Garch11_params_optimal_constr.fun,    \n",
    "                   }, index=[\"L_opt\"])\n",
    " \n",
    "df_Lopt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E.7 Compare x_opt for AR(1)-GARCH(1,1) Across Optimization Routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = pd.DataFrame({\"BFGS: Quasi-Newton\": ar1_Garch11_params_optimal_constr_bfgs_x[:-1].round(5), \n",
    "                     \"Dual Annealing\": ar1_Garch11_params_optimal_constr_go_ann.x[:-1].round(5),\n",
    "                     \"arch_pckge\": res.params.values,\n",
    "                     \"Nelder-Mead\": ar1_Garch11_params_optimal.x[:-1].round(5),\n",
    "                     \"Evolut.Algo\": ar1_Garch11_params_optimal_constr_go_de.x[:-1].round(5),\n",
    "                     \"SLSQP\": ar1_Garch11_params_optimal_constr.x[:-1].round(5) ,            \n",
    "                     },\n",
    "                    index=[\"phi_0\",\"phi_1\",\"alpha_0\",\"alpha_1\",\"beta_1\"])\n",
    "df_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation w.r.t. Choice of Optimizer\n",
    "\n",
    "- **Choice of optimizer is crucial**\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "- **Different optimization routines succeed for different problems**\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "- **Try at least one global (like Dual Annealing), especially for high dimensional problems (more than 5 variables) problems**\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "- **If you use local optimizers: randomize start values**\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "- **USE SMART (INFORMATIVE) START VALUES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
