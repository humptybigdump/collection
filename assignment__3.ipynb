{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Machine Vision 2022/23 - Assignment 7: Deep Learning\n",
    "\n",
    "In this exercises you will apply different concepts of deep learning in order to classify images of traffic signs. While working through this notebook, different links to official web-sites or blog-posts are provided for additional information.\n",
    "This exercise uses the Tensorflow framework, which is one of the most popular deep learning frameworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "tf.get_logger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### Preparation\n",
    "\n",
    "##### German Traffic Sign Recognition Benchmark\n",
    "\n",
    "The German Traffic Sign Recognition Benchmark [(GTSRB)](https://benchmark.ini.rub.de/) is a competition that was held at the IJCNN 2011. In this competition images of traffic signs should be classified.\n",
    "You will implement your own neural network to classify a subset of the GTSRB dataset. This subset consists of `12` different classes, which are shown in the figures below. However, you are free to extend your solution to the full dataset.\n",
    "\n",
    "\n",
    "|---|------------------------------|-------------------------------|-------------------------------|-------------------------------|-------------------------------|-------------------------------|-------------------------------|-------------------------------|-------------------------------|--------------------------------|--------------------------------|--------------------------------|\n",
    "|  ![Class 0](res/images/0.png) | ![Class 1](res/images/6.png) | ![Class 2](res/images/16.png) | ![Class 3](res/images/17.jpg) | ![Class 4](res/images/19.png) | ![Class 5](res/images/22.jpg) | ![Class 6](res/images/28.png) | ![Class 7](res/images/29.png) | ![Class 8](res/images/32.png) | ![Class 9](res/images/33.png) | ![Class 10](res/images/38.png) | ![Class 11](res/images/40.png) |\n",
    "<br></br>\n",
    "\n",
    "In order to simplify this exercise, the raw GTSRB images are already transformed into a dataset, where each image has the shape of `[H,W,C]` (Height x Width x Channels) with values ranging from `0-1`.\n",
    "Furthermore, the dataset is split into a train-, validation- and test-dataset, where the train- and validation-datasets are provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 12\n",
    "\n",
    "def get_datasets(*, images, labels, shuffle=True):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((np.load(images), np.load(labels)))\n",
    "\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(1024)\n",
    "\n",
    "    return ds.batch(32)\n",
    "\n",
    "# Create a dataset for training\n",
    "train_ds = get_datasets(\n",
    "    images=\"res/images_train.npy\",\n",
    "    labels=\"res/labels_train.npy\",\n",
    ")\n",
    "# Create a dataset for validation\n",
    "val_ds = get_datasets(\n",
    "    images=\"res/images_val.npy\",\n",
    "    labels=\"res/labels_val.npy\",\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The `gen_datasets` function creates a [Tensorflow dataset](https://blog.tensorflow.org/2019/02/introducing-tensorflow-datasets.html) from two numpy arrays containing the images and the corresponding ground truth class labels.\n",
    "\n",
    "A Tensorflow dataset is a python class, which provide an easy way iterate a dataset. Each iteration, the dataset returns a batch of `x = [Bx32x32x3]` images and `y = [Bx12]` class labels, where B is the batch size.\n",
    "\n",
    "There are different approaches to encode the class label. For further information you can read this blog entry [integer- or one-hot-encoding](https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/).\n",
    "In this exercise the labels are encoded in one-hot format. Which means, that each label is a vector of 12 entries, where only the entry of the class has the value $1$ and all others values are $0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_batch, y_batch = next(iter(train_ds))\n",
    "\n",
    "# @student: print the image and label shape of a batch\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# @student: show one image of the batch and its label\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### Execution\n",
    "\n",
    "In order to compare models against each other metrics are calculated on an unseen test dataset. In this exercise you should try to develop your own model and upload the `final_model` directory to ilias.\n",
    "All submitted models are compared to each other using the accuracy metric.\n",
    "\n",
    "**The student that submits the best model will be given the chance to be in the passenger seat while our autonomous car drives around the adenauer ring**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_model(image_shape):\n",
    "    input = tf.keras.layers.Input(shape=image_shape)\n",
    "    # @student: implement your neural network\n",
    "\n",
    "    outputs = ...\n",
    "\n",
    "    return tf.keras.Model(inputs=input, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In the `create_model` function you can define your own neural network using the [functional tensorflow API](https://www.tensorflow.org/guide/keras/functional).\n",
    "You can also use other tensorflow APIs like the [SequentialModel](https://www.tensorflow.org/guide/keras/sequential_model). However, when transitioning to complex architectures the functional API provides the more flexibility.\n",
    "\n",
    "\n",
    "You are free to use any layer and activation provided by tensorflow for example:\n",
    "[tf.keras.layers.Conv2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D)\n",
    "[tf.keras.layers.Dropout](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout)\n",
    "[tf.keras.layers.AveragePooling2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/AveragePooling2D)\n",
    "[tf.keras.layers.Flatten](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten)\n",
    "[tf.keras.layers.Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense)\n",
    "[tf.keras.activations.relu](https://www.tensorflow.org/api_docs/python/tf/keras/activations/relu)\n",
    "\n",
    "For inspiration you can take a look at these ground-breaking publications:\n",
    "[LeNet](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf)\n",
    "[AlexNet](https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf)\n",
    "[GoogLeNet](https://arxiv.org/pdf/1409.4842.pdf)\n",
    "[ResNet](https://arxiv.org/pdf/1512.03385.pdf)\n",
    "[ViT](https://arxiv.org/abs/2010.11929)\n",
    "[Swin Transformer](https://arxiv.org/abs/2103.14030)\n",
    "[ConvNext](https://arxiv.org/abs/2201.03545)\n",
    "\n",
    "Additionally, you can also add data augmentation to the training data in order to improve the generalization of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = create_model(image_shape=(32,32,3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-3)\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "acc_metric = tf.keras.metrics.CategoricalAccuracy(name=\"accuracy\")\n",
    "model.compile(optimizer, loss=loss_fn, metrics=[acc_metric])\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    epochs=25,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.ModelCheckpoint(filepath=\"final_model\", monitor='val_accuracy', mode='max', save_best_only=True)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"final_model/\")\n",
    "loss, acc = model.evaluate(val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### From Logits to Labels\n",
    "\n",
    "Your network will output logits as long as you use `tf.keras.losses.CategoricalCrossentropy` as loss function.\n",
    "However, if you want to manually infer you have to calculate the predicted label based on the logits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pred_logit = model.predict(val_ds)\n",
    "y_labels = [labels for _, labels in val_ds.unbatch()]\n",
    "y_labels = tf.argmax(y_labels, axis=1)\n",
    "\n",
    "\n",
    "# @student: pred_logit are the predicted logits of your model, while y_labels are the ground truth labels.\n",
    "# calculate the labels from the logits\n",
    "...\n",
    "pred_labels = ...\n",
    "\n",
    "\n",
    "confusion_matrix = tf.math.confusion_matrix(y_labels, pred_labels, num_classes=NUM_CLASSES)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix.numpy())\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}