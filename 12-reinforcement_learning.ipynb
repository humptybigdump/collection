{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Science and AI for Energy Systems** \n",
    "\n",
    "Karlsruhe Institute of Technology\n",
    "\n",
    "Institute of Automation and Applied Informatics\n",
    "\n",
    "Summer Term 2024\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise XII: Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark:** Use the updated docker image with version 1.0.1 (or arm-1.0.1) from this exercise onwards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T06:36:59.601666Z",
     "start_time": "2024-07-15T06:36:58.062768Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from collections import deque\n",
    "import random\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# import gym\n",
    "# from gym import spaces\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem XII.3 (programming) - Implementing Deep Reinforcement Learning Methods in A Building Energy Management Problem "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this programming task, we will work on a building installed with photovoltaic (PV) panels and batteries (storage). Data to be used here is named as `building_battery_data.csv`. This data is recorded from a house within this project [SonyCSL](https://www.sonycsl.co.jp/tokyo/daisuke/14820/). Below is a figure showing the configuration of the building.\n",
    "<img src=\"house.png\" alt=\"Local Image\" width=\"800\">\n",
    "The energy flow of this building can be simplified as\n",
    "<img src=\"flow.png\" alt=\"Local Image\" width=\"1200\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**(a) Load the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T06:36:59.605064Z",
     "start_time": "2024-07-15T06:36:59.603140Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO ???\n",
    "# load dataset and plot the first day data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deep Q-Network Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNNet():\n",
    "    \n",
    "    def __init__(self, state_size, action_size, learning_rate):\n",
    "\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.model = self.create_model()\n",
    "\n",
    "    def create_model(self):\n",
    "        \n",
    "        # state_size = (3, ) \n",
    "        input = Input(shape = self.state_size)\n",
    "\n",
    "        x = Dense(64, activation = \"relu\", \n",
    "                  kernel_initializer = glorot_uniform(seed = 42))(input)\n",
    "        x = Dense(256, activation = \"relu\",\n",
    "                  kernel_initializer = glorot_uniform(seed = 42))(x)\n",
    "\n",
    "        output = Dense(self.action_size, activation = \"linear\", \n",
    "                  kernel_initializer = glorot_uniform(seed = 42))(x)\n",
    "\n",
    "        model = Model(inputs = [input], outputs = [output])\n",
    "        model.compile(loss = \"mse\", optimizer = Adam(lr = self.learning_rate))\n",
    "        model.summary()\n",
    "\n",
    "        return model  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Memory Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A tree based array containing priority of each experience for fast sampling\n",
    "# This SumTree code is a modified version and the original code is from:\n",
    "# https://github.com/jaromiru/AI-blog/blob/master/SumTree.py\n",
    "\n",
    "class SumTree():\n",
    "            \n",
    "    \"\"\"\n",
    "    __init__ - create data array storing experience and a tree based array storing priority\n",
    "    add - store new experience in data array and update tree with new priority\n",
    "    update - update tree and propagate the change through the tree\n",
    "    get_leaf - find the final nodes with a given priority value\n",
    "    \n",
    "    store data with its priority in the tree.\n",
    "    \"\"\"\n",
    "\n",
    "    data_pointer = 0\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "          \n",
    "        \"\"\"\n",
    "        capacity - Number of final nodes containing experience, for all priority values\n",
    "        data - array containing experience (with pointers to Python objects), for all transitions\n",
    "        tree - a tree shape array containing priority of each experience\n",
    "\n",
    "        tree index:\n",
    "            0       -> storing priority sum\n",
    "           / \\\n",
    "          1   2\n",
    "         / \\ / \\\n",
    "        3  4 5  6   -> storing priority for transitions\n",
    "        \n",
    "        Array type for storing:\n",
    "        [0, 1, 2, 3, 4, 5, 6]\n",
    "        \"\"\"\n",
    "        \n",
    "        self.capacity = capacity        \n",
    "        self.tree = np.zeros(2 * capacity - 1)\n",
    "        self.data = np.zeros(capacity, dtype = object)\n",
    "\n",
    "    def add(self, priority, data):\n",
    "        \n",
    "        # Start from first leaf node of the most bottom layer\n",
    "        tree_index = self.data_pointer + self.capacity - 1\n",
    "\n",
    "        self.data[self.data_pointer] = data # Update data frame\n",
    "        self.update(tree_index, priority) # Update priority\n",
    "\n",
    "        # Overwrite if exceed memory capacity\n",
    "        self.data_pointer += 1\n",
    "        if self.data_pointer >= self.capacity:\n",
    "            self.data_pointer = 0\n",
    "\n",
    "    def update(self, tree_index, priority):\n",
    "\n",
    "        # Change = new priority score - former priority score\n",
    "        change = priority - self.tree[tree_index] \n",
    "        self.tree[tree_index] = priority\n",
    "\n",
    "        # Propagate the change through tree\n",
    "        while tree_index != 0:  # this method is faster than the recursive loop in the reference code\n",
    "            tree_index = (tree_index - 1) // 2\n",
    "            self.tree[tree_index] += change\n",
    "\n",
    "    def get_leaf(self, v):\n",
    "\n",
    "        parent_index = 0\n",
    "\n",
    "        while True:  # while loop is faster than the method in the reference code\n",
    "            left_child_index = 2 * parent_index + 1  # this leaf's left and right kids\n",
    "            right_child_index = left_child_index + 1\n",
    "            # Downward search, always search for a higher priority node till the last layer\n",
    "            if left_child_index >= len(self.tree): # reach the bottom, end search\n",
    "                leaf_index = parent_index\n",
    "                break\n",
    "            else:    # downward search, always search for a higher priority node\n",
    "                if v <= self.tree[left_child_index]:\n",
    "                    parent_index = left_child_index\n",
    "                else:\n",
    "                    v -= self.tree[left_child_index]\n",
    "                    parent_index = right_child_index\n",
    "\n",
    "        data_index = leaf_index - self.capacity + 1\n",
    "\n",
    "        # tree leaf index, priority, experience\n",
    "        return leaf_index, self.tree[leaf_index], self.data[data_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory():  # stored as (s, a, r, s_) in SumTree\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    __init__ - create SumTree memory\n",
    "    store - assign priority to new experience and store with SumTree.add & SumTree.update\n",
    "    sample - uniformly sample from the range between 0 and total priority and \n",
    "           retrieve the leaf index, priority and experience with SumTree.get_leaf\n",
    "    batch_update - update the priority of experience after training with SumTree.update\n",
    "\n",
    "    PER_e - Hyperparameter that avoid experiences having 0 probability of being taken\n",
    "    PER_a - Hyperparameter that allows tradeoff between taking only experience with \n",
    "          high priority and sampling randomly (0 - pure uniform randomness, 1 -\n",
    "          select experiences with the highest priority), convert the importance of TD error to priority\n",
    "    PER_b - Importance-Sampling (IS), from initial value increasing to 1, control how much beta\n",
    "          IS affect learning\n",
    "    \"\"\"\n",
    "  \n",
    "    PER_e = 0.01 \n",
    "    PER_a = 0.6\n",
    "    PER_b = 0.4\n",
    "    PER_b_increment_per_sampling = 0.001\n",
    "    absolute_error_upper = 1.  # Clipped abs error\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.tree = SumTree(capacity)\n",
    "\n",
    "    def store(self, experience):\n",
    "        \n",
    "        # Find the max priority\n",
    "        max_priority = np.max(self.tree.tree[-self.tree.capacity:])\n",
    "\n",
    "        # If the max priority = 0, this experience will never have a chance to be selected\n",
    "        # So a minimum priority is assigned\n",
    "        if max_priority == 0:\n",
    "            max_priority = self.absolute_error_upper\n",
    "\n",
    "        self.tree.add(max_priority, experience)  # set the max priority for new priority\n",
    "\n",
    "    def sample(self, n):\n",
    "        \n",
    "        \"\"\"\n",
    "        First, to sample a minibatch of k size, the range [0, priority_total] is\n",
    "        divided into k ranges. A value is uniformly sampled from each range. Search \n",
    "        in the sumtree, the experience where priority score correspond to sample \n",
    "        values are retrieved from. Calculate IS weights for each minibatch element\n",
    "        \"\"\"\n",
    "\n",
    "        b_idx = np.empty((n, ), dtype=np.int32)\n",
    "        b_memory = [] # np.empty((n, self.tree.data[0].size))        \n",
    "        b_ISWeights =  np.empty((n, 1))\n",
    "\n",
    "        priority_segment = self.tree.tree[0] / n   \n",
    "\n",
    "        self.PER_b = np.min([1., self.PER_b + self.PER_b_increment_per_sampling]) # max = 1\n",
    "\n",
    "        prob_min = np.min(self.tree.tree[-self.tree.capacity:]) / self.tree.tree[0] # for later calculate ISweight\n",
    "        max_weight = (prob_min * n) ** (-self.PER_b)\n",
    "\n",
    "        for i in range(n):\n",
    "            a = priority_segment * i\n",
    "            b = priority_segment * (i + 1)\n",
    "            value = np.random.uniform(a, b)\n",
    "            index, priority, data = self.tree.get_leaf(value)\n",
    "            prob = priority / self.tree.tree[0]\n",
    "            b_ISWeights[i, 0] = (prob * n) ** (-self.PER_b) / max_weight               \n",
    "            b_idx[i]= index\n",
    "            b_memory.append([data])\n",
    "\n",
    "        return b_idx, b_memory, b_ISWeights\n",
    "\n",
    "    def batch_update(self, tree_idx, abs_errors):\n",
    "        # To avoid 0 probability\n",
    "        abs_errors += self.PER_e # convert to abs and avoid 0\n",
    "        clipped_errors = np.minimum(abs_errors, self.absolute_error_upper)\n",
    "        ps = np.power(clipped_errors, self.PER_a)\n",
    "\n",
    "        for ti, p in zip(tree_idx, ps):\n",
    "            self.tree.update(ti, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**(b) Set up the environment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T06:36:59.607740Z",
     "start_time": "2024-07-15T06:36:59.605817Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO ???\n",
    "# Define the Battery environment\n",
    "class BatteryEnv():\n",
    "    \n",
    "    def __init__(self, action_size):\n",
    "        \"\"\"\n",
    "        coeff_d - discharge coefficient\n",
    "        coeff_c - charge coefficient\n",
    "\n",
    "        wear cost is not considered at this moment\n",
    "        actions space is 3, where\n",
    "        a = -1, battery discharge\n",
    "        a = 0,  battery in idle\n",
    "        a = 1,  battery charge\n",
    "        \"\"\"\n",
    "        self.action_set      = np.linspace(-35, 35, num=action_size, endpoint=True)\n",
    "        self.initial_rsoc    = 30.\n",
    "        self.coeff_c         = 0.02\n",
    "        self.coeff_d         = 0.02\n",
    "        self.decay           = 0.0018\n",
    "\n",
    "\n",
    "    def step(self, state, action, timestep):\n",
    "        current_pv   = state[0]\n",
    "        current_load = state[1]\n",
    "        current_p2   = state[2]\n",
    "        current_rsoc = state[3]\n",
    "\n",
    "        # TODO: rsoc update\n",
    "        \n",
    "\n",
    "        return # values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**(c) Implement DRL**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameters** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DQN hyperparameters\n",
    "state_size = (4, ) # pv_power, consumption, p2, rsoc\n",
    "action_size = 11\n",
    "learning_rate = 0.01\n",
    "lr = 0.001\n",
    "batch_size = 64\n",
    "gamma = 0.95     \n",
    "\n",
    "# Exploration hyperparameters for epsilon greedy strategy\n",
    "explore_start = 1.0 # exploration probability at start\n",
    "explore_stop = 0.01 # minimum exploration probability \n",
    "decay_rate = 0.001 # exponential decay rate for exploration prob\n",
    "\n",
    "# Memory hyperparameters\n",
    "pretrain_length = 10000 # # of experiences stored in Memory during initialization\n",
    "memory_size = 10000 # # of experiences Memory can keep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T08:18:07.006849Z",
     "start_time": "2024-07-15T08:18:06.961112Z"
    }
   },
   "source": [
    "**Memory Initialization**\n",
    "reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Q-Network (DQN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T06:36:59.611299Z",
     "start_time": "2024-07-15T06:36:59.609157Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**(d) Plot the average reward**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T06:36:59.615421Z",
     "start_time": "2024-07-15T06:36:59.614190Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO ???"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
