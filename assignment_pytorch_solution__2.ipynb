{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Machine Vision - Assignment 8: ViT Implementation\n",
    "\n",
    "This exercise will follow assignment 7 in structure. However, its goal is to get used to implement state-of-the-art architectures based on reading a paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-02-16T08:29:33.534674540Z",
     "start_time": "2024-02-16T08:29:31.117471947Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import torchvision\n",
    "from torchvision.transforms import v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### Preparation\n",
    "\n",
    "##### German Traffic Sign Recognition Benchmark\n",
    "\n",
    "The German Traffic Sign Recognition Benchmark [(GTSRB)](https://benchmark.ini.rub.de/) is a competition that was held at the IJCNN 2011. In this competition images of traffic signs should be classified.\n",
    "You will implement your own neural network to classify a subset of the GTSRB dataset. This subset consists of `12` different classes, which are shown in the figures below. However, you are free to extend your solution to the full dataset.\n",
    "\n",
    "\n",
    "|---|------------------------------|-------------------------------|-------------------------------|-------------------------------|-------------------------------|-------------------------------|-------------------------------|-------------------------------|-------------------------------|--------------------------------|--------------------------------|--------------------------------|\n",
    "|  ![Class 0](res/images/0.png) | ![Class 1](res/images/6.png) | ![Class 2](res/images/16.png) | ![Class 3](res/images/17.jpg) | ![Class 4](res/images/19.png) | ![Class 5](res/images/22.jpg) | ![Class 6](res/images/28.png) | ![Class 7](res/images/29.png) | ![Class 8](res/images/32.png) | ![Class 9](res/images/33.png) | ![Class 10](res/images/38.png) | ![Class 11](res/images/40.png) |\n",
    "<br></br>\n",
    "\n",
    "In order to simplify this exercise, the raw GTSRB images are already transformed into a dataset, where each image has the shape of `[C,H,W]` (Height x Width x Channels) with values ranging from `0-1`.\n",
    "Furthermore, the dataset is split into a train-, validation- and test-dataset, where the train- and validation-datasets are provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-02-16T08:29:33.535255642Z",
     "start_time": "2024-02-16T08:29:33.533714655Z"
    }
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 12\n",
    "\n",
    "train_ds = torchvision.datasets.ImageFolder(\"data_train\", transform=v2.Compose([\n",
    "    v2.RandAugment(),\n",
    "    v2.PILToTensor(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "]))\n",
    "\n",
    "val_ds = torchvision.datasets.ImageFolder(\"data_val\", transform=v2.Compose([\n",
    "    v2.PILToTensor(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "]))\n",
    "\n",
    "train_dl = DataLoader(dataset=train_ds, batch_size=8, shuffle=True)\n",
    "val_dl = DataLoader(dataset=val_ds, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Which means, that each label is a vector of 12 entries, where only the entry of the class has the value $1$ and all others values are $0$The `torchvision.datasets.ImageFolder` is a simple way to represent classification datasets. For more information you can read it up here: [ImageFolder](https://pytorch.org/vision/stable/generated/torchvision.datasets.ImageFolder.html)\n",
    "\n",
    "Furthermore, the standard pytorch dataloader class is used to create an iterator based on an `torch.utils.data.Dataset` class.\n",
    "Each iteration, the dataloader returns a batch of `x = [Bx3x32x32]` images and `y = [Bx12]` class labels, where B is the batch size.\n",
    "\n",
    "There are different approaches to encode the class label. For further information you can read this blog entry [integer- or one-hot-encoding](https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/).\n",
    "In this exercise the labels are encoded in the integer format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-02-16T08:29:33.536152928Z",
     "start_time": "2024-02-16T08:29:33.535149546Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape: torch.Size([8, 3, 32, 32])\n",
      "label shape: torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "x_batch, y_batch = next(iter(train_dl))\n",
    "\n",
    "# @student print the image and label shape of a batch\n",
    "print(f\"image shape: {x_batch.shape}\")\n",
    "print(f\"label shape: {y_batch.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 4\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# @student show one image of the batch and its label\n",
    "print(f\"label: {y_batch[1]}\")\n",
    "\n",
    "plt.imshow(x_batch[0].permute(1,2,0))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T08:29:33.610772504Z",
     "start_time": "2024-02-16T08:29:33.535479407Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE\n",
    "\n",
    "We will follow the steps of the ground braking paper \"AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE\" [Link to Publication](https://arxiv.org/abs/2010.11929)\n",
    "which generalized the idea of language transformer models to vision tasks.\n",
    "\n",
    "![vit_architecture](res/images/vit.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Method\n",
    "\n",
    "Before starting to implement the ViT please read the publication and shortly describe each of these steps:\n",
    "<br />\n",
    "\n",
    "##### Step 1: Transform Images into Patches\n",
    "\n",
    "##### Step 2: Linear embed Patches into Tokens (Embeddings)\n",
    "\n",
    "##### Step 3: Add Position embedding to Tokens (Embeddings)\n",
    "\n",
    "##### Step 4: Feed Tokens into multiple Transformer Encoder Layer\n",
    "\n",
    "##### Step 5: Pool the Result and feed into Classification Head"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-02-16T08:29:33.617357777Z",
     "start_time": "2024-02-16T08:29:33.611054640Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 32, 32])\n",
      "torch.Size([8, 64, 48])\n"
     ]
    }
   ],
   "source": [
    "# hint: you can easily implement the patching of an image using einops. https://einops.rocks/1-einops-basics/\n",
    "# However, it is also possible using numpy / for loops\n",
    "from einops import rearrange\n",
    "def transform_batch_into_patches(image_batch, patch_size):\n",
    "    return rearrange(image_batch, 'b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = patch_size, p2 = patch_size)\n",
    "\n",
    "print(x_batch.shape)\n",
    "batch_patches = transform_batch_into_patches(x_batch, patch_size=4)\n",
    "print(batch_patches.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Make sure tokens are extracted correctly"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 288x288 with 64 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img0_patches = batch_patches[0]\n",
    "\n",
    "rows = 8\n",
    "cols = 8\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(4, 4))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, patch in enumerate(img0_patches):\n",
    "    # @ student: reshape the flattened patch back to an image\n",
    "    patch_ = patch.reshape(4,4,3)\n",
    "    axes[i].imshow(patch_)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T08:29:34.747303595Z",
     "start_time": "2024-02-16T08:29:33.620551894Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Step 2, 3, 4, 5\n",
    "\n",
    "The embedding from patches to tokens is a part of our model, hence we will start with the implementation of our model in this step.\n",
    "To ease the implementation, an already working Transformer class is available in `transformer.py`.\n",
    "Please use it until you can train your model to convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from transformer import Transformer\n",
    "\n",
    "class VisionTransformer(nn.Module):\n",
    "    def __init__(self, *,\n",
    "                 image_size, patch_size,\n",
    "                 transformer_dim, transformer_depth, transformer_heads=4, transformer_dim_head=32\n",
    "     ):\n",
    "        super().__init__()\n",
    "        assert image_size % patch_size == 0, 'Image dimensions must be divisible by the patch size.'\n",
    "        self.image_size = image_size\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "        # @student: Layers for step 2\n",
    "        patch_dim = 3 * patch_size * patch_size\n",
    "        self.to_patch_embedding = nn.Sequential(\n",
    "            nn.LayerNorm(patch_dim),\n",
    "            nn.Linear(patch_dim, transformer_dim),\n",
    "            nn.LayerNorm(transformer_dim),\n",
    "        )\n",
    "\n",
    "        # @student: Layers for step 3\n",
    "        # Hint: Use the learned position embedding (using a nn.Parameter)\n",
    "        num_patches = (image_size // patch_size) * (image_size // patch_size)\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches, transformer_dim))\n",
    "\n",
    "        # @student: Layers for step 4\n",
    "        self.transformer = Transformer(\n",
    "            transformer_dim,\n",
    "            transformer_depth,\n",
    "            transformer_heads,\n",
    "            transformer_dim_head,\n",
    "            transformer_dim * 2\n",
    "        )\n",
    "\n",
    "        # @student: Layers for step 5\n",
    "        self.pred = nn.Linear(transformer_dim, 12)\n",
    "\n",
    "    def forward(self, image_batch):\n",
    "        # @student: (step 1) Transform Images into Patches\n",
    "        patches_batch = transform_batch_into_patches(image_batch, self.patch_size)\n",
    "\n",
    "        # @student: (step 2) Linear embed Patches into Tokens (Embeddings)\n",
    "        tokens_batch = self.to_patch_embedding(patches_batch)\n",
    "\n",
    "        # @student: (step 3) Add Position embedding to Tokens (Embeddings)\n",
    "        #tokens_batch = tokens_batch + self.pos_embedding\n",
    "\n",
    "        # @student: (step 4) Feed Tokens (Embeddings) into multiple Transformer Encoder Layer\n",
    "        # hint: instead of a cls token you can use the mean over the tokens as final embedding per image (Simple ViT) https://arxiv.org/abs/2205.01580\n",
    "        image_embeddings = self.transformer(tokens_batch)\n",
    "        image_embeddings = image_embeddings.mean(dim = 1)\n",
    "\n",
    "        # @student: (step 5)\n",
    "        return self.pred(image_embeddings)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T08:29:34.802708194Z",
     "start_time": "2024-02-16T08:29:34.750680814Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-02-16T08:29:34.803333096Z",
     "start_time": "2024-02-16T08:29:34.801188109Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VisionTransformer(\n",
      "  (to_patch_embedding): Sequential(\n",
      "    (0): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
      "    (1): Linear(in_features=48, out_features=48, bias=True)\n",
      "    (2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (transformer): Transformer(\n",
      "    (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
      "    (layers): ModuleList(\n",
      "      (0-5): 6 x ModuleList(\n",
      "        (0): Attention(\n",
      "          (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
      "          (attend): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (to_qkv): Linear(in_features=48, out_features=384, bias=False)\n",
      "          (to_out): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=48, bias=True)\n",
      "            (1): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): FeedForward(\n",
      "          (net): Sequential(\n",
      "            (0): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
      "            (1): Linear(in_features=48, out_features=96, bias=True)\n",
      "            (2): GELU(approximate='none')\n",
      "            (3): Dropout(p=0.0, inplace=False)\n",
      "            (4): Linear(in_features=96, out_features=48, bias=True)\n",
      "            (5): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pred): Linear(in_features=48, out_features=12, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = VisionTransformer(\n",
    "    image_size=32, patch_size=4,\n",
    "    transformer_dim=48, transformer_depth=6, transformer_heads=8, transformer_dim_head=16\n",
    ")\n",
    "print(model)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "\n",
    "def eval(model, dl, with_cm=False):\n",
    "    y_labels = []\n",
    "    pred_labels = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (imgs, labels) in enumerate(dl):\n",
    "            logits = model(imgs)\n",
    "\n",
    "            # @student: calculate class predictions based on the logits\n",
    "            preds = torch.argmax(torch.softmax(logits, dim=-1), dim=-1)\n",
    "\n",
    "            pred_labels.extend(preds.detach().numpy())\n",
    "            y_labels.extend(labels.detach().numpy())\n",
    "\n",
    "    if with_cm:\n",
    "        cm = confusion_matrix(y_labels, pred_labels)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot()\n",
    "        plt.show()\n",
    "    model.train()\n",
    "    print(f\"f1: {f1_score(y_labels, pred_labels, average='macro')}, p: {precision_score(y_labels, pred_labels, average='macro')}, r: {recall_score(y_labels, pred_labels, average='macro')}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T08:29:34.803478186Z",
     "start_time": "2024-02-16T08:29:34.801625141Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Below is the training process of the model.\n",
    "If your machine supports gpu acceleration uncomment line 6."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-02-16T08:57:28.804298928Z",
     "start_time": "2024-02-16T08:29:34.801817073Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/klemp/miniconda3/envs/mv_assignments/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "loss 1.23 - : : 866it [00:58, 14.80it/s]\n",
      "/home/klemp/miniconda3/envs/mv_assignments/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.40203161194209786, p: 0.37604548229548235, r: 0.48333333333333334\n",
      "epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 0.678 - : : 866it [00:55, 15.48it/s]\n",
      "/home/klemp/miniconda3/envs/mv_assignments/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.555503850285634, p: 0.56441887361005, r: 0.6083333333333333\n",
      "epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 0.526 - : : 866it [18:57,  1.31s/it] \n",
      "/home/klemp/miniconda3/envs/mv_assignments/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.7251933311076534, p: 0.7218510656010656, r: 0.7583333333333333\n",
      "epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 0.417 - : : 866it [00:46, 18.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.7610160726512186, p: 0.8025450244200245, r: 0.775\n",
      "epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 0.377 - : : 866it [00:56, 15.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.7420200714318361, p: 0.7663179413179413, r: 0.7666666666666666\n",
      "epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 0.343 - : : 866it [01:22, 10.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.8384094706463127, p: 0.8466750841750842, r: 0.8416666666666668\n",
      "epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 0.29 - : : 866it [01:05, 13.32it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.7682388990853567, p: 0.7679178664472782, r: 0.7833333333333333\n",
      "epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 0.282 - : : 866it [00:56, 15.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.7810805252688414, p: 0.8213369963369962, r: 0.7916666666666666\n",
      "epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 0.271 - : : 866it [00:55, 15.51it/s]\n",
      "/home/klemp/miniconda3/envs/mv_assignments/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.6395180799592565, p: 0.6810606060606061, r: 0.6749999999999999\n",
      "epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 0.257 - : : 866it [00:56, 15.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.7922576668448702, p: 0.8198409161644454, r: 0.8000000000000002\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    print(f\"epoch {epoch+1}\")\n",
    "    pbar = tqdm(enumerate(train_dl))\n",
    "    running_loss = []\n",
    "    for i, (imgs, labels) in pbar:\n",
    "        # @student: uncomment if your machine has GPU support\n",
    "        #imgs, labels = imgs.to(\"cuda\"), labels.to(\"cuda\")\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        preds = model(imgs)\n",
    "        loss = loss_fn(preds, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss.append(loss.detach().numpy())\n",
    "        pbar.set_description(f\"loss {np.mean(running_loss):.3} - \" )\n",
    "        pbar.update()\n",
    "    eval(model, val_dl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### From Logits to Labels\n",
    "\n",
    "Your network will output logits and not the final predictions.\n",
    "Hence, you further need to calculate the predicted label based on the logits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.7922576668448702, p: 0.8198409161644454, r: 0.8000000000000002\n"
     ]
    }
   ],
   "source": [
    "eval(model, val_dl, with_cm=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T08:57:29.696123821Z",
     "start_time": "2024-02-16T08:57:28.803676706Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Once you feel confident with your model evaluate it one last time on the test set.\n",
    "The test set will be uploaded during the exercise session."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.8309659644983207, p: 0.8537841325667078, r: 0.8279327412783295\n"
     ]
    }
   ],
   "source": [
    "# @student: final check of your fully trained model\n",
    "test_ds = torchvision.datasets.ImageFolder(\"data_test\", transform=v2.Compose([\n",
    "    v2.PILToTensor(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "]))\n",
    "test_dl = DataLoader(dataset=test_ds, batch_size=16, shuffle=False)\n",
    "\n",
    "eval(model, test_dl)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T08:57:33.197389413Z",
     "start_time": "2024-02-16T08:57:29.695397969Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T08:57:33.201396945Z",
     "start_time": "2024-02-16T08:57:33.198903021Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
