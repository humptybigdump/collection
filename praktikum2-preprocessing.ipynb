{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MT Praktikum - Text processing and Language Models\n",
    "\n",
    "In the directory `/opt/data/nc19/` you will find the raw text files from\n",
    "the News-Commentary corpus which we will use today for our\n",
    "preprocessing, as well as the language model. The corresponding source\n",
    "data you can find in  \n",
    "`/opt/data/wmt10-xlats/ref/wmt10-newssyscombtest2010-src.de.sgm`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing\n",
    "=============\n",
    "\n",
    "Tokenization\n",
    "------------\n",
    "\n",
    "Tokenization, in brief terms, is the task of breaking down the text\n",
    "stream into discrete units, called *tokens*. Before looking at\n",
    "tokenization, let's first take a look at the data itself:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "export LANGUAGE=C.UTF-8\n",
    "export LC_ALL=C.UTF-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumption of the session\n",
      "I declare resumed the session of the European Parliament adjourned on Friday, 15 December 2000.\n",
      "Statements by the President\n",
      "Ladies and gentlemen, on Saturday, as you know, an earthquake struck Central America once again, with tragic consequences.\n",
      "This is an area which has already been seriously affected on a number of occasions since the beginning of the twentieth century.\n",
      "The latest, provisional, figures for victims in El Salvador are already very high.\n",
      "There are 350 people dead, 1 200 people missing, the area is completely devastated and thousands of homes have been destroyed throughout the country.\n",
      "The European Union has already shown its solidarity by sending a rescue team to the area, whilst financial assistance from the Union and Member States has been, or is in the process of being, released and I am able to inform you that some groups in the European Parliament have requested that this issue be included in the debate on topical and urgent subjects of major importance on Thursday.\n",
      "However, I should like to inform you that I have, of course, on behalf of the European Union, expressed our sincere condolences and deepest sympathy to the President of El Salvador in the tragedy which has struck his country.\n",
      "I would ask you, as a mark of respect for the victims and for the immense suffering of their families, to observe a minute' s silence.\n"
     ]
    }
   ],
   "source": [
    "head /opt/data/nc19/europarl-v9.en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2295044 /opt/data/nc19/europarl-v9.en\n"
     ]
    }
   ],
   "source": [
    "wc -l /opt/data/nc19/europarl-v9.en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's manually try to extract the unique words in this corpus.\n",
    "The following command will extract a (sorted and de-duplicated) list of\n",
    "tokens, as well as an occurrence count for each of them, from the text\n",
    "file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat /opt/data/nc19/europarl-v9.en | tr ' ' '\\n' | sort | uniq -c > /tmp/europarl.hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then read the file *europarl.hist*. Try to answer the following\n",
    "questions:\n",
    "\n",
    "-   How many items (words separated by space) are there in the original\n",
    "    europarl-v9.en data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329276\n"
     ]
    }
   ],
   "source": [
    "wc -l < /tmp/europarl.hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Is each one of the items totally unique, or can you spot some\n",
    "    obvious redundancies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 Example\n",
      "    162 Examples\n",
      "      1 Examples,\n",
      "  11829 example\n",
      "     12 example!\n",
      "      4 example'\n",
      "      1 example',\n",
      "      1 example'.\n",
      "     23 example)\n",
      "     20 example),\n",
      "     11 example).\n",
      "      1 example)?\n",
      "  16499 example,\n",
      "   2328 example.\n",
      "      1 example.4.If\n",
      "      1 example.I\n",
      "    379 example:\n",
      "     46 example;\n",
      "     91 example?\n",
      "      1 example?!\n",
      "   2263 examples\n",
      "      2 examples)\n",
      "      2 examples),\n",
      "      3 examples).\n",
      "    254 examples,\n",
      "    438 examples.\n",
      "    144 examples:\n",
      "      9 examples;\n",
      "      6 examples?\n",
      "      1 examplesas\n",
      "      1 example…\n"
     ]
    }
   ],
   "source": [
    "cat /tmp/europarl.hist | grep -i ' *[0-9]*  *example'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Does the phenomenon in question affect statistical models (such as\n",
    "    $n$-gram models) or probabilistic models such as neural language\n",
    "    models?\n",
    "  - Yes, it affects both. With more vocabulary words and less samples per word the maximum-likelihood estimation for the word embeddings, as well as the $n$-gram probabilities will yield worse estimations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization aims at solving the problems that we observed. For\n",
    "languages such as English and German, the tools are often implemented\n",
    "with rule-based approaches. A standard tool for such tokenization is\n",
    "`tokenizer.perl` from the `Moses` SMT project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is an example , ( it shows how &quot; tokenziation &quot; works ) .\n"
     ]
    }
   ],
   "source": [
    "echo 'This is an example, (it shows how \"tokenziation\" works).' |\n",
    "    tokenizer.perl -l en  2>/dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run the tool to tokenize your input file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer Version 1.1\n",
      "Language: en\n",
      "Number of threads: 1\n"
     ]
    }
   ],
   "source": [
    "tokenizer.perl -l en < /opt/data/nc19/europarl-v9.en > /tmp/europarl-v9.tok.en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The file name is a typical convention in the Natural Language\n",
    "Processing (NLP) community. The 'tok' suffix is just a naming\n",
    "convention, telling that tokenization is applied on top of the input\n",
    "file.\n",
    "\n",
    "Now you can try to extract to vocab again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat /tmp/europarl-v9.tok.en | tr ' ' '\\n' | sort | uniq -c > /tmp/europarl.tok.hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tokenized text file is always longer than the original one. By using\n",
    "the `wc` command you can verify if your command ran correctly or not.\n",
    "How many words do you now have in this vocabulary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140473\n"
     ]
    }
   ],
   "source": [
    "wc -l < /tmp/europarl.tok.hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True-Casing\n",
    "-----------\n",
    "\n",
    "When you look at the vocabulary file, you will probably find there to\n",
    "still be some duplicate words, once in upper-case form and once in\n",
    "lower-case form: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 Example\n",
      "  31252 example\n"
     ]
    }
   ],
   "source": [
    "cat /tmp/europarl.tok.hist | grep -i ' *[0-9]*  *example$'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The more we can\n",
    "reduce the number of duplication the better, so after tokenization we\n",
    "will use a true-casing tool to strip even more redundancy.  \n",
    "We apply the true-casing in a 2 step procedure:\n",
    "\n",
    "1.  train a true-casing model to get the \"true\" case of each vocabulary\n",
    "    word using  \n",
    "    `$ train-truecaser.perl --model truecase-model.en --corpus europarl-v9.tok.en`\n",
    "\n",
    "2.  apply the model to the data to convert upper-cased words at the the\n",
    "    beginning of the sentence to their respective \"true\" case:  \n",
    "    `$ truecase.perl --model truecase-model.en < europarl-v9.tok.en > europarl-v9.true.en`  \n",
    "    (it may take a few minutes to complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train-truecaser.perl --model /tmp/truecase-model.en --corpus /tmp/europarl-v9.tok.en\n",
    "truecase.perl        --model /tmp/truecase-model.en        < /tmp/europarl-v9.tok.en > /tmp/europarl-v9.true.en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we need the tokenized text file to train the model (Why? What\n",
    "would happen if we use the original file?).  \n",
    "\n",
    "If you check the model file\n",
    "contents, you will see it simply contains statistics about upper-case\n",
    "and lower-case occurrences for each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round-up (5/6) Round-up (1)\n",
      "over-emphasised (12/12)\n",
      "cicadas (1/1)\n",
      "wrap (43/43)\n",
      "instead (6602/6612) Instead (10)\n",
      "improvised (49/49)\n",
      "Christer (3/3)\n",
      "firebrands (1/1)\n",
      "emeritus (1/1)\n",
      "sleeps (2/2)\n",
      "al-Mabhouh (1/1)\n",
      "ná (4/4)\n",
      "C4-0661 (2/2)\n",
      "christening (4/4)\n",
      "compacted (5/5)\n",
      "complacency (176/176)\n",
      "Beitenu (1/1)\n",
      "rum-producing (1/1)\n",
      "in-transit (4/4)\n",
      "IBAN (16/16)\n",
      "conquering (21/21)\n",
      "Balázs (5/5)\n",
      "C5-0226 (1/1)\n",
      "befell (20/20)\n",
      "B5-0163 (2/2)\n",
      "opposed (4185/4185)\n",
      "non-transparently (1/1)\n",
      "pallets (3/3)\n",
      "root-andbranch (1/1)\n",
      "H5N1 (18/18)\n",
      "Kajumulo (1/1)\n",
      "-B4-0764 (2/2)\n",
      "Joel (4/4)\n",
      "risksall (1/1)\n",
      "C4-0122 (1/1)\n",
      "berthing (3/3)\n",
      "hobby-horses (3/3)\n",
      "CO2-polluted (1/1)\n",
      "Jangchub (2/2)\n",
      "unido (1/2) UNIDO (1)\n",
      "sector (27517/27538) Sector (21)\n",
      "expectantly (9/9)\n",
      "Pan-Orthodox (1/1)\n",
      "place-based (3/3)\n",
      "weapons-related (1/1)\n",
      "EKO (1/1)\n",
      "administratively (60/60)\n",
      "TSIs (9/9)\n",
      "Apalina (1/1)\n",
      "SeaFrance (2/2)\n",
      "hooks (5/5)\n",
      "Saint-Barthélemy (1/1)\n",
      "abnormally (31/31)\n",
      "Euro-Jus (1/1)\n",
      "definitive (944/951) Definitive (7)\n",
      "O-0048 (2/2)\n",
      "Bouler (2/2)\n",
      "left-hand-drive (3/3)\n",
      "ancestors (52/52)\n",
      "Hollands (1/1)\n",
      "Communists (145/264) communists (119)\n",
      "mausoleum (5/6) Mausoleum (1)\n",
      "VSE (1/1)\n",
      "MSE (2/2)\n",
      "unforgivable (43/43)\n",
      "Gémayel (1/1)\n",
      "law-suits (1/1)\n",
      "print-disabled (13/13)\n",
      "Fitzsimmons (2/2)\n",
      "allopathy (2/2)\n",
      "Directorate (187/294) directorate (107)\n",
      "C4-0106 (1/1)\n",
      "small-calibre (1/1)\n",
      "disenfranchising (2/2)\n",
      "Nouadhibou (1/1)\n",
      "Russian-Iranian (2/2)\n",
      "Trans-Pacific (2/2)\n",
      "Cioloş (107/107)\n",
      "Leopold (15/15)\n",
      "Niangadou (1/1)\n",
      "Α (5/5)\n",
      "Sixth (534/1030) sixth (496)\n",
      "Malliori (48/48)\n",
      "over-quota (4/4)\n",
      "fault-free (1/1)\n",
      "retrofitting (25/25)\n",
      "quashed (26/26)\n",
      "Panchayat (1/1)\n",
      "48-month (1/1)\n",
      "drawn-up (4/4)\n",
      "climate-sceptics (1/1)\n",
      "-A4-0215 (1/1)\n",
      "gavel (41/41)\n",
      "tollbooths (1/1)\n",
      "-have (2/2)\n",
      "C4-0512 (3/3)\n",
      "Safilo (1/1)\n",
      "non-European (301/301)\n",
      "C7-0169 (1/1)\n",
      "clearsightedness (1/1)\n",
      "presidentialization (1/1)\n",
      "connective (9/9)\n",
      "www.autre-europe.org (1/1)\n",
      "EU-2020 (2/2)\n",
      "Capoualas (1/1)\n",
      "central-bank (1/1)\n",
      "trade-unionists (1/1)\n",
      "balances (509/509)\n",
      "somatotrophine (1/1)\n",
      "rout (8/8)\n",
      "wird (2/2)\n",
      "assertive (70/70)\n",
      "washout (2/2)\n",
      "assumes (310/310)\n",
      "B7-0636 (1/1)\n",
      "Caesarian (2/2)\n",
      "all-year-round (2/2)\n",
      "Rousseaux (1/1)\n",
      "Magusta (1/1)\n",
      "C7-0430 (1/1)\n",
      "blinders (1/1)\n",
      "neo-imperialistic (4/4)\n",
      "mercury-contaminated (1/1)\n",
      "tooth-comb (1/1)\n",
      "tough-going (1/1)\n",
      "sacri (1/1)\n",
      "B5-0412 (1/1)\n",
      "-Europe (2/2)\n"
     ]
    }
   ],
   "source": [
    "head -n128 /tmp/truecase-model.en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "listen potato Word Peter Germany USA\n",
      "\n",
      "Peter (243/250) peter (7)\n",
      "USA (3044/3044)\n",
      "potato (245/245)\n",
      "Germany (6193/6193)\n",
      "word (4988/4996) WORD (1) Word (7)\n",
      "listen (2362/2367) Listen (5)\n"
     ]
    }
   ],
   "source": [
    "echo 'Listen Potato Word Peter Germany USA' |\n",
    "    truecase.perl --model /tmp/truecase-model.en\n",
    "echo\n",
    "grep -E -i '^(Listen|Potato|Word|Peter|Germany|USA) ' /tmp/truecase-model.en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the true-cased text you can now try to extract to vocab again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat /tmp/europarl-v9.true.en | tr ' ' '\\n' | sort | uniq -c > /tmp/europarl.true.hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we did everything correctly the vocabulary size should have further\n",
    "decreased.  \n",
    "What is the vocabulary size at the moment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134462\n"
     ]
    }
   ],
   "source": [
    "wc -l < /tmp/europarl.true.hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to look at the histogram file a little bit more.  \n",
    "Notice that many words share the same root and differ in suffixes or prefixes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1 Listen\n",
      "      2 Listening\n",
      "   2407 listen\n",
      "   1718 listened\n",
      "     10 listener\n",
      "     29 listeners\n",
      "   1438 listening\n",
      "     92 listens\n"
     ]
    }
   ],
   "source": [
    "cat /tmp/europarl.true.hist | grep -i ' *[0-9]*  *listen'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also most of the items in the vocabulary appear only once in the data (especially\n",
    "numbers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58699\n",
      "1334\n"
     ]
    }
   ],
   "source": [
    "cat /tmp/europarl.true.hist | grep ' *1 ' | wc -l\n",
    "cat /tmp/europarl.true.hist | grep ' *1 [0-9][0-9]*$' | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What could be the problem for algorithms that learn embeddings or\n",
    "statistical/probabilistic models in general? (This is an open question,\n",
    "and there are several problems that I can remember, but in general it\n",
    "comes from the curse of dimensionality)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Byte-Pair Encoding\n",
    "------------------\n",
    "\n",
    "Byte-Pair Encoding (BPE) is an algorithm that helps us automatically\n",
    "split words into smaller components. Since BPE is also a statistical\n",
    "algorithm, first we need to extract the statistics from our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                 | 0/32000 [00:00<?, ?it/s]\r",
      "  0%|                                         | 3/32000 [00:00<45:58, 11.60it/s]\r",
      "  0%|                                       | 5/32000 [00:00<1:02:47,  8.49it/s]\r",
      "  0%|                                       | 6/32000 [00:00<1:07:22,  7.91it/s]\r",
      "  0%|                                       | 7/32000 [00:00<1:07:48,  7.86it/s]\r",
      "  0%|                                         | 9/32000 [00:01<59:11,  9.01it/s]\r",
      "  0%|                                      | 10/32000 [00:01<1:05:40,  8.12it/s]\r",
      "  0%|                                        | 14/32000 [00:01<40:38, 13.12it/s]\r",
      "  0%|                                        | 16/32000 [00:01<38:20, 13.90it/s]\r",
      "  0%|                                        | 20/32000 [00:01<30:44, 17.34it/s]\r",
      "  0%|                                        | 23/32000 [00:01<29:12, 18.24it/s]\r",
      "  0%|                                        | 25/32000 [00:01<32:32, 16.38it/s]\r",
      "  0%|                                        | 27/32000 [00:02<33:04, 16.11it/s]\r",
      "  0%|                                        | 29/32000 [00:02<33:21, 15.97it/s]\r",
      "  0%|                                        | 32/32000 [00:02<27:50, 19.14it/s]\r",
      "  0%|                                        | 35/32000 [00:02<24:23, 21.84it/s]\r",
      "  0%|                                        | 39/32000 [00:02<24:54, 21.38it/s]\r",
      "  0%|                                        | 44/32000 [00:02<19:05, 27.90it/s]\r",
      "  0%|                                        | 48/32000 [00:02<20:09, 26.43it/s]\r",
      "  0%|                                        | 54/32000 [00:02<15:47, 33.72it/s]\r",
      "  0%|                                        | 60/32000 [00:03<13:15, 40.13it/s]\r",
      "  0%|                                        | 65/32000 [00:03<12:54, 41.24it/s]\r",
      "  0%|                                        | 70/32000 [00:03<13:18, 39.99it/s]\r",
      "  0%|                                        | 77/32000 [00:03<12:22, 42.97it/s]\r",
      "  0%|1                                       | 84/32000 [00:03<10:43, 49.56it/s]\r",
      "  0%|1                                       | 90/32000 [00:03<10:40, 49.80it/s]\r",
      "  0%|1                                      | 100/32000 [00:03<08:54, 59.71it/s]\r",
      "  0%|1                                      | 108/32000 [00:03<08:24, 63.26it/s]\r",
      "  0%|1                                      | 124/32000 [00:04<06:04, 87.38it/s]\r",
      "  0%|1                                      | 133/32000 [00:04<06:24, 82.80it/s]\r",
      "  0%|1                                      | 143/32000 [00:04<06:06, 86.84it/s]\r",
      "  0%|1                                      | 156/32000 [00:04<05:23, 98.44it/s]\r",
      "  1%|2                                      | 167/32000 [00:04<05:18, 99.85it/s]\r",
      "  1%|2                                      | 178/32000 [00:04<05:58, 88.66it/s]\r",
      "  1%|2                                     | 192/32000 [00:04<05:13, 101.39it/s]\r",
      "  1%|2                                     | 204/32000 [00:04<05:00, 105.94it/s]\r",
      "  1%|2                                     | 221/32000 [00:04<04:17, 123.54it/s]\r",
      "  1%|2                                     | 241/32000 [00:05<03:42, 142.54it/s]\r",
      "  1%|3                                     | 257/32000 [00:05<03:36, 146.34it/s]\r",
      "  1%|3                                     | 273/32000 [00:05<03:35, 147.45it/s]\r",
      "  1%|3                                     | 288/32000 [00:05<03:37, 145.51it/s]\r",
      "  1%|3                                     | 304/32000 [00:05<03:37, 145.82it/s]\r",
      "  1%|3                                     | 321/32000 [00:05<03:28, 152.20it/s]\r",
      "  1%|4                                     | 342/32000 [00:05<03:11, 164.98it/s]\r",
      "  1%|4                                     | 362/32000 [00:05<03:01, 174.12it/s]\r",
      "  1%|4                                     | 384/32000 [00:05<02:49, 186.07it/s]\r",
      "  1%|4                                     | 403/32000 [00:05<02:49, 186.65it/s]\r",
      "  1%|5                                     | 432/32000 [00:06<02:25, 216.48it/s]\r",
      "  1%|5                                     | 457/32000 [00:06<02:19, 225.44it/s]\r",
      "  2%|5                                     | 481/32000 [00:06<02:19, 226.29it/s]\r",
      "  2%|5                                     | 504/32000 [00:06<02:27, 214.06it/s]\r",
      "  2%|6                                     | 540/32000 [00:06<02:03, 254.43it/s]\r",
      "  2%|6                                     | 566/32000 [00:06<02:07, 246.15it/s]\r",
      "  2%|7                                     | 591/32000 [00:06<02:20, 223.79it/s]\r",
      "  2%|7                                     | 623/32000 [00:06<02:05, 249.06it/s]\r",
      "  2%|7                                     | 666/32000 [00:06<01:45, 296.98it/s]\r",
      "  2%|8                                     | 697/32000 [00:07<01:44, 298.35it/s]\r",
      "  2%|8                                     | 741/32000 [00:07<01:32, 338.50it/s]\r",
      "  2%|9                                     | 776/32000 [00:07<01:31, 341.26it/s]\r",
      "  3%|9                                     | 811/32000 [00:07<01:32, 337.47it/s]\r",
      "  3%|#                                     | 846/32000 [00:07<01:32, 337.09it/s]\r",
      "  3%|#                                     | 880/32000 [00:07<01:32, 336.52it/s]\r",
      "  3%|#                                     | 915/32000 [00:07<01:33, 334.03it/s]\r",
      "  3%|#1                                    | 953/32000 [00:07<01:29, 346.50it/s]\r",
      "  3%|#1                                    | 988/32000 [00:07<01:31, 339.35it/s]\r",
      "  3%|#1                                   | 1028/32000 [00:07<01:27, 355.34it/s]\r",
      "  3%|#2                                   | 1064/32000 [00:08<01:27, 353.01it/s]\r",
      "  3%|#2                                   | 1100/32000 [00:08<01:35, 324.08it/s]\r",
      "  4%|#3                                   | 1141/32000 [00:08<01:29, 346.62it/s]\r",
      "  4%|#3                                   | 1180/32000 [00:08<01:26, 357.40it/s]\r",
      "  4%|#4                                   | 1217/32000 [00:08<01:40, 305.03it/s]\r",
      "  4%|#4                                   | 1257/32000 [00:08<01:33, 328.12it/s]\r",
      "  4%|#4                                   | 1294/32000 [00:08<01:30, 338.22it/s]\r",
      "  4%|#5                                   | 1346/32000 [00:08<01:19, 383.95it/s]\r",
      "  4%|#6                                   | 1386/32000 [00:08<01:20, 380.67it/s]\r",
      "  4%|#6                                   | 1435/32000 [00:09<01:14, 409.03it/s]\r",
      "  5%|#7                                   | 1487/32000 [00:09<01:23, 367.30it/s]\r",
      "  5%|#7                                   | 1531/32000 [00:09<01:18, 385.75it/s]\r",
      "  5%|#8                                   | 1579/32000 [00:09<01:14, 410.74it/s]\r",
      "  5%|#8                                   | 1630/32000 [00:09<01:09, 435.65it/s]\r",
      "  5%|#9                                   | 1675/32000 [00:09<01:14, 405.38it/s]\r",
      "  5%|#9                                   | 1717/32000 [00:09<01:15, 400.06it/s]\r",
      "  6%|##                                   | 1770/32000 [00:09<01:09, 434.07it/s]\r",
      "  6%|##1                                  | 1820/32000 [00:10<01:06, 451.83it/s]\r",
      "  6%|##1                                  | 1881/32000 [00:10<01:00, 495.55it/s]\r",
      "  6%|##2                                  | 1935/32000 [00:10<00:59, 507.16it/s]\r",
      "  6%|##2                                  | 1987/32000 [00:10<01:15, 398.15it/s]\r",
      "  6%|##3                                  | 2041/32000 [00:10<01:09, 432.66it/s]\r",
      "  7%|##4                                  | 2096/32000 [00:10<01:04, 462.38it/s]\r",
      "  7%|##4                                  | 2146/32000 [00:10<01:04, 459.94it/s]\r",
      "  7%|##5                                  | 2195/32000 [00:10<01:04, 460.83it/s]\r",
      "  7%|##6                                  | 2263/32000 [00:10<00:57, 521.00it/s]\r",
      "  7%|##6                                  | 2317/32000 [00:11<00:56, 524.51it/s]\r",
      "  7%|##7                                  | 2389/32000 [00:11<00:51, 578.67it/s]\r",
      "  8%|##8                                  | 2463/32000 [00:11<00:47, 623.12it/s]\r",
      "  8%|##9                                  | 2527/32000 [00:11<00:47, 614.67it/s]\r",
      "  8%|##9                                  | 2590/32000 [00:11<00:48, 602.66it/s]\r",
      "  8%|###                                  | 2665/32000 [00:11<00:45, 644.11it/s]\r",
      "  9%|###1                                 | 2741/32000 [00:11<00:43, 675.05it/s]\r",
      "  9%|###2                                 | 2809/32000 [00:11<00:44, 662.16it/s]\r",
      "  9%|###3                                 | 2882/32000 [00:11<00:42, 680.48it/s]\r",
      "  9%|###4                                 | 2951/32000 [00:11<00:43, 669.61it/s]\r",
      "  9%|###5                                 | 3028/32000 [00:12<00:41, 697.81it/s]\r",
      " 10%|###6                                 | 3126/32000 [00:12<00:37, 778.65it/s]\r",
      " 10%|###7                                 | 3205/32000 [00:12<00:41, 693.32it/s]\r",
      " 10%|###7                                 | 3278/32000 [00:12<00:40, 701.22it/s]\r",
      " 10%|###8                                 | 3357/32000 [00:12<00:39, 724.85it/s]\r",
      " 11%|###9                                 | 3456/32000 [00:12<00:35, 799.54it/s]\r",
      " 11%|####1                                | 3552/32000 [00:12<00:33, 843.83it/s]\r",
      " 11%|####2                                | 3643/32000 [00:12<00:32, 861.54it/s]\r",
      " 12%|####3                                | 3758/32000 [00:12<00:29, 944.38it/s]\r",
      " 12%|####3                               | 3881/32000 [00:13<00:27, 1028.19it/s]\r",
      " 12%|####4                               | 3994/32000 [00:13<00:26, 1057.81it/s]\r",
      " 13%|####7                                | 4101/32000 [00:14<01:30, 308.31it/s]\r",
      " 13%|####8                                | 4179/32000 [00:14<01:21, 339.56it/s]\r",
      " 13%|####9                                | 4249/32000 [00:14<01:16, 364.06it/s]\r",
      " 13%|####9                                | 4313/32000 [00:14<01:13, 376.14it/s]\r",
      " 14%|#####                                | 4370/32000 [00:14<01:09, 397.86it/s]\r",
      " 14%|#####1                               | 4425/32000 [00:14<01:07, 409.33it/s]\r",
      " 14%|#####1                               | 4477/32000 [00:14<01:03, 430.95it/s]\r",
      " 14%|#####2                               | 4529/32000 [00:14<01:01, 448.98it/s]\r",
      " 14%|#####2                               | 4582/32000 [00:15<00:58, 468.45it/s]\r",
      " 14%|#####3                               | 4634/32000 [00:15<00:58, 470.02it/s]\r",
      " 15%|#####4                               | 4685/32000 [00:15<00:57, 474.85it/s]\r",
      " 15%|#####4                               | 4736/32000 [00:15<00:56, 479.52it/s]\r",
      " 15%|#####5                               | 4788/32000 [00:15<00:55, 488.64it/s]\r",
      " 15%|#####6                               | 4844/32000 [00:15<00:53, 506.50it/s]\r",
      " 15%|#####6                               | 4896/32000 [00:15<01:04, 417.88it/s]\r",
      " 15%|#####7                               | 4950/32000 [00:15<01:00, 446.87it/s]\r",
      " 16%|#####7                               | 4999/32000 [00:15<00:59, 457.35it/s]\r",
      " 16%|#####8                               | 5054/32000 [00:16<00:56, 480.70it/s]\r",
      " 16%|#####9                               | 5106/32000 [00:16<00:54, 490.73it/s]\r",
      " 16%|#####9                               | 5157/32000 [00:16<00:54, 496.10it/s]\r",
      " 16%|######                               | 5208/32000 [00:16<00:56, 477.93it/s]\r",
      " 16%|######                               | 5266/32000 [00:16<00:52, 504.88it/s]\r",
      " 17%|######1                              | 5322/32000 [00:16<00:51, 518.67it/s]\r",
      " 17%|######2                              | 5381/32000 [00:16<00:49, 535.18it/s]\r",
      " 17%|######2                              | 5445/32000 [00:16<00:47, 563.86it/s]\r",
      " 17%|######3                              | 5502/32000 [00:16<00:46, 564.75it/s]\r",
      " 17%|######4                              | 5565/32000 [00:16<00:45, 581.60it/s]\r",
      " 18%|######5                              | 5624/32000 [00:17<00:46, 568.28it/s]\r",
      " 18%|######5                              | 5682/32000 [00:17<00:47, 556.55it/s]\r",
      " 18%|######6                              | 5741/32000 [00:17<00:46, 565.89it/s]\r",
      " 18%|######7                              | 5802/32000 [00:17<00:45, 577.14it/s]\r",
      " 18%|######7                              | 5867/32000 [00:17<00:43, 596.72it/s]\r",
      " 19%|######8                              | 5935/32000 [00:17<00:42, 619.56it/s]\r",
      " 19%|######9                              | 5998/32000 [00:17<00:42, 618.59it/s]\r",
      " 19%|#######                              | 6061/32000 [00:17<00:41, 620.61it/s]\r",
      " 19%|#######                              | 6126/32000 [00:17<00:41, 627.70it/s]\r",
      " 19%|#######1                             | 6190/32000 [00:17<00:40, 629.90it/s]\r",
      " 20%|#######2                             | 6258/32000 [00:18<00:39, 643.90it/s]\r",
      " 20%|#######3                             | 6332/32000 [00:18<00:38, 671.44it/s]\r",
      " 20%|#######4                             | 6401/32000 [00:18<00:37, 675.82it/s]\r",
      " 20%|#######4                             | 6482/32000 [00:18<00:35, 715.72it/s]\r",
      " 20%|#######5                             | 6560/32000 [00:18<00:34, 734.70it/s]\r",
      " 21%|#######6                             | 6638/32000 [00:18<00:33, 746.57it/s]\r",
      " 21%|#######7                             | 6724/32000 [00:18<00:32, 780.47it/s]\r",
      " 21%|#######8                             | 6809/32000 [00:18<00:31, 801.24it/s]\r",
      " 22%|#######9                             | 6902/32000 [00:18<00:29, 839.24it/s]\r",
      " 22%|########                             | 6986/32000 [00:18<00:30, 815.41it/s]\r",
      " 22%|########1                            | 7068/32000 [00:19<00:35, 703.82it/s]\r",
      " 22%|########2                            | 7167/32000 [00:19<00:32, 773.24it/s]\r",
      " 23%|########3                            | 7261/32000 [00:19<00:30, 817.95it/s]\r",
      " 23%|########5                            | 7362/32000 [00:19<00:28, 870.54it/s]\r",
      " 23%|########6                            | 7466/32000 [00:19<00:26, 917.61it/s]\r",
      " 24%|########7                            | 7585/32000 [00:19<00:24, 996.35it/s]\r",
      " 24%|########6                           | 7696/32000 [00:19<00:23, 1029.25it/s]\r",
      " 25%|########8                           | 7850/32000 [00:19<00:20, 1178.74it/s]\r",
      " 25%|#########2                           | 7969/32000 [00:21<01:28, 270.31it/s]\r",
      " 25%|#########3                           | 8056/32000 [00:21<01:18, 304.56it/s]\r",
      " 25%|#########4                           | 8132/32000 [00:21<01:11, 334.87it/s]\r",
      " 26%|#########4                           | 8201/32000 [00:21<01:05, 361.71it/s]\r",
      " 26%|#########5                           | 8264/32000 [00:21<01:00, 390.94it/s]\r",
      " 26%|#########6                           | 8324/32000 [00:21<00:58, 406.38it/s]\r",
      " 26%|#########6                           | 8380/32000 [00:21<00:55, 426.74it/s]\r",
      " 26%|#########7                           | 8435/32000 [00:22<00:52, 446.86it/s]\r",
      " 27%|#########8                           | 8491/32000 [00:22<00:49, 471.25it/s]\r",
      " 27%|#########8                           | 8548/32000 [00:22<00:47, 495.34it/s]\r",
      " 27%|#########9                           | 8603/32000 [00:22<00:48, 486.11it/s]\r",
      " 27%|##########                           | 8660/32000 [00:22<00:46, 506.71it/s]\r",
      " 27%|##########                           | 8714/32000 [00:22<00:45, 515.19it/s]\r",
      " 27%|##########1                          | 8775/32000 [00:22<00:42, 540.39it/s]\r",
      " 28%|##########2                          | 8832/32000 [00:22<00:42, 548.58it/s]\r",
      " 28%|##########2                          | 8889/32000 [00:22<00:41, 550.92it/s]\r",
      " 28%|##########3                          | 8953/32000 [00:22<00:40, 574.86it/s]\r",
      " 28%|##########4                          | 9016/32000 [00:23<00:38, 590.76it/s]\r",
      " 28%|##########5                          | 9083/32000 [00:23<00:37, 612.56it/s]\r",
      " 29%|##########5                          | 9146/32000 [00:23<00:37, 616.53it/s]\r",
      " 29%|##########6                          | 9208/32000 [00:23<00:38, 592.47it/s]\r",
      " 29%|##########7                          | 9276/32000 [00:23<00:36, 616.10it/s]\r",
      " 29%|##########8                          | 9341/32000 [00:23<00:36, 625.49it/s]\r",
      " 29%|##########8                          | 9404/32000 [00:23<00:37, 604.91it/s]\r",
      " 30%|##########9                          | 9476/32000 [00:23<00:35, 636.90it/s]\r",
      " 30%|###########                          | 9543/32000 [00:23<00:34, 645.18it/s]\r",
      " 30%|###########1                         | 9612/32000 [00:23<00:34, 657.42it/s]\r",
      " 30%|###########2                         | 9687/32000 [00:24<00:32, 684.02it/s]\r",
      " 31%|###########2                         | 9767/32000 [00:24<00:31, 716.67it/s]\r",
      " 31%|###########3                         | 9845/32000 [00:24<00:30, 732.52it/s]\r",
      " 31%|###########4                         | 9919/32000 [00:24<00:30, 721.89it/s]\r",
      " 31%|###########5                         | 9998/32000 [00:24<00:29, 739.12it/s]\r",
      " 32%|###########3                        | 10087/32000 [00:24<00:27, 783.38it/s]\r",
      " 32%|###########4                        | 10172/32000 [00:24<00:27, 800.64it/s]\r",
      " 32%|###########5                        | 10265/32000 [00:24<00:25, 836.24it/s]\r",
      " 32%|###########6                        | 10349/32000 [00:24<00:30, 713.31it/s]\r",
      " 33%|###########7                        | 10459/32000 [00:25<00:26, 815.13it/s]\r",
      " 33%|###########9                        | 10583/32000 [00:25<00:22, 931.68it/s]\r",
      " 33%|###########7                       | 10715/32000 [00:25<00:20, 1040.71it/s]\r",
      " 34%|###########8                       | 10852/32000 [00:25<00:18, 1133.48it/s]\r",
      " 34%|############                       | 10990/32000 [00:25<00:17, 1202.91it/s]\r",
      " 35%|############1                      | 11142/32000 [00:25<00:16, 1294.69it/s]\r",
      " 35%|############3                      | 11295/32000 [00:25<00:15, 1361.51it/s]\r",
      " 36%|############5                      | 11458/32000 [00:25<00:14, 1438.95it/s]\r",
      " 36%|############7                      | 11641/32000 [00:25<00:13, 1554.32it/s]\r",
      " 37%|#############2                      | 11798/32000 [00:27<01:08, 295.25it/s]\r",
      " 37%|#############3                      | 11911/32000 [00:27<01:00, 329.94it/s]\r",
      " 38%|#############5                      | 12006/32000 [00:27<00:55, 359.44it/s]\r",
      " 38%|#############6                      | 12089/32000 [00:27<00:51, 390.32it/s]\r",
      " 38%|#############6                      | 12164/32000 [00:28<00:47, 421.96it/s]\r",
      " 38%|#############7                      | 12234/32000 [00:28<00:44, 448.76it/s]\r",
      " 38%|#############8                      | 12301/32000 [00:28<00:41, 470.93it/s]\r",
      " 39%|#############9                      | 12373/32000 [00:28<00:37, 517.43it/s]\r",
      " 39%|#############9                      | 12439/32000 [00:28<00:35, 545.27it/s]\r",
      " 39%|##############                      | 12505/32000 [00:28<00:34, 566.10it/s]\r",
      " 39%|##############1                     | 12581/32000 [00:28<00:31, 613.17it/s]\r",
      " 40%|##############2                     | 12660/32000 [00:28<00:29, 658.10it/s]\r",
      " 40%|##############3                     | 12738/32000 [00:28<00:27, 689.85it/s]\r",
      " 40%|##############4                     | 12819/32000 [00:29<00:26, 723.03it/s]\r",
      " 40%|##############5                     | 12895/32000 [00:29<00:26, 722.91it/s]\r",
      " 41%|##############6                     | 12979/32000 [00:29<00:25, 755.64it/s]\r",
      " 41%|##############6                     | 13057/32000 [00:29<00:25, 757.63it/s]\r",
      " 41%|##############7                     | 13144/32000 [00:29<00:23, 789.12it/s]\r",
      " 41%|##############8                     | 13236/32000 [00:29<00:22, 825.40it/s]\r",
      " 42%|##############9                     | 13331/32000 [00:29<00:21, 859.74it/s]\r",
      " 42%|###############1                    | 13427/32000 [00:29<00:20, 887.42it/s]\r",
      " 42%|###############2                    | 13523/32000 [00:29<00:20, 908.59it/s]\r",
      " 43%|###############3                    | 13618/32000 [00:29<00:19, 919.97it/s]\r",
      " 43%|###############4                    | 13729/32000 [00:30<00:18, 975.67it/s]\r",
      " 43%|###############1                   | 13844/32000 [00:30<00:17, 1027.28it/s]\r",
      " 44%|###############2                   | 13956/32000 [00:30<00:17, 1053.14it/s]\r",
      " 44%|###############3                   | 14067/32000 [00:30<00:16, 1068.94it/s]\r",
      " 44%|###############5                   | 14184/32000 [00:30<00:16, 1098.03it/s]\r",
      " 45%|###############6                   | 14306/32000 [00:30<00:15, 1133.05it/s]\r",
      " 45%|###############8                   | 14456/32000 [00:30<00:14, 1241.51it/s]\r",
      " 46%|###############9                   | 14602/32000 [00:30<00:13, 1305.25it/s]\r",
      " 46%|################1                  | 14773/32000 [00:30<00:12, 1425.64it/s]\r",
      " 47%|################3                  | 14962/32000 [00:30<00:10, 1564.02it/s]\r",
      " 47%|################5                  | 15165/32000 [00:31<00:09, 1703.52it/s]\r",
      " 48%|#################2                  | 15336/32000 [00:32<00:52, 318.98it/s]\r",
      " 48%|#################3                  | 15459/32000 [00:32<00:47, 351.59it/s]\r",
      " 49%|#################5                  | 15561/32000 [00:32<00:43, 380.38it/s]\r",
      " 49%|#################6                  | 15649/32000 [00:33<00:40, 406.10it/s]\r",
      " 49%|#################6                  | 15727/32000 [00:33<00:37, 429.30it/s]\r",
      " 49%|#################7                  | 15798/32000 [00:33<00:35, 452.48it/s]\r",
      " 50%|#################8                  | 15865/32000 [00:33<00:34, 473.38it/s]\r",
      " 50%|#################9                  | 15929/32000 [00:33<00:32, 491.93it/s]\r",
      " 50%|#################9                  | 15991/32000 [00:33<00:31, 510.88it/s]\r",
      " 50%|##################                  | 16052/32000 [00:33<00:30, 530.87it/s]\r",
      " 50%|##################1                 | 16113/32000 [00:33<00:29, 547.47it/s]\r",
      " 51%|##################1                 | 16176/32000 [00:34<00:27, 566.63it/s]\r",
      " 51%|##################2                 | 16239/32000 [00:34<00:27, 583.49it/s]\r",
      " 51%|##################3                 | 16301/32000 [00:34<00:32, 479.15it/s]\r",
      " 51%|##################4                 | 16364/32000 [00:34<00:30, 515.43it/s]\r",
      " 51%|##################4                 | 16427/32000 [00:34<00:28, 542.89it/s]\r",
      " 52%|##################5                 | 16494/32000 [00:34<00:26, 575.11it/s]\r",
      " 52%|##################6                 | 16558/32000 [00:34<00:26, 592.69it/s]\r",
      " 52%|##################7                 | 16623/32000 [00:34<00:25, 607.68it/s]\r",
      " 52%|##################7                 | 16694/32000 [00:34<00:24, 634.66it/s]\r",
      " 52%|##################8                 | 16766/32000 [00:35<00:23, 657.48it/s]\r",
      " 53%|##################9                 | 16836/32000 [00:35<00:22, 668.69it/s]\r",
      " 53%|###################                 | 16906/32000 [00:35<00:22, 675.62it/s]\r",
      " 53%|###################1                | 16984/32000 [00:35<00:21, 704.76it/s]\r",
      " 53%|###################1                | 17063/32000 [00:35<00:20, 727.37it/s]\r",
      " 54%|###################2                | 17143/32000 [00:35<00:19, 746.53it/s]\r",
      " 54%|###################3                | 17224/32000 [00:35<00:19, 764.42it/s]\r",
      " 54%|###################4                | 17302/32000 [00:35<00:19, 766.82it/s]\r",
      " 54%|###################5                | 17384/32000 [00:35<00:18, 782.29it/s]\r",
      " 55%|###################6                | 17469/32000 [00:35<00:18, 800.08it/s]\r",
      " 55%|###################7                | 17556/32000 [00:36<00:17, 820.04it/s]\r",
      " 55%|###################8                | 17644/32000 [00:36<00:17, 837.39it/s]\r",
      " 55%|###################9                | 17732/32000 [00:36<00:16, 848.23it/s]\r",
      " 56%|####################                | 17823/32000 [00:36<00:16, 864.79it/s]\r",
      " 56%|####################1               | 17914/32000 [00:36<00:16, 876.19it/s]\r",
      " 56%|####################2               | 18007/32000 [00:36<00:15, 890.20it/s]\r",
      " 57%|####################3               | 18108/32000 [00:36<00:15, 924.64it/s]\r",
      " 57%|####################4               | 18203/32000 [00:36<00:14, 931.54it/s]\r",
      " 57%|####################6               | 18316/32000 [00:36<00:13, 988.80it/s]\r",
      " 58%|####################1              | 18427/32000 [00:36<00:13, 1023.34it/s]\r",
      " 58%|####################2              | 18557/32000 [00:37<00:12, 1103.54it/s]\r",
      " 58%|####################4              | 18688/32000 [00:37<00:11, 1163.99it/s]\r",
      " 59%|####################6              | 18835/32000 [00:37<00:10, 1253.28it/s]\r",
      " 59%|####################7              | 18990/32000 [00:37<00:09, 1340.61it/s]\r",
      " 60%|####################9              | 19156/32000 [00:37<00:08, 1434.91it/s]\r",
      " 60%|#####################7              | 19300/32000 [00:39<00:51, 248.88it/s]\r",
      " 61%|#####################8              | 19404/32000 [00:39<00:44, 285.73it/s]\r",
      " 61%|#####################9              | 19493/32000 [00:39<00:38, 321.16it/s]\r",
      " 61%|######################              | 19572/32000 [00:39<00:34, 356.66it/s]\r",
      " 61%|######################1             | 19645/32000 [00:39<00:31, 391.82it/s]\r",
      " 62%|######################1             | 19714/32000 [00:39<00:28, 425.91it/s]\r",
      " 62%|######################2             | 19780/32000 [00:40<00:26, 460.78it/s]\r",
      " 62%|######################3             | 19845/32000 [00:40<00:24, 489.15it/s]\r",
      " 62%|######################3             | 19909/32000 [00:40<00:23, 516.24it/s]\r",
      " 62%|######################4             | 19974/32000 [00:40<00:21, 547.38it/s]\r",
      " 63%|######################5             | 20038/32000 [00:40<00:21, 567.67it/s]\r",
      " 63%|######################6             | 20102/32000 [00:40<00:20, 580.49it/s]\r",
      " 63%|######################6             | 20172/32000 [00:40<00:19, 610.81it/s]\r",
      " 63%|######################7             | 20239/32000 [00:40<00:18, 624.75it/s]\r",
      " 63%|######################8             | 20307/32000 [00:40<00:18, 639.46it/s]\r",
      " 64%|######################9             | 20376/32000 [00:40<00:17, 653.54it/s]\r",
      " 64%|#######################             | 20445/32000 [00:41<00:17, 662.66it/s]\r",
      " 64%|#######################             | 20513/32000 [00:41<00:17, 665.85it/s]\r",
      " 64%|#######################1            | 20586/32000 [00:41<00:16, 683.79it/s]\r",
      " 65%|#######################2            | 20662/32000 [00:41<00:16, 704.12it/s]\r",
      " 65%|#######################3            | 20738/32000 [00:41<00:15, 719.80it/s]\r",
      " 65%|#######################4            | 20811/32000 [00:41<00:15, 719.98it/s]\r",
      " 65%|#######################5            | 20890/32000 [00:41<00:15, 737.90it/s]\r",
      " 66%|#######################5            | 20970/32000 [00:41<00:14, 755.11it/s]\r",
      " 66%|#######################6            | 21051/32000 [00:41<00:14, 769.61it/s]\r",
      " 66%|#######################7            | 21136/32000 [00:41<00:13, 792.13it/s]\r",
      " 66%|#######################8            | 21216/32000 [00:42<00:13, 788.19it/s]\r",
      " 67%|#######################9            | 21305/32000 [00:42<00:13, 817.37it/s]\r",
      " 67%|########################            | 21392/32000 [00:42<00:12, 830.58it/s]\r",
      " 67%|########################1           | 21487/32000 [00:42<00:12, 863.85it/s]\r",
      " 67%|########################2           | 21586/32000 [00:42<00:11, 899.06it/s]\r",
      " 68%|########################3           | 21686/32000 [00:42<00:11, 926.93it/s]\r",
      " 68%|########################5           | 21786/32000 [00:42<00:10, 948.43it/s]\r",
      " 68%|########################6           | 21893/32000 [00:42<00:10, 984.22it/s]\r",
      " 69%|########################           | 22001/32000 [00:42<00:09, 1012.58it/s]\r",
      " 69%|########################1          | 22121/32000 [00:42<00:09, 1065.21it/s]\r",
      " 69%|########################3          | 22238/32000 [00:43<00:08, 1094.63it/s]\r",
      " 70%|########################4          | 22368/32000 [00:43<00:08, 1154.26it/s]\r",
      " 70%|########################6          | 22506/32000 [00:43<00:07, 1220.28it/s]\r",
      " 71%|########################7          | 22662/32000 [00:43<00:07, 1320.31it/s]\r",
      " 71%|########################9          | 22816/32000 [00:43<00:06, 1384.67it/s]\r",
      " 72%|#########################1         | 22996/32000 [00:43<00:05, 1507.65it/s]\r",
      " 72%|##########################          | 23147/32000 [00:45<00:35, 246.55it/s]\r",
      " 73%|##########################1         | 23256/32000 [00:45<00:30, 284.42it/s]\r",
      " 73%|##########################2         | 23349/32000 [00:45<00:27, 319.70it/s]\r",
      " 73%|##########################3         | 23431/32000 [00:45<00:24, 352.99it/s]\r",
      " 73%|##########################4         | 23505/32000 [00:45<00:21, 387.18it/s]\r",
      " 74%|##########################5         | 23575/32000 [00:46<00:20, 419.28it/s]\r",
      " 74%|##########################5         | 23642/32000 [00:46<00:18, 452.03it/s]\r",
      " 74%|##########################6         | 23707/32000 [00:46<00:17, 481.49it/s]\r",
      " 74%|##########################7         | 23772/32000 [00:46<00:15, 516.39it/s]\r",
      " 74%|##########################8         | 23837/32000 [00:46<00:14, 545.78it/s]\r",
      " 75%|##########################8         | 23901/32000 [00:46<00:14, 564.08it/s]\r",
      " 75%|##########################9         | 23968/32000 [00:46<00:13, 591.03it/s]\r",
      " 75%|###########################         | 24033/32000 [00:46<00:13, 606.05it/s]\r",
      " 75%|###########################1        | 24100/32000 [00:46<00:12, 621.22it/s]\r",
      " 76%|###########################1        | 24167/32000 [00:47<00:12, 633.32it/s]\r",
      " 76%|###########################2        | 24236/32000 [00:47<00:11, 647.06it/s]\r",
      " 76%|###########################3        | 24305/32000 [00:47<00:11, 657.63it/s]\r",
      " 76%|###########################4        | 24377/32000 [00:47<00:11, 673.93it/s]\r",
      " 76%|###########################5        | 24450/32000 [00:47<00:10, 689.53it/s]\r",
      " 77%|###########################5        | 24525/32000 [00:47<00:10, 705.10it/s]\r",
      " 77%|###########################6        | 24598/32000 [00:47<00:10, 712.08it/s]\r",
      " 77%|###########################7        | 24676/32000 [00:47<00:10, 731.74it/s]\r",
      " 77%|###########################8        | 24755/32000 [00:47<00:09, 747.74it/s]\r",
      " 78%|###########################9        | 24837/32000 [00:47<00:09, 768.18it/s]\r",
      " 78%|############################        | 24924/32000 [00:48<00:08, 796.96it/s]\r",
      " 78%|############################1       | 25007/32000 [00:48<00:08, 806.69it/s]\r",
      " 78%|############################2       | 25097/32000 [00:48<00:08, 834.08it/s]\r",
      " 79%|############################3       | 25183/32000 [00:48<00:08, 841.61it/s]\r",
      " 79%|############################4       | 25273/32000 [00:48<00:07, 857.65it/s]\r",
      " 79%|############################5       | 25369/32000 [00:48<00:07, 886.52it/s]\r",
      " 80%|############################6       | 25470/32000 [00:48<00:07, 922.05it/s]\r",
      " 80%|############################7       | 25576/32000 [00:48<00:06, 962.23it/s]\r",
      " 80%|############################       | 25687/32000 [00:48<00:06, 1005.43it/s]\r",
      " 81%|############################2      | 25801/32000 [00:48<00:05, 1045.62it/s]\r",
      " 81%|############################3      | 25923/32000 [00:49<00:05, 1097.47it/s]\r",
      " 81%|############################4      | 26048/32000 [00:49<00:05, 1141.37it/s]\r",
      " 82%|############################6      | 26169/32000 [00:49<00:05, 1161.90it/s]\r",
      " 82%|############################7      | 26301/32000 [00:49<00:04, 1206.68it/s]\r",
      " 83%|#############################7      | 26422/32000 [00:49<00:05, 976.01it/s]\r",
      " 83%|#############################      | 26575/32000 [00:49<00:04, 1118.23it/s]\r",
      " 84%|#############################2     | 26749/32000 [00:49<00:04, 1284.68it/s]\r",
      " 84%|##############################2     | 26885/32000 [00:51<00:23, 221.27it/s]\r",
      " 84%|##############################3     | 26983/32000 [00:51<00:19, 257.15it/s]\r",
      " 85%|##############################4     | 27068/32000 [00:51<00:16, 292.96it/s]\r",
      " 85%|##############################5     | 27145/32000 [00:52<00:14, 329.33it/s]\r",
      " 85%|##############################6     | 27217/32000 [00:52<00:13, 365.87it/s]\r",
      " 85%|##############################6     | 27285/32000 [00:52<00:11, 402.58it/s]\r",
      " 85%|##############################7     | 27351/32000 [00:52<00:10, 439.91it/s]\r",
      " 86%|##############################8     | 27415/32000 [00:52<00:09, 471.99it/s]\r",
      " 86%|##############################9     | 27480/32000 [00:52<00:08, 508.00it/s]\r",
      " 86%|##############################9     | 27544/32000 [00:52<00:08, 536.44it/s]\r",
      " 86%|###############################     | 27608/32000 [00:52<00:07, 557.16it/s]\r",
      " 86%|###############################1    | 27675/32000 [00:52<00:07, 585.94it/s]\r",
      " 87%|###############################2    | 27740/32000 [00:53<00:07, 602.88it/s]\r",
      " 87%|###############################2    | 27805/32000 [00:53<00:06, 615.95it/s]\r",
      " 87%|###############################3    | 27877/32000 [00:53<00:06, 642.96it/s]\r",
      " 87%|###############################4    | 27945/32000 [00:53<00:06, 652.42it/s]\r",
      " 88%|###############################5    | 28016/32000 [00:53<00:05, 666.92it/s]\r",
      " 88%|###############################5    | 28088/32000 [00:53<00:05, 680.10it/s]\r",
      " 88%|###############################6    | 28161/32000 [00:53<00:05, 693.76it/s]\r",
      " 88%|###############################7    | 28236/32000 [00:53<00:05, 709.84it/s]\r",
      " 88%|###############################8    | 28311/32000 [00:53<00:05, 721.67it/s]\r",
      " 89%|###############################9    | 28389/32000 [00:53<00:04, 737.53it/s]\r",
      " 89%|################################    | 28469/32000 [00:54<00:04, 755.61it/s]\r",
      " 89%|################################1   | 28551/32000 [00:54<00:04, 772.13it/s]\r",
      " 89%|################################2   | 28635/32000 [00:54<00:04, 789.79it/s]\r",
      " 90%|################################3   | 28723/32000 [00:54<00:04, 814.07it/s]\r",
      " 90%|################################4   | 28812/32000 [00:54<00:03, 834.67it/s]\r",
      " 90%|################################5   | 28903/32000 [00:54<00:03, 856.70it/s]\r",
      " 91%|################################6   | 28997/32000 [00:54<00:03, 881.02it/s]\r",
      " 91%|################################7   | 29096/32000 [00:54<00:03, 911.50it/s]\r",
      " 91%|################################8   | 29197/32000 [00:54<00:02, 939.89it/s]\r",
      " 92%|################################9   | 29307/32000 [00:54<00:02, 987.43it/s]\r",
      " 92%|################################1  | 29420/32000 [00:55<00:02, 1028.77it/s]\r",
      " 92%|################################3  | 29538/32000 [00:55<00:02, 1072.51it/s]\r",
      " 93%|################################4  | 29655/32000 [00:55<00:02, 1100.99it/s]\r",
      " 93%|################################5  | 29780/32000 [00:55<00:01, 1144.48it/s]\r",
      " 93%|################################7  | 29913/32000 [00:55<00:01, 1198.97it/s]\r",
      " 94%|################################8  | 30060/32000 [00:55<00:01, 1279.09it/s]\r",
      " 94%|#################################  | 30206/32000 [00:55<00:01, 1332.73it/s]\r",
      " 95%|#################################2 | 30373/32000 [00:55<00:01, 1431.59it/s]\r",
      " 96%|##################################3 | 30562/32000 [00:57<00:05, 248.40it/s]\r",
      " 96%|##################################4 | 30666/32000 [00:57<00:04, 283.13it/s]\r",
      " 96%|##################################6 | 30756/32000 [00:57<00:03, 316.86it/s]\r",
      " 96%|##################################6 | 30836/32000 [00:58<00:03, 350.00it/s]\r",
      " 97%|##################################7 | 30909/32000 [00:58<00:02, 381.73it/s]\r",
      " 97%|##################################8 | 30977/32000 [00:58<00:02, 415.72it/s]\r",
      " 97%|##################################9 | 31043/32000 [00:58<00:02, 448.30it/s]\r",
      " 97%|##################################9 | 31107/32000 [00:58<00:01, 474.95it/s]\r",
      " 97%|################################### | 31170/32000 [00:58<00:01, 506.78it/s]\r",
      " 98%|###################################1| 31233/32000 [00:58<00:01, 533.02it/s]\r",
      " 98%|###################################2| 31297/32000 [00:58<00:01, 558.72it/s]\r",
      " 98%|###################################2| 31363/32000 [00:58<00:01, 582.50it/s]\r",
      " 98%|###################################3| 31428/32000 [00:59<00:00, 598.68it/s]\r",
      " 98%|###################################4| 31495/32000 [00:59<00:00, 617.66it/s]\r",
      " 99%|###################################5| 31563/32000 [00:59<00:00, 633.69it/s]\r",
      " 99%|###################################5| 31631/32000 [00:59<00:00, 646.61it/s]\r",
      " 99%|###################################6| 31699/32000 [00:59<00:00, 655.50it/s]\r",
      " 99%|###################################7| 31772/32000 [00:59<00:00, 675.13it/s]\r",
      "100%|###################################8| 31846/32000 [00:59<00:00, 692.62it/s]\r",
      "100%|###################################9| 31922/32000 [00:59<00:00, 711.07it/s]\r",
      "100%|###################################9| 31994/32000 [00:59<00:00, 711.42it/s]\r",
      "100%|####################################| 32000/32000 [00:59<00:00, 534.53it/s]\n"
     ]
    }
   ],
   "source": [
    "subword-nmt learn-bpe -s 32000 < /tmp/europarl-v9.true.en > /tmp/code.en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32001 /tmp/code.en\n"
     ]
    }
   ],
   "source": [
    "wc -l /tmp/code.en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sea food</w>\n",
      "scre ened</w>\n",
      "sco t-free</w>\n",
      "sa y\n",
      "s as</w>\n",
      "ru de</w>\n",
      "ron ique</w>\n",
      "restra ining</w>\n",
      "reservo ir</w>\n",
      "res a</w>\n"
     ]
    }
   ],
   "source": [
    "tail /tmp/code.en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to true-casing, after training the BPE codes we have to apply it\n",
    "to the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "subword-nmt apply-bpe -c /tmp/code.en < /tmp/europarl-v9.true.en > /tmp/europarl-v9.bpe.en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can check the vocabulary size once more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat /tmp/europarl-v9.bpe.en | tr ' ' '\\n' | sort | uniq -c > /tmp/europarl.bpe.hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31520\n",
      "\n",
      "   2407 listen\n",
      "     39 listen@@\n",
      "   1719 listened\n",
      "   1438 listening\n",
      "     92 listens\n",
      "\n",
      "listen@@ ers an@@ da@@ very@@ long@@ word\n"
     ]
    }
   ],
   "source": [
    "wc -l < /tmp/europarl.bpe.hist\n",
    "echo\n",
    "cat /tmp/europarl.bpe.hist | grep -i ' *[0-9]*  *listen'\n",
    "echo\n",
    "echo 'listeners andaverylongword' | subword-nmt apply-bpe -c /tmp/code.en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistical Language Model\n",
    "==========================\n",
    "\n",
    "In the following we will use n-gram language modeling to look at domain,\n",
    "an important consideration when training NMT models.  \n",
    "All of the data are provided at `/opt/data/lmdom/`.  \n",
    "To train an order-n language model use\n",
    "```bash\n",
    "lmplz -o {order} < {training_data} > {lm_name.arpa}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 1/5 Counting and sorting n-grams ===\n",
      "Reading /opt/data/lmdom/wiki.en.txt\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Unigram tokens 42681165 types 1114998\n",
      "=== 2/5 Calculating and sorting adjusted counts ===\n",
      "Chain sizes: 1:13379976 2:216187715584\n",
      "Statistics:\n",
      "1 1114998 D1=0.731948 D2=1.03082 D3+=1.2829\n",
      "2 9551015 D1=0.754579 D2=1.0721 D3+=1.31276\n",
      "Memory estimate for binary LM:\n",
      "type     MB\n",
      "probing 191 assuming -p 1.5\n",
      "probing 195 assuming -r models -p 1.5\n",
      "trie     84 without quantization\n",
      "trie     58 assuming -q 8 -b 8 quantization \n",
      "trie     84 assuming -a 22 array pointer compression\n",
      "trie     58 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
      "=== 3/5 Calculating and sorting initial probabilities ===\n",
      "Chain sizes: 1:13379976 2:152816240\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
      "Chain sizes: 1:13379976 2:152816240\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 5/5 Writing ARPA model ===\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Name:lmplz\tVmPeak:211325412 kB\tVmRSS:35644 kB\tRSSMax:57754612 kB\tuser:26.9182\tsys:33.8399\tCPU:60.7581\treal:60.9906\n"
     ]
    }
   ],
   "source": [
    "lmplz -o 2 < /opt/data/lmdom/wiki.en.txt > /tmp/wiki.arpa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the perplexity of a dataset using an arpa file use\n",
    "```bash\n",
    "python3 perp.py {lm_name.arpa} {text_data}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading /tmp/wiki.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "212.9959476604841\n",
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading /tmp/wiki.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "353676.242629899\n"
     ]
    }
   ],
   "source": [
    "perp.py /tmp/wiki.arpa /opt/data/lmdom/wiki.en.txt\n",
    "perp.py /tmp/wiki.arpa /tmp/wiki.arpa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   First, train a bigram ($n=2$) LM on the English UDHR. Use this model\n",
    "    on `dev` data. What is the perplexity?   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 1/5 Counting and sorting n-grams ===\n",
      "Reading /opt/data/lmdom/english.udhr\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Unigram tokens 1778 types 627\n",
      "=== 2/5 Calculating and sorting adjusted counts ===\n",
      "Chain sizes: 1:7524 2:216201084928\n",
      "Statistics:\n",
      "1 627 D1=0.786408 D2=1.03486 D3+=1.95146\n",
      "2 1341 D1=0.8418 D2=1.35127 D3+=1.19614\n",
      "Memory estimate for binary LM:\n",
      "type    kB\n",
      "probing 39 assuming -p 1.5\n",
      "probing 41 assuming -r models -p 1.5\n",
      "trie    21 without quantization\n",
      "trie    18 assuming -q 8 -b 8 quantization \n",
      "trie    21 assuming -a 22 array pointer compression\n",
      "trie    18 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
      "=== 3/5 Calculating and sorting initial probabilities ===\n",
      "Chain sizes: 1:7524 2:21456\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
      "Chain sizes: 1:7524 2:21456\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 5/5 Writing ARPA model ===\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Name:lmplz\tVmPeak:211308004 kB\tVmRSS:6264 kB\tRSSMax:57605188 kB\tuser:6.12102\tsys:23.712\tCPU:29.833\treal:29.8323\n"
     ]
    }
   ],
   "source": [
    "lmplz -o 2 < /opt/data/lmdom/english.udhr > /tmp/udhr.arpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Universal Declaration of Human Rights\n",
      "Preamble\n",
      "Whereas recognition of the inherent dignity and of the equal and inalienable rights of all members of the human family is the foundation of freedom, justice and peace in the world,\n",
      "Whereas disregard and contempt for human rights have resulted in barbarous acts which have outraged the conscience of mankind, and the advent of a world in which human beings shall enjoy freedom of speech and belief and freedom from fear and want has been proclaimed as the highest aspiration of the common people,\n",
      "Whereas it is essential, if man is not to be compelled to have recourse, as a last resort, to rebellion against tyranny and oppression, that human rights should be protected by the rule of law,\n",
      "Whereas it is essential to promote the development of friendly relations between nations,\n",
      "Whereas the peoples of the United Nations have in the Charter reaffirmed their faith in fundamental human rights, in the dignity and worth of the human person and in the equal rights of men and women and have determined to promote social progress and better standards of life in larger freedom,\n",
      "Whereas Member States have pledged themselves to achieve, in cooperation with the United Nations, the promotion of universal respect for and observance of human rights and fundamental freedoms,\n",
      "Whereas a common understanding of these rights and freedoms is of the greatest importance for the full realization of this pledge,\n",
      "Now, therefore,\n"
     ]
    }
   ],
   "source": [
    "head /opt/data/lmdom/english.udhr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading /tmp/udhr.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "613.303224701251\n"
     ]
    }
   ],
   "source": [
    "perp.py /tmp/udhr.arpa /opt/data/lmdom/dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Now, train a bigram LM on the wikipedia data. Use this model to\n",
    "    calculate the perplexity of the `dev` data. What is the perplexity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading /tmp/wiki.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "2455.2919557159653\n"
     ]
    }
   ],
   "source": [
    "perp.py /tmp/wiki.arpa /opt/data/lmdom/dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Finally, train a bigram LM on the novel chapter. Use this model to\n",
    "    calculate the perplexity of the `dev` data. What is the perplexity?    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr. and Mrs. Dursley , of number four , Privet Drive , were proud to say that they were perfectly normal , thank you very much . They were the last people you &apos;d expect to be involved in anything strange or mysterious , because they just didn &apos;t hold with such nonsense .\n",
      "\n",
      "Mr. Dursley was the director of a firm called Grunnings , which made drills . He was a big , beefy man with hardly any neck , although he did have a very large mustache . Mrs. Dursley was thin and blonde and had nearly twice the usual amount of neck , which came in very useful as she spent so much of her time craning over garden fences , spying on the neighbors . The Dursleys had a small son called Dudley and in their opinion there was no finer boy anywhere .\n",
      "\n",
      "The Dursleys had everything they wanted , but they also had a secret , and their greatest fear was that somebody would discover it . They didn &apos;t think they could bear it if anyone found out about the Potters . Mrs. Potter was Mrs. Dursley &apos;s sister , but they hadn &apos;t met for several years ; in fact , Mrs. Dursley pretended she didn &apos;t have a sister , because her sister and her good-for-nothing husband were as unDursleyish as it was possible to be . The Dursleys shuddered to think what the neighbors would say if the Potters arrived in the street . The Dursleys knew that the Potters had a small son , too , but they had never even seen him . This boy was another good reason for keeping the Potters away ; they didn &apos;t want Dudley mixing with a child like that .\n",
      "\n",
      "When Mr. and Mrs. Dursley woke up on the dull , gray Tuesday our story starts , there was nothing about the cloudy sky outside to suggest that strange and mysterious things would soon be happening all over the country . Mr. Dursley hummed as he picked out his most boring tie for work , and Mrs. Dursley gossiped away happily as she wrestled a screaming Dudley into his high chair .\n",
      "\n",
      "None of them noticed a large , tawny owl flutter past the window .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "head /opt/data/lmdom/hpchapter1.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 1/5 Counting and sorting n-grams ===\n",
      "Reading /opt/data/lmdom/hpchapter1.txt\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Unigram tokens 5722 types 1251\n",
      "=== 2/5 Calculating and sorting adjusted counts ===\n",
      "Chain sizes: 1:15012 2:216201084928\n",
      "Statistics:\n",
      "1 1251 D1=0.637427 D2=1.27739 D3+=1.75624\n",
      "2 4003 D1=0.808964 D2=1.09147 D3+=1.53722\n",
      "Memory estimate for binary LM:\n",
      "type     kB\n",
      "probing 102 assuming -p 1.5\n",
      "probing 107 assuming -r models -p 1.5\n",
      "trie     49 without quantization\n",
      "trie     39 assuming -q 8 -b 8 quantization \n",
      "trie     49 assuming -a 22 array pointer compression\n",
      "trie     39 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
      "=== 3/5 Calculating and sorting initial probabilities ===\n",
      "Chain sizes: 1:15012 2:64048\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
      "Chain sizes: 1:15012 2:64048\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 5/5 Writing ARPA model ===\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Name:lmplz\tVmPeak:211308024 kB\tVmRSS:6280 kB\tRSSMax:57605184 kB\tuser:7.10461\tsys:24.2404\tCPU:31.3451\treal:31.3415\n"
     ]
    }
   ],
   "source": [
    "lmplz -o 2 < /opt/data/lmdom/hpchapter1.txt > /tmp/hpchapter1.arpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading /tmp/hpchapter1.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "516.76552634914\n"
     ]
    }
   ],
   "source": [
    "perp.py /tmp/hpchapter1.arpa /opt/data/lmdom/dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   How was the perplexity different with each of the models? Look at\n",
    "    the first few lines of each training dataset, and the `dev` data.\n",
    "    Why might this be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Long-Expected Party\n",
      "When Mr. Bilbo Baggins of Bag End announced that he would shortly be\n",
      "celebrating his eleventy-first birthday with a party of special\n",
      "magnificence , there was much talk and excitement in Hobbiton .\n",
      "Bilbo was very rich and very peculiar , and had been the\n",
      "wonder of the Shire for sixty years , ever since his remarkable\n",
      "disappearance and unexpected return . The riches he had brought back\n",
      "from his travels had now become a local legend , and it was popularly\n",
      "believed , whatever the old folk might say , that the Hill at Bag End\n",
      "was full of tunnels stuffed with treasure . And if that was not enough\n",
      "for fame , there was also his prolonged vigour to marvel at . Time wore\n",
      "on , but it seemed to have little effect on Mr. Baggins . At ninety he\n",
      "was much the same as at fifty . At ninety-nine they began to call him\n",
      "well-preserved ; but unchanged would have been nearer the mark . There\n",
      "were some that shook their heads and thought this was too much of a\n",
      "good thing ; it seemed unfair that anyone should possess ( apparently )\n",
      "perpetual youth as well as ( reputedly ) inexhaustible wealth .\n",
      "&quot; It will have to be paid for , &quot; they said . &quot; It isn &quot; t natural ,\n",
      "and trouble will come of it ! &quot;\n",
      "\n",
      "But so far trouble had not come ; and as Mr. Baggins was\n",
      "generous with his money , most people were willing to forgive him his\n",
      "oddities and his good fortune . He remained on visiting terms with his\n",
      "relatives ( except , of course , the Sackville-Bagginses ) , and he had\n",
      "many devoted admirers among the hobbits of poor and unimportant\n",
      "families . But he had no close friends , until some of his younger\n",
      "cousins began to grow up .\n",
      "The eldest of these , and Bilbo &quot; s favourite , was young Frodo\n",
      "Baggins . When Bilbo was ninety-nine he adopted Frodo as his heir , and\n",
      "brought him to live at Bag End ; and the hopes of the Sackville-\n",
      "Bagginses were finally dashed . Bilbo and Frodo happened to have the\n",
      "same birthday , September 22nd . &quot; You had better come and live here ,\n",
      "Frodo my lad , &quot; said Bilbo one day ; &quot; and then we can celebrate our\n",
      "birthday-parties comfortably together . &quot; At that time Frodo was still\n",
      "in his tweens , as the hobbits called the irresponsible twenties\n",
      "between childhood and coming of age at thirty-three .\n",
      "Twelve more years passed . Each year the Bagginses had given\n",
      "very lively combined birthday-parties at Bag End ; but now it was\n",
      "understood that something quite exceptional was being planned for\n",
      "that autumn . Bilbo was going to be eleventy-one , 111 , a rather\n",
      "curious number , and a very respectable age for a hobbit ( the Old Took\n",
      "himself had only reached 130 ) ; and Frodo was going to be thirty-\n",
      "three , 33 , an important number : the date of his &quot; coming of age &quot; .\n",
      "Tongues began to wag in Hobbiton and Bywater ; and rumour of\n",
      "the coming event travelled all over the Shire . The history and\n",
      "character of Mr. Bilbo Baggins became once again the chief topic of\n",
      "conversation ; and the older folk suddenly found their reminiscences\n",
      "in welcome demand .\n",
      "No one had a more attentive audience than old Ham Gamgee ,\n",
      "commonly known as the Gaffer . He held forth at The Ivy Bush , a small\n",
      "inn on the Bywater road ; and he spoke with some authority , for he had\n",
      "tended the garden at Bag End for forty years , and had helped old\n",
      "Holman in the same job before that . Now that he was himself growing\n",
      "old and stiff in the joints , the job was mainly carried on by his\n",
      "youngest son , Sam Gamgee . Both father and son were on very friendly\n",
      "terms with Bilbo and Frodo . They lived on the Hill itself , in Number\n",
      "3 Bagshot Row just below Bag End .\n",
      "&quot; A very nice well-spoken gentlehobbit is Mr. Bilbo , as I &quot; ve\n",
      "always said , &quot; the Gaffer declared . With perfect truth : for Bilbo was\n",
      "very polite to him , calling him &quot; Master Hamfast &quot; , and consulting him\n",
      "constantly upon the growing of vegetables — in the matter of &quot; roots &quot; ,\n",
      "especially potatoes , the Gaffer was recognized as the leading\n",
      "authority by all in the neighbourhood ( including himself ) .\n",
      "&quot; But what about this Frodo that lives with him ? &quot; asked Old\n",
      "Noakes of Bywater . &quot; Baggins is his name , but he &quot; s more than half a\n",
      "Brandybuck , they say . It beats me why any Baggins of Hobbiton should\n",
      "go looking for a wife away there in Buckland , where folks are so\n",
      "queer . &quot;\n",
      "&quot; And no wonder they &quot; re queer , &quot; put in Daddy Twofoot ( the\n",
      "Gaffer &quot; s next-door neighbour ) , &quot; if they live on the wrong side of the\n",
      "Brandywine River , and right agin the Old Forest . That &quot; s a dark bad\n",
      "place , if half the tales be true . &quot;\n",
      "&quot; You &quot; re right , Dad ! &quot; said the Gaffer . &quot; Not that the\n",
      "Brandybucks of Buckland live in the Old Forest ; but they &quot; re a queer\n",
      "breed , seemingly . They fool about with boats on that big river — and\n",
      "that isn &quot; t natural . Small wonder that trouble came of it , I say . But\n",
      "be that as it may , Mr. Frodo is as nice a young hobbit as you could\n",
      "wish to meet . Very much like Mr. Bilbo , and in more than looks . After\n",
      "all his father was a Baggins . A decent respectable hobbit was Mr.\n",
      "Drogo Baggins ; there was never much to tell of him , till he was\n",
      "drownded . &quot;\n",
      "&quot; Drownded ? &quot; said several voices . They had heard this and\n",
      "other darker rumours before , of course ; but hobbits have a passion\n",
      "for family history , and they were ready to hear it again .\n",
      "&quot; Well , so they say , &quot; said the Gaffer . &quot; You see : Mr. Drogo , he\n",
      "married poor Miss Primula Brandybuck . She was our Mr. Bilbo &quot; s first\n",
      "cousin on the mother &quot; s side ( her mother being the youngest of the Old\n",
      "Took &quot; s daughters ) ; and Mr. Drogo was his second cousin . So Mr. Frodo\n",
      "is his first and second cousin , once removed either way , as the\n",
      "saying is , if you follow me . And Mr. Drogo was staying at Brandy Hall\n",
      "with his father-in-law , old Master Gorbadoc , as he often did after\n",
      "his marriage ( him being partial to his vittles , and old Gorbadoc\n",
      "keeping a mighty generous table ) ; and he went out boating on the\n",
      "Brandywine River ; and he and his wife were drownded , and poor Mr.\n",
      "Frodo only a child and all . &quot;\n",
      "&quot; I &quot; ve heard they went on the water after dinner in the\n",
      "moonlight , &quot; said Old Noakes ; &quot; and it was Drogo &quot; s weight as sunk the\n",
      "boat . &quot;\n",
      "&quot; And I heard she pushed him in , and he pulled her in after\n",
      "him , &quot; said Sandyman , the Hobbiton miller .\n",
      "&quot; You shouldn &quot; t listen to all you hear , Sandyman , &quot; said the\n",
      "Gaffer , who did not much like the miller . &quot; There isn &quot; t no call to go\n",
      "talking of pushing and pulling . Boats are quite tricky enough for\n",
      "those that sit still without looking further for the cause of\n",
      "trouble . Anyway : there was this Mr. Frodo left an orphan and\n",
      "stranded , as you might say , among those queer Bucklanders , being\n",
      "brought up anyhow in Brandy Hall . A regular warren , by all accounts .\n",
      "Old Master Gorbadoc never had fewer than a couple of hundred\n",
      "relations in the place . Mr. Bilbo never did a kinder deed than when\n",
      "he brought the lad back to live among decent folk .\n",
      "&quot; But I reckon it was a nasty shock for those Sackville-\n",
      "Bagginses . They thought they were going to get Bag End , that time\n",
      "when he went off and was thought to be dead . And then he comes back\n",
      "and orders them off ; and he goes on living and living , and never\n",
      "looking a day older , bless him ! And suddenly he produces an heir , and\n",
      "has all the papers made out proper . The Sackville-Bagginses won &quot; t\n",
      "never see the inside of Bag End now , or it is to be hoped not . &quot;\n",
      "&quot; There &quot; s a tidy bit of money tucked away up there , I hear\n",
      "tell , &quot; said a stranger , a visitor on business from Michel Delving in\n",
      "the Westfarthing . &quot; All the top of your hill is full of tunnels packed\n",
      "with chests of gold and silver , and jools , by what I &quot; ve heard . &quot;\n",
      "&quot; Then you &quot; ve heard more than I can speak to , &quot; answered the\n",
      "Gaffer . I know nothing about jools . Mr. Bilbo is free with his money ,\n",
      "and there seems no lack of it ; but I know of no tunnel-making . I saw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr. Bilbo when he came back , a matter of sixty years ago , when I was\n",
      "a lad . I &quot; d not long come prentice to old Holman ( him being my dad &quot; s\n",
      "cousin ) , but he had me up at Bag End helping him to keep folks from\n",
      "trampling and trapessing all over the garden while the sale was on .\n"
     ]
    }
   ],
   "source": [
    "head -n128 /opt/data/lmdom/dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   How do you think this would change if you used a larger order\n",
    "    (e.g. 5) LM?   \n",
    "    N-grams can be good models, but only if the test corpus looks like\n",
    "    the training corpus. In reality, it often does not. We need to come\n",
    "    up with adaptation and smoothing methods to account for this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 1/5 Counting and sorting n-grams ===\n",
      "Reading /opt/data/lmdom/hpchapter1.txt\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Unigram tokens 5722 types 1251\n",
      "=== 2/5 Calculating and sorting adjusted counts ===\n",
      "Chain sizes: 1:15012 2:36800184320 3:69000347648 4:110400552960\n",
      "Statistics:\n",
      "1 1251 D1=0.637427 D2=1.27739 D3+=1.75624\n",
      "2 4003 D1=0.82817 D2=1.23715 D3+=1.60199\n",
      "3 5247 D1=0.934414 D2=1.50625 D3+=1.67374\n",
      "4 5494 D1=0.976564 D2=1.54928 D3+=2.60937\n",
      "Memory estimate for binary LM:\n",
      "type     kB\n",
      "probing 345 assuming -p 1.5\n",
      "probing 404 assuming -r models -p 1.5\n",
      "trie    155 without quantization\n",
      "trie     92 assuming -q 8 -b 8 quantization \n",
      "trie    149 assuming -a 22 array pointer compression\n",
      "trie     85 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
      "=== 3/5 Calculating and sorting initial probabilities ===\n",
      "Chain sizes: 1:15012 2:64048 3:104940 4:131856\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
      "Chain sizes: 1:15012 2:64048 3:104940 4:131856\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 5/5 Writing ARPA model ===\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Name:lmplz\tVmPeak:211316204 kB\tVmRSS:6692 kB\tRSSMax:42251868 kB\tuser:4.78237\tsys:16.4344\tCPU:21.2168\treal:21.1947\n",
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading /tmp/hp_o4.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "503.7123702342283\n"
     ]
    }
   ],
   "source": [
    "lmplz -o 4 < /opt/data/lmdom/hpchapter1.txt > /tmp/hp_o4.arpa\n",
    "perp.py /tmp/hp_o4.arpa /opt/data/lmdom/dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 1/5 Counting and sorting n-grams ===\n",
      "Reading /opt/data/lmdom/english.udhr\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Unigram tokens 1778 types 627\n",
      "=== 2/5 Calculating and sorting adjusted counts ===\n",
      "Chain sizes: 1:7524 2:36800184320 3:69000347648 4:110400552960\n",
      "Statistics:\n",
      "1 627 D1=0.786408 D2=1.03486 D3+=1.95146\n",
      "2 1341 D1=0.872832 D2=1.43464 D3+=1.52997\n",
      "3 1551 D1=0.956688 D2=1.4091 D3+=0.813285\n",
      "4 1543 D1=0.950096 D2=1.41533 D3+=0.62476\n",
      "Memory estimate for binary LM:\n",
      "type     kB\n",
      "probing 110 assuming -p 1.5\n",
      "probing 130 assuming -r models -p 1.5\n",
      "trie     52 without quantization\n",
      "trie     36 assuming -q 8 -b 8 quantization \n",
      "trie     50 assuming -a 22 array pointer compression\n",
      "trie     34 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
      "=== 3/5 Calculating and sorting initial probabilities ===\n",
      "Chain sizes: 1:7524 2:21456 3:31020 4:37032\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
      "Chain sizes: 1:7524 2:21456 3:31020 4:37032\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 5/5 Writing ARPA model ===\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Name:lmplz\tVmPeak:211316204 kB\tVmRSS:6512 kB\tRSSMax:42251704 kB\tuser:4.48327\tsys:16.8413\tCPU:21.3246\treal:21.3111\n"
     ]
    }
   ],
   "source": [
    "lmplz -o 4 < /opt/data/lmdom/english.udhr > /tmp/udhr_o4.arpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"kenlm.pyx\", line 139, in kenlm.Model.__init__\n",
      "RuntimeError: util/file.cc:76 in int util::OpenReadOrThrow(const char*) threw ErrnoException because `-1 == (ret = open(name, 00))'.\n",
      "No such file or directory while opening /tmp/udhr_o3.arpa\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/perp.py\", line 9, in <module>\n",
      "    model=kenlm.Model(arpafile)\n",
      "  File \"kenlm.pyx\", line 142, in kenlm.Model.__init__\n",
      "OSError: Cannot read model '/tmp/udhr_o3.arpa' (util/file.cc:76 in int util::OpenReadOrThrow(const char*) threw ErrnoException because `-1 == (ret = open(name, 00))'. No such file or directory while opening /tmp/udhr_o3.arpa)\n",
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading /tmp/udhr_o4.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "591.2512898622641\n"
     ]
    }
   ],
   "source": [
    "perp.py /tmp/udhr_o3.arpa /opt/data/lmdom/dev\n",
    "perp.py /tmp/udhr_o4.arpa /opt/data/lmdom/dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Perplexity is often used as intrinsic evaluation for language\n",
    "    models. Let's think about what these values mean more closely.\n",
    "    Suppose a 'sentence' consists of random digits. What is the\n",
    "    perplexity of this sentence, if our model assigns probability\n",
    "    $p=1/10$ to each digit?   \n",
    "  - \\begin{align*}\n",
    "      H = & \\sum_{i=0}^{9}{\\frac{1}{10} log \\left( \\frac{1}{10} \\right) } \\\\\n",
    "        = & -log(10) \\\\\n",
    "      \\implies ppl = & e^{-H} = 10  \n",
    "    \\end{align*}\n",
    "  - \"intuitively\": perplexity is the \"average branching factor\". Given a uniform distribution each decoding step branches into 10 equally probable decisions  \n",
    "     $\\implies$ average branching factor 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Consider now a natural language sentence. What is the maximum\n",
    "    perplexity of a sentence with 10 tokens? With 100 tokens?   \n",
    "  - maximum perplexity is reached in case of uniform distribution (see above), for $N$ tokens and vocab size $V$:\n",
    "    $$ H = exp\\left(\\frac{N}{V}log\\left(V\\right)\\right) = V^{\\frac{N}{V}} $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Let's return to our language models. Pick one of the three datasets,\n",
    "    and train trigram and 4-gram LMs as well. Evaluate the perplexity of\n",
    "    the `dev` data. How is it different between the bigram, trigram, and\n",
    "    4-gram models? Why might this be?   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   One major problem with models is generalization. If we have a bigram\n",
    "    we have never seen before in `dev`, our model will produce a\n",
    "    probability of 0 for the sentence and we can't compute the\n",
    "    perplexity (can't divide by 0!). Not good  \n",
    "    In order to do something about this, people typically use smoothing\n",
    "    methods. The simplest is called add-one or Laplace smoothing. This\n",
    "    is as simple as it sounds: we increment the counts of all seen word\n",
    "    types (unique) by 1, and the vocabulary by the same amount (size of\n",
    "    the vocabulary, number of unique words)  \n",
    "    Now, there is a small probability allocated for unknown words:\n",
    "    unseen n-grams have $\\frac{1}{N+V}$ instead of 0!\n",
    "    $$\\mathcal{P}_{Laplace}(w_i) = \\frac{count_i + 1}{N + V}$$\n",
    "\n",
    "    A basic bigram language model has been coded for you in python,\n",
    "    `bigram_lm.py`. Use this script to train a bigram LM on\n",
    "    hpchapter1.txt. It will print the model entropy.   \n",
    "    In this last exercise, modify this script to use add-one smoothing.\n",
    "    Now train a bigram LM. How has the entropy changed?   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The entropy of the bigram model for this file is: 3.052 bits.\n"
     ]
    }
   ],
   "source": [
    "bigram_lm.py /opt/data/lmdom/hpchapter1.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patching file bigram_lm.py\n"
     ]
    }
   ],
   "source": [
    "cp /usr/local/bin/bigram_lm.py bigram_lm.py\n",
    "patch bigram_lm.py <<EOF\n",
    "--- /usr/local/bin/bigram_lm.py\t2021-07-05 12:54:44.000000000 +0000\n",
    "+++ bigram_lm.py\t2022-06-20 12:38:37.247364696 +0000\n",
    "@@ -39,8 +39,8 @@\n",
    "         bigramsplit = k.split(\"_\")\n",
    "         hist = bigramsplit[0]\n",
    "         if hist==j:\n",
    "-            numer = bigramfreqs[k]\n",
    "-            denom = bigramhcs[j]\n",
    "+            numer = bigramfreqs[k]+1\n",
    "+            denom = bigramhcs[j]+bigramnum\n",
    "             frac = numer/denom\n",
    "             y = math.log(frac,2)\n",
    "             z = numer*y\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The entropy of the bigram model for this file is: 18.98 bits.\n"
     ]
    }
   ],
   "source": [
    "./bigram_lm.py /opt/data/lmdom/hpchapter1.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
