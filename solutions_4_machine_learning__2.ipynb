{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d6bd0cc-fce2-445a-b6c3-6b0bc9d7a395",
   "metadata": {},
   "source": [
    "# Data Analysis in Geoscience Remote Sensing Projects: Exercises \n",
    "## Solutions to tasks: Machine learning\n",
    "\n",
    "Hendrik Andersen | contact: hendrik.andersen@kit.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af971f8-9e07-4928-ad80-aec121fd3773",
   "metadata": {},
   "source": [
    "__Task 1: Data__ \n",
    "\n",
    "Use the following webpage (https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset) to find some information on the data contained in the California housing data set.\n",
    "\n",
    "... needs no explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d22df7d0-2aa0-42b4-9e6e-4edd54255677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>random</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>0.201248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>0.860836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>0.251222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>0.715379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>0.216618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude    random  \n",
       "0    -122.23  0.201248  \n",
       "1    -122.22  0.860836  \n",
       "2    -122.24  0.251222  \n",
       "3    -122.25  0.715379  \n",
       "4    -122.25  0.216618  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "cal_housing = fetch_california_housing()\n",
    "X = cal_housing.data#[:n_data_points]\n",
    "y = cal_housing.target#[:n_data_points]\n",
    "X = np.append(X,np.random.rand(y.size,1),axis=1) # add a random variable to the data\n",
    "cal_housing.feature_names.append('random') # add \"random\" as variable name\n",
    "X_df = pd.DataFrame(X, columns=cal_housing.feature_names)\n",
    "X_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7393d17c-5102-4597-a902-4105e86b5d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    }
   ],
   "source": [
    "n_iter = 100 \n",
    "random_params = {'learning_rate': np.random.uniform(0,1,size = n_iter),\n",
    "        'max_depth': np.random.randint(3, 10, n_iter),\n",
    "        'n_estimators': np.random.randint(100, 500, n_iter),\n",
    "        'subsample':np.random.uniform(0,1,size = n_iter),\n",
    "        'min_samples_split': np.random.randint(3, 30, n_iter)\n",
    "         }\n",
    "\n",
    "gbrt_model = GradientBoostingRegressor()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "\n",
    "searchcv = RandomizedSearchCV(gbrt_model, random_params, n_iter = n_iter, n_jobs = -1, verbose = 1, cv = 5)\n",
    "searchcv.fit(X_train, y_train) \n",
    "best_gbrt_model = searchcv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76afb11b-ae73-4175-9229-d8765a5b05a3",
   "metadata": {},
   "source": [
    "__Task 2: Separating training and test data__ \n",
    "\n",
    "Use the help page of \"train_test_split\" to see how a) reproducability in results can be achieved, and b) data sets can be split in different ways\n",
    "\n",
    "> a) The argument \"random_state\" can be used to split the data \"pseudo randomly\", so if the same integer is provided (e.g.random_state=1), always the same data will be selected for training and testing data.\n",
    "\n",
    "> b) The argument \"shuffle\" controls if data is shuffled (shuffle = True) or not. \n",
    "\n",
    "__Task 3.1: Fitting a model__\n",
    "\n",
    "Check the sklearn website of the GBRT model https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html to find out about\n",
    "\n",
    "1. the different hyperparameters ('parameters') of the GBRT model and their default values (especially those that are tuned below)\n",
    "2. the different methods of the GBRT model\n",
    "3. the different attributes of the GBRT model\n",
    "\n",
    "... needs no explanation\n",
    "\n",
    "__Task 3.2: Fitting a model__\n",
    "\n",
    "1. Check out the sklearn website of RandomizedSearchCV and GridSearchCV to find out more about their parameters, attributes and methods.\n",
    "2. Obviously, the hyperparameters n_estimators or max_depth are not driving the variability in the cross-validation score of the models observed. Which hyperparameters are driving the observed variability in cross-validation score? Can we use this information to fine-tune the range from which random data are drawn during hyperparameter tuning? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed079bf5-d956-4e11-8f12-36cdaa5ed401",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = searchcv.cv_results_[\"mean_test_score\"]\n",
    "subsample = searchcv.cv_results_[\"param_subsample\"]\n",
    "learning_rate = searchcv.cv_results_[\"param_learning_rate\"]\n",
    "\n",
    "# you can also visualize how two hyperparameter settings are related to the score at the same time\n",
    "plt.scatter(subsample, learning_rate, c=scores, vmin=0.1, vmax=0.9)\n",
    "plt.xlabel('subsample'); plt.ylabel('learning_rate')\n",
    "plt.colorbar(label='Mean test score in cross validation')\n",
    "plt.show()\n",
    "\n",
    "print('The hyperparameters subsample and learning rate seem to be driving the variability in model skill, with low subsample and high learning rate leading to poor model performance.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e125a231-a186-412c-8171-44b10de44816",
   "metadata": {},
   "source": [
    "__Task 4__\n",
    "\n",
    "1. Evaluate the linear regression model in the same manner as the tuned GBRT model is analyzed above. \n",
    "2. Compare the linear regression model with the tuned GBRT model - which one is better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de880c16-648e-4127-838a-438c716581e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linear_model = LinearRegression() \n",
    "linear_model.fit(X_train, y_train)\n",
    "\n",
    "print('Linear model coefficient of determination with the built-in method \"score\": %.2f' % linear_model.score(X_test,y_test))\n",
    "\n",
    "plt.scatter(y_test, linear_model.predict(X_test))\n",
    "plt.xlabel(\"Observed\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.plot(y_test, y_test, color = 'k')\n",
    "plt.show()\n",
    "\n",
    "print('The linear model explains 60% of the variability in housing prices, whereas the GBRTs explain 84% of the variability.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbda01ef-25bc-4595-b5a8-9c8d0d3204ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
