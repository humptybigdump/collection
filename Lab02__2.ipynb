{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e42763e",
   "metadata": {},
   "source": [
    "# Stochastic Simulation\n",
    "\n",
    "*Winter Semester 2023/24*\n",
    "\n",
    "10.11.2023\n",
    "\n",
    "Prof. Sebastian Krumscheid<br>\n",
    "Asstistant: Stjepan Salatovic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5187ec",
   "metadata": {},
   "source": [
    "<h3 align=\"center\">\n",
    "Exercise sheet 02\n",
    "</h3>\n",
    "\n",
    "---\n",
    "\n",
    "<h1 align=\"center\">\n",
    "Random Variable Generation\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f636d6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from ipywidgets import interact\n",
    "from scipy.integrate import quad\n",
    "from scipy.stats import linregress\n",
    "from scipy.stats import uniform, norm, expon, bernoulli, burr12\n",
    "from typing import Callable, Optional, Tuple\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271ef4b5-be03-4743-bb03-358bdb518a71",
   "metadata": {},
   "source": [
    "The following `cdf` function is the one you implemented in Lab 1 and you will need it later in this Lab, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "682763bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cdf(seq: np.array, x: np.array) -> np.array:\n",
    "    \"\"\"Computes the empirical CDF of `seq` and evaluates in `x`.\"\"\"\n",
    "    n = len(seq)\n",
    "    indices = np.searchsorted(np.sort(seq), x, side='right')\n",
    "    y = np.concatenate(([0], np.arange(1, n + 1) / n))\n",
    "    return y[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6ec4b1",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "Consider the random variable $X$ with cumulative distribution function\n",
    "(CDF) $F\\colon[-1,3]\\to [0,1]$ given by\n",
    "\n",
    "\\begin{equation*}\n",
    "  F(x) = \\begin{cases}\n",
    "    0\\;,& -1\\le x<0\\;,\\\\\n",
    "    1-\\frac{2}{3}e^{-x/2}\\;,& 0\\le x< 2\\;,\\\\\n",
    "    1\\;,& 2\\le x\\le 3\\;.\n",
    "  \\end{cases}\n",
    "\\end{equation*}\n",
    "\n",
    "Implement the inverse-transform method to generate $n$ independent\n",
    "copies of the random variable $X$. Assess the quality of the\n",
    "realizations by comparing the empirical CDF with the theoretical CDF\n",
    "$F$ for various values of $n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44e4c9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines the cdf F and pdf f\n",
    "\n",
    "F = lambda u: (u < 2) * (u >= 0) * (1 - 2 * np.exp(-u / 2.) / 3.) + (u >= 2) * (u <= 3)\n",
    "f = lambda u: (u >= 0) * (u <= 2) * np.exp(- u / 2.) / 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9548b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_transform(inv_cdf: Callable, n: int) -> np.array:\n",
    "    \"\"\"\n",
    "    Generates sequence of `n` random numbers using the inverse-transform method.\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ff2eb2",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "Consider the random variable $X$ with probability density function\n",
    "(PDF) $f$, which is only known up a multiplicative\n",
    "constant. Specifically, let $f(x) := k\\tilde{f}(x)$ with\n",
    "\n",
    "\\begin{equation*}\n",
    "  \\tilde{f}(x) := \\bigl(\\sin^2(6x)+3\\cos^2(x)\\sin^2(4x)+1\\bigr)e^{-x^2/2}\\;,\n",
    "\\end{equation*}\n",
    "\n",
    "where the normalization constant\n",
    "$k = \\left(\\int_\\mathbb{R}\\tilde{f}(x)\\,dx\\right)^{-1}$ is unknown."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2e34e6",
   "metadata": {},
   "source": [
    "1. Argue that $\\tilde{f}(x)$ can be bounded by $C\\phi(x)$, where\n",
    "  $C$ is an appropriately chosen constant and $\\phi$ denotes the PDF\n",
    "  of the standard normal distribution, that is\n",
    "  $\\phi(x) = e^{-x^2/2}/\\sqrt{2\\pi}$. Find an acceptable value for\n",
    "  $C$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbb7cbc",
   "metadata": {},
   "source": [
    "2. Generate $n=10^4$ random variables according to the PDF $f$ using the Acceptance-Rejection Method. \n",
    "\n",
    "    **Hint:** Use `scipy.stats.norm.rvs()` to sample normally distributed random variables in **Python**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86e3040c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acceptance_rejection(n: int) -> Tuple[np.array, float]:\n",
    "    \"\"\"\n",
    "    Generates sequence of `n` random numbers using the Acceptance-Rejection method.\n",
    "    Returns the sequence as well as the acceptance rate.\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25abf80",
   "metadata": {},
   "source": [
    "3. Derive an estimate of the normalization constant $k$, using your procedure's acceptance probability. Compare it to the exact value $k=0.1696542774$. Furthermore, compare the empirical CDF to the theorized, normalized CDF $F(x) = \\int_{-\\infty}^xf(u)\\, du$.\n",
    "\n",
    "   **Hint:** Here, you should take advantage of the fact that your AR method also returns the acceptance rate in addition to the actual samples. The theorized PDF and CDF is given down below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60990dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PDF(x: float) -> float:\n",
    "    e = lambda x: np.exp(x)\n",
    "    f= (np.sin(6*x)**2+3*np.cos(x)**2*np.sin(4*x)**2+1)*np.exp(-x**2/2)\n",
    "    mass=(-4-3*e(22)-6*e(40)-3*e(54)+6*e(70)+18*e(72))*np.sqrt(np.pi*0.5)/(4*e(72))\n",
    "    return f/mass;\n",
    "\n",
    "def CDF(x: float) -> float:\n",
    "    f=quad(PDF, -10, x)[0]\n",
    "    return f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2159f90b",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "An element $(x,y) \\in \\mathbb{R}^2$ may be represented by its polar coordinates $(\\rho,\\Theta) \\in [0,\\infty) \\times [0,2\\pi)$ defined by\n",
    "\n",
    "$$\n",
    "\\rho(x,y) = \\sqrt{x^2 + y^2},\n",
    "$$\n",
    "and\n",
    "$$\n",
    "  \\Theta(x,y) = \\begin{cases}\n",
    "    \\tan^{-1} \\left({\\frac{y}{x}}\\right) & \\text{if } x>0 \\text{ and } y \\ge 0,\\\\\n",
    "    \\tan^{-1} \\left({\\frac{y}{x}}\\right) +\\pi & \\text{if } x<0,\\\\\n",
    "    \\tan^{-1} \\left({\\frac{y}{x}}\\right) +2 \\pi & \\text{if } x>0 \\text{ and } y \\le 0,\\\\\n",
    "    0 & \\text{if } x=y=0,\n",
    "    \\end{cases}\n",
    "$$\n",
    "\n",
    "where $\\tan^{-1}:\\mathbb{R} \\to (-\\pi/2, \\pi/2)$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc25154e",
   "metadata": {},
   "source": [
    "1. Show by calculation that if the random variables $X,Y \\sim N(0,1)$ are independent, then the polar coordinate representation of $(X,Y)$ satisfies\n",
    "\n",
    "    $$\n",
    "    \\rho^2 \\sim \\exp(1/2) \\quad \\text{and} \\quad \\Theta \\sim U([0,2\\pi)).\n",
    "    $$\n",
    "\n",
    "    Show further that $\\rho$ and $\\Theta$ are independent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdad3a49",
   "metadata": {},
   "source": [
    "2. In the opposite direction, show that if $\\rho^2 \\sim \\exp(1/2)$ and $\\Theta \\sim U([0,2\\pi))$ and $\\rho$ and $\\Theta$ are independent, then the Cartesian representation of the polar coordinates $(\\rho, \\Theta)$,\n",
    "\n",
    "    $$\n",
    "    X = \\rho \\cos(2\\pi \\Theta) \\quad \\text{and} \\quad Y =\\rho \\sin(2 \\pi \\Theta),\n",
    "    $$\n",
    "\n",
    "    satisfies $X,Y \\sim N(0,1)$ with $X$ and $Y$ being independent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296e63a9",
   "metadata": {},
   "source": [
    "3. In order to construct an Acceptance-Rejection (AR) method for generating standard normal random variables consider the auxiliary PDF $g(x) = \\frac{1}{2} e^{-|x|}$. For your auxiliary PDF, determine a $C\\ge1$ such that\n",
    "  \n",
    "    $$\n",
    "    \\frac{e^{-x^2/2}}{\\sqrt{2\\pi}} \\le C g(x), \\qquad \\forall x \\in \\mathbb{R}.\n",
    "    $$\n",
    "\n",
    "    **Hint:** See lecture notes for how to sample from the PDF $g$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9ea270",
   "metadata": {},
   "source": [
    "4. Implement the above AR method and the Box-Muller method and use the built-in timer function `time()` within `time` module, to compare the performance of the respective methods in terms of runtime per sample.\n",
    "\n",
    "    **Hint:** To measure the time of your code, you can save start and end time and calculate the elapsed time using their difference:\n",
    "   ```python\n",
    "   start = time.time()\n",
    "   # some code\n",
    "   end = time.time()\n",
    "\n",
    "   elapsed_time = end - start\n",
    "   ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e53b9788",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acceptance_rejection_normal(n: int) -> Tuple[np.array, float]:\n",
    "    \"\"\"\n",
    "    Generates sequence of `n` standard normal random variables using the Acceptance-Rejection method.\n",
    "    Returns the sequence as well as the acceptance rate.\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10f3034e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_muller(n: int) -> np.array:\n",
    "    \"\"\"\n",
    "    Generates sequence of `n` standard normal random variables using the Box-Muller method.\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787a833d",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "\n",
    "The density of a random variable $X$ may be approximated by a mixed distribution generated by so called kernel density estimation. In its simplest form, kernel density estimation consists of the following steps:\n",
    "\n",
    "1. Choose a so called kernel function $K \\in \\{f: \\mathbb{R} \\to \\mathbb{R}_+ \\mid \\|f\\|_{L^1(\\mathbb{R})} =1 \\}$ (so the kernel is itself a PDF).\n",
    "2. For some $n \\in \\mathbb{N}$, generate a sequence of i.i.d. random variables $X_1,X_2,\\ldots,X_n$ from the distribution of $X$.\n",
    "3. Define the kernel density estimator by\n",
    "\n",
    "    $$\n",
    "    f(x)= \\frac{1}{n} \\sum_{i=1}^n K_\\delta(x-X_i),\n",
    "    $$\n",
    "\n",
    "    where\n",
    "\n",
    "    $$\n",
    "    K_\\delta(x-X_i) := \\frac{1}{\\delta} K\\left(\\frac{x-X_i}{\\delta}\\right), \\quad \\delta >0,\n",
    "    $$\n",
    "\n",
    "    and $\\delta$ is an appropriately chosen scaling parameter relating to the width of the kernel.\n",
    "   \n",
    "The Burr type XII distribution has the CDF\n",
    "\n",
    "$$\n",
    "F(x; \\alpha,c,k) =\n",
    "\\begin{cases}\n",
    "  0 & x \\le 0\\\\\n",
    "  1- \\left(1 + \\left(\\frac{x}{\\alpha}\\right)^c \\right)^{-k}, \\quad x \\in (0,\\infty),\n",
    "  & x>0,\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "with parameters $\\alpha,c,k>0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ead008c",
   "metadata": {},
   "source": [
    "1. Consider the Gaussian density kernel function\n",
    "    $$\n",
    "    K(x) = \\frac{1}{\\sqrt{2 \\pi}} e^{-x^2/2},\n",
    "    $$\n",
    "    and implement a kernel density estimator for\n",
    "\n",
    "    $$\n",
    "    X \\sim \\text{BurrXII}(\\alpha=1, c=2, k=4).\n",
    "    $$\n",
    "\n",
    "    **Hint:** Samples of $X$ can be obtained using [`scipy.stats.burr12`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.burr12.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7440d615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kde(data: np.array, kernel: Callable, delta: Optional[float]=None) -> Callable:\n",
    "    \"\"\"\n",
    "    Kernel density estimator for `data` using a `kernel` and optional `delta`.\n",
    "    Returns a Callable.\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ead513",
   "metadata": {},
   "source": [
    "2. For varying $n =[100,10^5]$ and $\\delta(n) =n^{-1/5}$ compute kernel density estimators\n",
    "    $$\n",
    "    f_{n}(x) = \\frac{1}{n} \\sum_{i=1}^n K_{\\delta(n)}(x-X_i),\n",
    "    $$\n",
    "    and plot $f_n$ and the PDF of BurrXII(1,2,4). Furthermore, for each value of $n$ sample $N=200.000$ i.i.d. random variables $Y^{n}_i \\sim f_n(x)$ by means of the composition method. \n",
    "\n",
    "    **Hint:** The `numpy.random.randint` built-in function might come handy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12a73d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226b269e",
   "metadata": {},
   "source": [
    "3. Study how well the empirical CDF of $Y_{1}^{n},Y_{2}^{n}, \\ldots,Y_{N}^{n}$, which we denote by $F_{n}^N(x)$, converges towards $F(x; 1,2,4)$. That is, investigate how fast\n",
    "\n",
    "    $$\n",
    "    D_n^N=\\sup_{x \\in [-2,5]} |F_{n}^N(x) - F(x;1,2,4)|\n",
    "    $$\n",
    "\n",
    "    decreases as $n$ increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f696bb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22414417",
   "metadata": {},
   "source": [
    "## Exercise 5\n",
    "\n",
    "The PDF for the Cauchy distribution centered at $x_0 \\in \\mathbb{R}$ and with scale parameter $\\gamma \\in \\mathbb{R}$ is given by\n",
    "\n",
    "$$\n",
    "f(x;x_0,\\gamma) = \\frac{1}{\\pi\\gamma\\left(1 + \\left(\\frac{x-x_0}{\\gamma}\\right)^2\\right)}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a45e72",
   "metadata": {},
   "source": [
    "1. Show by integration of the PDF that the CDF of the Cauchy distribution with $x_0=0$ and $\\gamma=1$ is given by\n",
    "\n",
    "    $$\n",
    "    F(x;0,1) = \\tan^{-1}(x)\\,/\\,\\pi +1/2,\n",
    "    $$\n",
    "\n",
    "    for $\\tan^{-1}:\\mathbb{R} \\to (-\\pi/2, \\pi/2)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942dabe9",
   "metadata": {},
   "source": [
    "2. Show that if $X_1,X_2 \\sim N(0,1)$ are independent, then $X = X_1/X_2$ is Cauchy distributed with $x_0=0$ and $\\gamma=1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0614a23f",
   "metadata": {},
   "source": [
    "3. Based on the information from exercise 5.1 and 5.2, describe and implement two algorithms for sampling $X \\sim F(\\cdot;0,1)$. Compare the performance of the respective algorithms in terms of runtime per sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfffa0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cauchy_by_inversion(n: int) -> np.array:\n",
    "    \"\"\"\n",
    "    Returns `n` Cauchy distributed random variables by the inversion-method.\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2244ff3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cauchy_by_gauss(n:int) -> np.array:\n",
    "    \"\"\"\n",
    "    Returns `n` Cauchy distributed random variables by the Gaussian ratio approach.\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58858ff2",
   "metadata": {},
   "source": [
    "4. It is possible to extend the preceding methods to sample from $X \\sim F(\\cdot; x_0,\\gamma)$ for any $x_0 \\in \\mathbb{R}$ and $\\gamma>0$. How? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54175883",
   "metadata": {},
   "source": [
    "## Exercise 6 (optional, no solution)\n",
    "\n",
    "Let $\\boldsymbol{X} = (X_1,X_2,\\dots,X_n)^T\\sim \\mathcal{U}\\bigl({(0,1)}^n\\bigr)$ and denote by $X_{(1)}\\le X_{(2)}\\le\\dots\\le X_{(n)}$ the ordered sample (i.e. the order statistic)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e078282",
   "metadata": {},
   "source": [
    "1. Implement a procedure to generate the order statistic $X_{(1)}\\le X_{(2)}\\le\\dots\\le X_{(n)}$, $n\\in\\mathbb{N}$, based on *sorting* a collection $\\boldsymbol{X}$ of i.i.d. uniform random variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0074e110",
   "metadata": {},
   "source": [
    "2. Prove the following properties:\n",
    "    1. Show that\n",
    "    $$\n",
    "    \\mathbb{P}\\bigl(X_{(j)}\\le  x\\bigr) = \\sum_{i=j}^n\\binom{n}{i}x^i{(1-x)}^{n-i}\\;,\n",
    "    $$\n",
    "        for any $x\\in (0,1)$. Furthermore, use this fact to infer the distribution of the random variable $\\max\\{X_1,X_2,\\dots,X_n\\}$.\n",
    "    2. Then show that\n",
    "    $$\n",
    "    \\mathbb{P}\\bigl(X_{(j)}\\le  z \\, \\bigl\\vert\\bigr. \\, X_{(k)}=x_k\\;,\\;\\forall\\,k>j\\bigr) = {\\left(\\frac{z}{x_{j+1}}\\right)}^{j}\\;\n",
    "    $$\n",
    "        for all $z\\le x_{j+1}$ and any $j<n$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5eda52",
   "metadata": {},
   "source": [
    "3. Use the facts above to implement a procedure that enables generating copies from the order statistic $X_{(1)}\\le X_{(2)}\\le\\dots\\le X_{(n)}$ *without sorting*. Compare this procedures and the procedure based on sorting with respect to time for various values of $n$. What do you observe?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb5ac51",
   "metadata": {},
   "source": [
    "4. Implement a procedure that generates uniform random vectors in the unit simplex\n",
    "$$\n",
    "\\mathcal{S} = \\Bigl\\{(x_1,x_2,\\dots,x_n)^T\\in\\mathbb{R}^n\\colon x_i\\ge 0\\;\\forall\\,i\\;,\\;\\sum_{i=1}^nx_i\\le 1\\Bigr\\}\\;.\n",
    "$$\n",
    "Assess your sampling procedure by visualizing $N=1000$ sampling points for $n=3$.\n",
    "\n",
    "**Hints:**\n",
    "- [3D scatter plots](https://matplotlib.org/stable/gallery/mplot3d/scatter3d.html) in Python.\n",
    "- Notice that a vector, whose coordinates are distributed according to the order statistic of a collection of i.i.d. $\\mathcal{U}(0,1)$, takes values in the \"wedge\"\n",
    "\n",
    "    $$\n",
    "    \\mathcal{W}=\\bigl\\{(u_1,u_2,\\dots,u_n)^T\\in\\mathbb{R}^n\\colon 0\\le u_i\\le 1\\;\\forall\\,i\\;,\\; u_1\\le u_2\\le\\dots \\le u_n\\}. \n",
    "    $$\n",
    "    \n",
    "    The unit simplex $\\mathcal{S}$ is then simply the image of the \"wedge\" $\\mathcal{W}$ under the linear transformation $\\boldsymbol{x} = A\\boldsymbol{u}$ where\n",
    "    \n",
    "    $$\n",
    "    A = \\begin{pmatrix}1 & 0 &\\dots & 0\\\\\n",
    "    \t\t-1 & 1 & \\dots & 0\\\\\n",
    "    \t\t\\vdots & \\ddots & \\ddots & \\vdots\\\\\n",
    "    \t\t0 & \\dots & -1 & 1\\end{pmatrix}\\;.\n",
    "    $$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
