{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practicals in Seismology, winter semester 2024/25 \n",
    "\n",
    "_____\n",
    "\n",
    "### Week 2, 30 Oct. 2024\n",
    "### Topics: Gutenberg-Richter and Omori analysis\n",
    "### Responsible: Dr. Yajian Gao\n",
    "\n",
    "-------\n",
    "\n",
    "**In this week's practicals you will learn**\n",
    "\n",
    "* how to plot data from your catalogs according to Gutenberg-Richter and Omori laws\n",
    "* how to fit lines and functions to data\n",
    "* how to determine relevant parameters in Gutenberg-Richter and Omori laws\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1: Computing a linear regression**\n",
    "\n",
    "Very often it is helpful to describe your dataset by a function. In the easiest case, this function is a straight line. In the ideal case, the data is found exactly on the line, but usually the data is scattered around the line. The line can be desccribed by the function y = mx + c, where x and y are data pairs, m gives the slope of the line and c is the intercept.\n",
    "\n",
    "Let’s create the data for this task now.\n",
    "\n",
    "Before we do so we will need to include the library numpy (as np). You know this command from last week's Seismic exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy here (as np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As next step we generate a dataset of N x-values. A simple way of doing that is that we choose a number (the mean of our dataset) around which the other data points are distributed. In order to describe the distribution around the mean, we simply need to give a standard deviation. In the np random function, the first value corresponds to the center of the Gaussian distribution, the 2nd value to the width of the distribution and the third value to the size of output samples. Here we use a mean value of 5.0 and standard deviation of 1.0, and we will create N=200 data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.normal(5.0,1.0,200) # (mean, std. deviation, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can plot the data you created (x-values), using the histogram plot function from matplotlib. \n",
    "\n",
    "You used matplotlib during the Seismic exercise, and certainly you remember that it needs to be imported first. Import it as plt. \n",
    "\n",
    "Then use plt.hist to plot your data. Use 50 bins. The command is <code>plt.hist(data,n)</code>, where data is your data (x in this case) and n is the number of bins. After you plotted the data, you can add labels to x- and y-axes, and a grid if you want. You can also add a title to the graphics. Call it 'Linear Regression Exercise - Figure 1'. Don't forget to use the <code>plt.show()</code> command in the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib here\n",
    "# plot histogram here\n",
    "# add x-label\n",
    "# add y-label\n",
    "# add grid\n",
    "# add title\n",
    "# show plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to complete the dataset we need y-values corresponding to those x-values. Because they should be linear related to the x-values, we simply use the linear equation y = mx + c to compute those. Define an intercept of c = 60 and a gradient of m = 3 first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define m here\n",
    "# define c here\n",
    "y = m * (x) + c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can plot your dataset which consists of x- and y-values. Use the command <code>plt.plot(x,y,'ko')</code>. Plot labels to your axes, add a grid (<code>plt.grid(True)</code>), a title ('Linear Regression Exercise - Figure 2'), and don't forget <code>plt.show()</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot data pairs here\n",
    "# add x-label\n",
    "# add y-label\n",
    "# add grid\n",
    "# add title\n",
    "# show plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, because we computed the y-values from the x-values using an equation for a straight line, those fit very nicely. We could also add a little bit of scatter to the y-values, to get more realisitic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = m * (x + np.random.normal(0,0.2,200)) + c # add a std. deviation to get a more realistic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the dataset again! You can use the same commands as above, but use 'Linear Regression Exercise - Figure 3' in the title instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot new data pairs here\n",
    "# add x-label\n",
    "# add y-label\n",
    "# add grid\n",
    "# add title\n",
    "# show plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As next step we will compute a linear regression to this data. Here, we will use a new library, which is called scipy. We will use the function stats from the scipy-library to compute the linear regression. It is applied to the dataset (x,y) and returns the slope and intercept of the straight line, and some additional values, which describe the quality of the fit. You don't have to make any changes to the cell below, but make sure that you understand it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x,y)\n",
    "\n",
    "print('Slope: ',slope)\n",
    "print('Intercept: ',intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to plot the line, we need to compute the y-values of the regression using slope and intercept, as well as our x-values. For this, we use the function predict_y_for(data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_y_for(x):\n",
    "    return slope * x + intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot dataset and regression together! Simply use the command <code>plt.plot</code> twice. The second plt.plot command is already inserted in the cell. Use 'Linear Regression Exercise - Figure 4' as title. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot data pairs here\n",
    "plt.plot(x, predict_y_for(x), c='r')\n",
    "# add x-label\n",
    "# add y-label\n",
    "# add grid\n",
    "# add title\n",
    "# show plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, you have all you need to do the Gutenberg-Richter analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2: Gutenberg – Richter analysis**\n",
    "\n",
    "We will plot the Gutenberg-Richter distribution of all European earthquakes larger than M4 in the next steps. Start with reading in your catalog, which is in the Files-folder and named Europe_mge4_1900_1999.txt. The data from the catalog will be copied into two arrays M (for magnitudes) and N (for number of occurence). You don't need to make any changes to the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'Files/Europe_mge4_1900_1999.txt'\n",
    "M = []\n",
    "N = []\n",
    "with open(filepath, 'r') as f:\n",
    "    MInfo = f.readlines()\n",
    "for Magn in [line.rstrip('\\n') for line in MInfo]:\n",
    "    info = Magn.split()\n",
    "    M.append(float(info[0]))\n",
    "    N.append(float(info[1]))\n",
    "N=np.asarray(N)  # change list to array\n",
    "M=np.asarray(M)  # -\"-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "Now plot the Gutenberg Richter distribution by executing the next cell withouth any changes.\n",
    "\n",
    "Once you have done that try to change the colour of the dots which represent the data changing the first letter in 'ko' in line 1. Accordingly try to change the shape of the symbol by changing the second letter. What happens if you use 'r--' or 'bs' or 'g^' instead of 'bd?\n",
    "\n",
    "Try out what happens if you change the axis limits of the x axis (change numbers in line 2 of the script). Add limits to the y axis and change those accordingly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(M, N, 'ko')\n",
    "plt.xlim((3,9))\n",
    "plt.title('Gutenberg-Richter Analysis - Figure 1')\n",
    "plt.xlabel('Magnitude M')\n",
    "plt.ylabel('Number N of earthquakes with magnitude greater or equal M')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to describe the dataset better, it is useful to fit a function. In task 1, we fitted a line to the dataset. However, in the above figure we can see that the dataset isn't resembled by a straight line. In fact, the Gutenberg-Richter distribution follows the equation\n",
    "\n",
    "log10(N)= a - bM\n",
    "\n",
    "A simple trick: We use a logarithmic N-axis to see the linear trend. \n",
    "\n",
    "Plot the data again, but include the command <code>plt.yscale('log')</code> before showing the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot data pairs here (M,N)\n",
    "# add limits to x-axis (3,9)\n",
    "# add title (use 'Gutenberg-Richter Analysis - Figure 2')\n",
    "# add x-label\n",
    "# add y-label\n",
    "# include here the command which gives you a log y-axis\n",
    "# add grid\n",
    "# show plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to display the linear relation would be to compute the logarithm of N first. You can do that executing the following cell. Here, a function from the numpy-library is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN=np.log10(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot your data again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot data pairs here (M,NN)\n",
    "# add limits to x-axis (3,9)\n",
    "# add title (use 'Gutenberg-Richter Analysis - Figure 3')\n",
    "# add x-label\n",
    "# add y-label\n",
    "# you mustn't include the command which gives you a log y-axis, because your values are already the log10(N)\n",
    "# add grid\n",
    "# show plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions to think about after you plotted the data:**\n",
    "\n",
    "* What can you say about the magnitude of completeness (lower limit) for your catalog?\n",
    "* And how about large magnitudes? Determine a cut-off magnitude (upper limit) for your catalog. Hint: add the **%matplotlib notebook** comment at the top of a plot to obtain an interactive plot. To go back to inline plots, use **%matplotlib inline**\n",
    "* When you were asked to fit a straight line in order to determine the b-value of the distribution, in which range would you fit it? The lower range should be the magnitude of completeness of your catalog, the upper limit should correspond to your estimated cut-off magnitude. Write down the two values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step we will compute this straight line using a regression. Do that as you did above in task 1, using M and NN for x and y. You don't need to make any changes to the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope, intercept, r_value, p_value, std_err = stats.linregress(M,NN)\n",
    "\n",
    "print('Slope: ',slope)\n",
    "print('Intercept: ',intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you explain why the slope is negative now?\n",
    "\n",
    "Now we will compute the values on the y-axis (NN) using predict_y_for(data), as we did in task 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_y_for(M):\n",
    "    return slope * M + intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally data and straight line can be plotted together. Youdon't need to make any changes to the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(M, NN, 'ko')\n",
    "plt.plot(M, predict_y_for(M), c='r')\n",
    "plt.xlim((3,9))\n",
    "plt.xlabel('Magnitude M')\n",
    "plt.ylabel('Logarithm of number N of earthquakes with magnitude greater or equal M')\n",
    "plt.title('Gutenberg-Richter Analysis - Figure 4')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you still have time, do the exercise (task 2) again, but using a catalog that contains all earthquakes larger or equal M = 2.5. It will be provided during the exercise (file name Files/Europe_mge2.5_1900_1999.txt). You can insert the catalogue's name in the first cell after the start of task 2. Execute all cells again. You will need to change the x-axis limits. What would be a good value to use as lower limit?\n",
    "\n",
    "If you don't have time to do this during the exercise, try it out some time during the week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "**Task 3: Omori analysis**\n",
    "\n",
    "The Omori law describes the number of aftershocks per time n(t): n (t) = k / (c + t). k and c are constants and vary between earthquake sequences. Aftershocks are recorded until the background level of seismicity is reached again after a large earthquake.  \n",
    "Before you start, think about the following questions:\n",
    "* How can you find out when the background level is reached again after an earthquake?\n",
    "* What are the spatial and temporal limits in which you would expect aftershocks?\n",
    "   \n",
    "We will start again with importing some packages that we haven't used so far. Please execute the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very similar to above, you will read in the catalog data now. Compare the following cell to the equivalent cell in task 2, and execute it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m     D\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mstr\u001b[39m(info[\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m      9\u001b[0m     X\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mint\u001b[39m(info[\u001b[38;5;241m1\u001b[39m]))\n\u001b[0;32m---> 10\u001b[0m X\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39masarray(X)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "filepath = 'Files/Tohoku_2011.txt' \n",
    "D = []\n",
    "X = []\n",
    "with open(filepath, 'r') as f:\n",
    "    DInfo = f.readlines()\n",
    "for day in [line.rstrip('\\n') for line in DInfo]:\n",
    "    info = day.split()\n",
    "    D.append(str(info[0]))\n",
    "    X.append(int(info[1]))\n",
    "X=np.asarray(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an Omori analysis, we use dates and times instead of simple numbers. Therefore, you will need to construct a date axis which will later be used for inversion and plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = []\n",
    "for day in D:\n",
    "    date.append(dt.datetime.strptime(day, \"%Y-%m-%d\"))\n",
    "\n",
    "eventdate = dt.datetime.strptime(\"2011-03-12\", \"%Y-%m-%d\")\n",
    "enddate = dt.datetime.strptime(\"2011-12-30\", \"%Y-%m-%d\")\n",
    "startii = [i for i in range (len(D)) if date[i]==eventdate][0]\n",
    "endii = [i for i in range (len(D)) if date[i]==enddate][0]\n",
    "date_omori = date[startii:endii]\n",
    "datenum = mdates.date2num(date_omori)-mdates.date2num(eventdate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might want to plot your data first. Execute the following cell (Note: The 2nd line increases the plot size to prevent the x-labels to overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = [10, 5]\n",
    "\n",
    "plt.bar(date,X)\n",
    "plt.title('Omori-analysis, Figure 1')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of events')\n",
    "plt.autoscale(enable=True, axis='both', tight=True)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step will be to fit a function to this data which describes the decay of number of events over time properly. This time, we will not simply be able to compute a linear regression, but we will need a more sophisticated function. Here we will define this function, similar as in task 2 above. The function will later be used for the curve-fitting. Let's call this function func."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(t, k, c):\n",
    "    return k/(c+t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, a curve-fitting fis performed to find the optimal parameters which you can then read from popt. Before we can use this function, we need to import it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popt, pcov = curve_fit(func, datenum, X[startii:endii])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell will plot the data together with the fitted curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(date,X)\n",
    "plt.plot(date_omori,func(datenum, *popt),'-r',linewidth=1.5)\n",
    "plt.title('Omori-analysis - Figure 2')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of events')\n",
    "plt.autoscale(enable=True, axis='both', tight=True)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use aftershock data until 29 February 2012 which is provided in the catalog Tohoku.txt. Start again from the top of task 3, but change the filname in cell 2 accordingly. Make sure that you also change enddate in the third cell of task 3  – set it to the last date in the list. Would you say that seismicity reached the background level at the end of February 2012? Discuss the effect of larger aftershocks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
