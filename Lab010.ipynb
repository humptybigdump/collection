{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e42763e",
   "metadata": {},
   "source": [
    "# Stochastic Simulation\n",
    "\n",
    "*Winter Semester 2024/25*\n",
    "\n",
    "24.01.2025\n",
    "\n",
    "Prof. Sebastian Krumscheid<br>\n",
    "Assistants: Stjepan Salatovic, Louise Kluge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5187ec",
   "metadata": {},
   "source": [
    "<h3 align=\"center\">\n",
    "Exercise sheet 10\n",
    "</h3>\n",
    "\n",
    "---\n",
    "\n",
    "<h1 align=\"center\">\n",
    "Markov Chains\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f636d6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from typing import Tuple\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.sparse import lil_matrix, diags\n",
    "from scipy.sparse.linalg import eigs\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a82b0a91-6d0f-436d-bc1e-bfc75cc60fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('axes', labelsize=14)     # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=12)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=12)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=14)    # legend fontsize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7afb1c-ba60-4eb0-894c-dc9a44c23c81",
   "metadata": {},
   "source": [
    "We recall some concepts on the theory of  Markov chains on a discrete state space $\\cal X$.\n",
    "\n",
    "**Irreducibility**\n",
    "\n",
    "Let $P$ be be a transition matrix on $\\cal X$. We say that a state $x_i\\in \\cal X$ communicates with a state $x_j\\in\\cal X$ if $\\mathbb{P}(X_n=x_j, \\text{ for some $n$ }| \\ X_0=x_i)>0$; equivalently, if $\\exists n\\geq 0$ such that $P^{(n)}_{i,j}>0$. A Markov chain is _irreducible_ if every state $x_j$ communicates with every other state $x_i$, i.e., $$ \\forall i,j,\\ \\ \\exists n\\geq 0 \\text{ such that } P^{(n)}_{i,j}>0.$$\n",
    "\n",
    "**Recurrence**\n",
    "\n",
    "A state $x_i\\in\\cal X$ is _recurrent_ if $\\mathbb{P}(X_n=x_i \\text{ infinitely often })=1$, that is, $x_i$ is visited infinitely-often with probability 1. A Markov chain $\\{X_n\\}$ is recurrent if every state is recurrent. It is known that every irreducible recurrent Markov chain $\\{X_n\\}$ on a discrete state space has a (not necessarily finite) invariant distribution  $\\pi$ that is unique up to a multiplicative constant. However, if the state space is _finite_, every irreducible Markov chain $\\{X_n\\}$ is recurrent and has a unique invariant probability distribution.\n",
    "\n",
    "**Aperiodicity**\n",
    "\n",
    "The _period_ of a state $x_i$ is the largest integer $d$ satisfying the following property: $P^{(n)}_{i,i}=0$, whenever $n$ is not divisible by $d$. The period of $x_i$ is given by $d(i)$. We say that if $d(i)>1$, then the state $x_i$ is _periodic_. We say that the state $x_i$ is _aperiodic_ otherwise. \n",
    "If a Markov chain $\\{X_n\\}$ is irreducible and has an aperiodic state, then all states are aperiodic, in which case we say that $\\{X_n\\}$ is aperiodic. In particular, an irreducible Markov chain $\\{X_n\\}$ is aperiodic if there exists a state $x_j\\in \\cal X$ such that $P_{jj}>0$. It is known that an irreducible  Markov chain $\\{X_n\\}$ on a _finite_ state space $\\cal X$ converges to $\\pi$, i.e., $\\pi_j=\\lim_{n\\to\\infty} \\mathbb{P}(X_n=x_j),$ $x_j\\in \\cal X$, if and only if $\\{X_n\\}$ is aperiodic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c4a7d3-b84d-41df-9acf-4567722da2dd",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "A random walk on the integers $I=\\{0,1,2\\dots\\}$ can be constructed in the following way. For $0<p<1/2$, let $Y_0,Y_1,\\dots$ be i.i.d random variables with $P(Y_i=1)=p$ and $P(Y_i=-1)=1-p$. Starting with $X_0 = Z_0 = 0$, define two random walks for $n \\geq 0$ as\n",
    "- $X_{n+1}=\\max \\{ X_n+Y_{n},0  \\}$ and\n",
    "- $Z_{n+1}=|Z_n+Y_n|$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be23f92d-6cab-4d7d-b6ff-0dd412e0283d",
   "metadata": {},
   "source": [
    "1. Show that $(X_n)$ and $(Z_n)$ are Markov chains."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a809ebe3-aee5-43b9-adaf-26aa27f01c83",
   "metadata": {},
   "source": [
    "2. Show that an invariant probability measure of the chains  $(X_n)$ and $(Z_n)$ is given by\n",
    "   \\begin{align*}\n",
    "\t&\\hat \\pi =\\left[1, \\left(\\frac{p}{1-p}\\right),\\dots, \\left(\\frac{p}{1-p}\\right)^k,\\dots \\right]a_0, \\nonumber \\ \\ k\\geq 0\\\\\n",
    "\t&\\bar \\pi = \\left[1,\\frac{1}{1-p},\\frac{p}{(1-p)^2},\\dots,\\frac{p^{k-1}}{(1-p)^k},\\dots\\right]b_0,\\quad k\\geq 1,\n",
    "\t\\end{align*}\n",
    "\trespectively. Find $p$, $a_0$, $b_0$ such that the expressions above are probability distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf5c92d-9bc9-4800-90f9-93691d69f4d2",
   "metadata": {},
   "source": [
    "3. Let $p=1/8$. Assess numerically  the convergence of both Markov chains to their \n",
    "\tinvariant distribution by simulating multiple  (independent)\n",
    "\tchains of length $n=100$, each starting in $0$ (i.e. $\\lambda = \\delta_0$). That is,\n",
    "\tplot the empirical distribution of $X_n,Z_n$ vs $\\hat \\pi$ and $\\bar \\pi$, respectively. Repeat your experiments for $m=n+1$. Explain your results.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c674d3c6-c649-44ed-8be9-bae9957ee6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chain_X(n: int, p: float) -> np.array:\n",
    "    \"\"\"\n",
    "    Generates the Markov chain (X_n).\n",
    "\n",
    "    Args:\n",
    "        n (int): The length of the sequence to generate.\n",
    "        p (float): The probability of choosing 1 for Y_n. The probability of choosing -1 is 1-p.\n",
    "\n",
    "    Returns:\n",
    "        np.array: The generated chain as a numpy array with length n.\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1efeb025-137b-4536-9d04-1360212b9d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chain_Z(n: int, p: float) -> np.array:\n",
    "    \"\"\"\n",
    "    Generates the Markov chain (Z_n).\n",
    "\n",
    "    Args:\n",
    "        n (int): The length of the sequence to generate.\n",
    "        p (float): The probability of choosing 1 for Y_n. The probability of choosing -1 is 1-p.\n",
    "\n",
    "    Returns:\n",
    "        np.array: The generated chain as a numpy array with length n.\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07a3d1bc-0a00-4e8a-b560-1136dde9a31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invariant_dist_X(K: int, p: float) -> np.array:\n",
    "    \"\"\"\n",
    "    Computes the invariant distribution for the Markov chain (X_n) characterized by a probability p.\n",
    "\n",
    "    Args:\n",
    "        K (int): Truncation of state space, the number of states to include in the result.\n",
    "        p (float): The probability parameter of the process.\n",
    "\n",
    "    Returns:\n",
    "        np.array: Invariant distribution over the first K states, a numpy array of length K.\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ff0f5e1-1b47-416e-bebe-a9d01eef2448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invariant_dist_Z(K: int, p: float) -> np.array:\n",
    "    \"\"\"\n",
    "    Computes the invariant distribution for the Markov chain (Z_n) characterized by a probability p.\n",
    "\n",
    "    Args:\n",
    "        K (int): Truncation of state space, the number of states to include in the result.\n",
    "        p (float): The probability parameter of the process.\n",
    "\n",
    "    Returns:\n",
    "        np.array: Invariant distribution over the first K states, a numpy array of length K.\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0db9287-c9b0-4891-9312-8a3fb91980a4",
   "metadata": {},
   "source": [
    "4. Discuss the periodicity of both chains. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a163792a-4b23-4abc-b18a-ec6d0f168765",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "Consider the random walk $\\{X_n\\in\\mathbb{Z}, n\\in\\mathbb{N}_0\\}$ with\n",
    "$X_0\\sim\\lambda$ on the lattice\n",
    "$\\mathcal{X}:= \\bigl\\{i\\colon i\\in\\mathbb{Z}, \\lvert i\\rvert \\le\n",
    "2N^2\\bigr\\}$, whose transition probabilities are given by\n",
    "\\begin{equation*}\n",
    "\\begin{aligned}\n",
    "\\mathbb{P}\\bigl(X_{n+1} = i\\pm 1\\bigl\\vert\\bigr. X_n = i\\bigr) &= \\alpha \\biggl(1\\mp \\frac{i}{2N^2}\\biggr)\\;,\\quad \\lvert i\\rvert \\le 2N^2\\;,\\\\\n",
    "\\mathbb{P}\\bigl(X_{n+1} = i\\bigl\\vert\\bigr. X_n = i\\bigr) &= 1-2\\alpha\\;,\n",
    "\\end{aligned}\n",
    "\\end{equation*}\n",
    "for some $\\alpha\\in (0,\\frac{1}{2}]$ and $N\\in\\mathbb{N}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c142f0c0-ad19-4288-8cc9-42d4f54a233e",
   "metadata": {},
   "source": [
    "1. Implement an algorithm that simulates the Markov Chain $\\{X_n\\in\\mathbb{Z}, n\\in\\mathbb{N}_0\\}$. Use your implementation to address the following points for different values of $N\\ge 1$:\n",
    "    1. Assess numerically that the Markov chain converges to an\n",
    "        invariant distribution by simulating multiple (independent)\n",
    "        chains, each starting in $0$ (i.e. $\\lambda = \\delta_0$). That is,\n",
    "        monitor the following quantities (rather, suitable Monte Carlo\n",
    "        approximations) as functions of the Markov chain length $n$. Speculate on the invariant distribution.\n",
    "\n",
    "        1. ${\\mathbb{E}_\\lambda\\bigl({X_n}^p\\bigr)}^{1/p}$ for $p\\in\\{1,2,4\\}$,\n",
    "        2. $M_{X_n}(t) := \\mathbb{E}_\\lambda\\bigl(e^{t X_n}\\bigr)$ for\n",
    "            $t\\in[-1,1]$.\n",
    "    2. For $N=10$, compute the eigenvalues and eigenvectors of the transition matrix $P$. Use the obtained results to deduce the invariant distribution $\\pi$.\n",
    "\n",
    "       **Hint:** Use NumPy's [`np.linalg.eig(P)`](https://numpy.org/doc/stable/reference/generated/numpy.linalg.eig.html).\n",
    "\n",
    "   3. Assess the validity of the ergodic theorem. That is, verify that $$\\lim_{n\\to\\infty}\\frac{1}{n}\\sum_{i=0}^n f(X_n) = \\mathbb{E}_\\pi(f)\\;,\\quad \\mathbb{P}_\\lambda\\,\\text{â€“a.s.,}\\,$$\n",
    "\t\tfor any $f: {\\cal X} \\to \\mathbb{R}$, with $\\sum_n |f(X_n)|\\pi_n < \\infty$. Specifically,\n",
    "\t\tinvestigate this identity for the moments used in Point\n",
    "\t\t1.A.a and monitor the rate of convergence as a function of $n$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef8e5244-7ad7-4c8f-8305-cf73fb17e77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lattice_random_walk(n: int, alpha: float, N: int) -> np.array:\n",
    "    \"\"\"\n",
    "    Simulates the random walk (X_n) on a 1D lattice.\n",
    "\n",
    "    Args:\n",
    "        n (int): The number of steps in the random walk.\n",
    "        alpha (float): The parameter controlling the transition probabilities in the random walk.\n",
    "        N (int): The parameter used to scale the lattice.\n",
    "\n",
    "    Returns:\n",
    "        np.array: Positions at each step of the random walk, a numpy array of length n.\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "052cd121-7c78-43bb-bbe3-03ca9b97f9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_transition_matrix(alpha: float, N: int) -> np.array:\n",
    "    \"\"\"\n",
    "    Builds the transition matrix for the random walk (X_n) on a 1D lattice.\n",
    "\n",
    "    Args:\n",
    "        alpha (float): The parameter controlling the transition probabilities in the random walk.\n",
    "        N (int): The parameter used to scale the lattice.\n",
    "\n",
    "    Returns:\n",
    "        np.array: Transition matrix, a numpy array of shape (4 * N ** 2 + 1) x (4 * N ** 2 + 1).\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a751bc-ffba-4b01-93a1-13681acf8a03",
   "metadata": {},
   "source": [
    "2. Consider the rescaled Markov chain $Y_n := \\frac{1}{N} X_n$ with\n",
    "state space\n",
    "$\\mathcal{Y}:= \\bigl\\{x_i\\equiv\\frac{i}{N}\\colon i\\in\\mathbb{Z},\n",
    "\\lvert i\\rvert \\le 2N^2\\bigr\\}$. Show by means of numerical\n",
    "simulations that the invariant distribution $\\nu\\equiv \\nu_N$ of\n",
    "$\\{Y_n\\in\\mathbb{Z}, n\\in\\mathbb{N}_0\\}$ is an accurate\n",
    "approximation to the standard normal measure. Moreover, illustrate\n",
    "that the approximation quality improves as $N$ increases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a240c3-291f-4ac3-b9cb-a394be5e8731",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "Given the transition matrix $$\n",
    "P=\\begin{pmatrix}\n",
    "0.0 & 0.4 & 0.6 & 0.0 & 0.0 \\\\\n",
    "0.65 & 0.0 & 0.35 & 0.0 & 0.0 \\\\\n",
    "0.32 & 0.68 & 0.0 & 0.0 & 0.0 \\\\\n",
    "0.0 & 0.0 & 0.0 & 0.12 & 0.88 \\\\\n",
    "0.0 & 0.0 & 0.0 & 0.56 & 0.44 \\\\\n",
    "\\end{pmatrix},\n",
    "$$\n",
    "and examine whether the corresponding chain is irreducible and aperiodic."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
