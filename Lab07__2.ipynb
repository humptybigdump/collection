{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e42763e",
   "metadata": {},
   "source": [
    "# Stochastic Simulation\n",
    "\n",
    "*Winter Semester 2023/24*\n",
    "\n",
    "22.12.2023\n",
    "\n",
    "Prof. Sebastian Krumscheid<br>\n",
    "Asstistant: Stjepan Salatovic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5187ec",
   "metadata": {},
   "source": [
    "<h3 align=\"center\">\n",
    "Exercise sheet 07\n",
    "</h3>\n",
    "\n",
    "---\n",
    "\n",
    "<h1 align=\"center\">\n",
    "Variance Reduction Techniques (cont.)\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f636d6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from typing import Tuple\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.stats import norm, multivariate_normal\n",
    "from scipy.integrate import nquad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a82b0a91-6d0f-436d-bc1e-bfc75cc60fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('axes', labelsize=14)     # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=12)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=12)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=14)    # legend fontsize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0d84ff-b2fb-4e5d-adb1-9fca7ff97936",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "Suppose we are given a control variate $Y$ with known mean $\\mathbb{E}(Y)$ and\n",
    "consider the usual modified random variable\n",
    "\\begin{equation*}\n",
    "  \\tilde{Z}_\\alpha = Z + \\alpha\\bigl(Y-\\mathbb{E}(Y)\\bigr)\\;,\n",
    "\\end{equation*}\n",
    "from which we aim at estimating $\\mu=\\mathbb{E}(Z)$. In fact, here we consider\n",
    "the following _one-shot algorithm_ for estimating $\\mu$:\n",
    "\n",
    "---\n",
    "\n",
    "**Algorithm 1** One-shot algorithm\n",
    "\n",
    "- Generate $N$ i.i.d. replicas $\\bigl(Z^{(i)},Y^{(i)}\\bigr)$, $i=1,\\dots, N$.\n",
    "- Estimate ${\\alpha}_{\\text{opt}}$ by $\\hat{\\alpha}_{\\text{opt}} := -\\hat{\\sigma}_{Z,Y}^2/\\hat{\\sigma}_{Y}^2$, using the usual unbiased mean, variance, and covariance estimators based on the sample ${\\bigl(Z^{(i)},Y^{(i)}\\bigr)}_{i=1,\\dots,N}$.\n",
    "- Compute the control variate estimator of $\\mu$ as $$\n",
    "    \\hat\\mu = \\frac{1}{N}\\sum_{i=1}^N \\Bigl(Z^{(i)} + \\hat{\\alpha}_{\\text{opt}}\\bigl(Y^{(i)} - \\mathbb{E}(Y)\\bigr)\\Bigr)\\;.$$\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696e9f95-fc46-401e-b226-2fec94255819",
   "metadata": {},
   "source": [
    "1. Show that the estimator $\\hat\\mu$ is asymptotically normally\n",
    "  distributed, in the sense that\n",
    "  \\begin{equation*}\n",
    "    \\sqrt{N}\\frac{ \\hat\\mu - \\mu}{\\sigma_{\\text{opt}}} \\underset{N\\to\\infty}{\\Rightarrow} \\mathcal{N}(0,1)\\;,\\quad\\text{where}\\quad \\sigma_{\\text{opt}} = \\sqrt{\\text{Var}(\\tilde{Z}_{\\alpha_\\text{opt}})}\\;.\n",
    "  \\end{equation*}\n",
    "  Furthermore, explain why the asymptotic normality also holds when\n",
    "  $\\sigma_{\\text{opt}}$ is replaced by the usual empirical standard\n",
    "  deviation based on a sample of realizations of\n",
    "  $\\tilde{Z}_{\\alpha_\\text{opt}}$.\n",
    "\n",
    "      **Hint:** Consider re-writing the estimator as the summation of the control variate estimator computed with the exact $\\alpha_{\\text{opt}}$ and a correction term involving $\\hat{\\alpha}_{\\text{opt}}-\\alpha_{\\text{opt}}$ as follows:\n",
    "      \\begin{align*}\n",
    "     \\hat\\mu &= \\frac{1}{N}\\sum_{i=1}^N \\Bigl(Z^{(i)} + \\alpha_{\\text{opt}}\\bigl(Y^{(i)} - \\mathbb{E}(Y)\\bigr)\\Bigr) + (\\hat{\\alpha}_{\\text{opt}}-\\alpha_{\\text{opt}})\\Bigl( \\frac{1}{N}\\sum_{i=1}^N Y^{(i)} -  \\mathbb{E}(Y) \\Bigr).\n",
    "    \\end{align*}  \n",
    "      Then, recall Slutsky's theorem, which states\n",
    "        that if $\\xi_n$ converges in distribution to $\\xi$ and $\\eta_n$\n",
    "        converges in probability to a constant $c$, then\n",
    "        $$f(\\xi_n,\\eta_n) \\underset{n\\to\\infty}{\\Rightarrow} f(\\xi,c)$$ for\n",
    "        any continuous function $f\\colon\\mathbb{R}\\times\\mathbb{R}\\to \\mathbb{R}$. Here, the\n",
    "        symbol $\\Rightarrow$ denotes convergence in distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a654f713-3798-408f-818f-377ecedcc831",
   "metadata": {},
   "source": [
    "2. Implement the one-shot algorithm described above. Apply it to\n",
    "  the examples considered in Lab 06, Exercise 1. That is, approximate\n",
    "  the probability $p = \\mathbb{P}(\\boldsymbol{X}\\in A)$ for the sets\n",
    "  $A=\\bigl\\{\\boldsymbol{x}=(x_1,x_2)\\in\\mathbb{R}^2\\colon x_i\\ge\n",
    "  a,\\,i=1,2\\bigr\\}$ with $a=1,3,10$. Here,\n",
    "  $\\boldsymbol{X}\\sim\\mathcal{N}(\\boldsymbol{0},\\Sigma)$ with\n",
    "  $\\Sigma=\\bigl(\\begin{smallmatrix} 4 & -1\\\\ -1 &\n",
    "    4 \\end{smallmatrix}\\bigr).$\n",
    "    1. First, explain why $Y = \\mathbb{I}_{\\{X_1+X_2\\ge 2a\\}}$ for\n",
    "    $\\boldsymbol{X} = (X_1,X_2)$ could be a decent control variate for\n",
    "    this problem.\n",
    "    2. Then perform simulations and investigate the variance\n",
    "    reduction effect for the control variate $Y$. Moreover, use the\n",
    "    result proved in point 1 to compute asymptotic $95\\%$ confidence\n",
    "    intervals.\n",
    "    3. Can you think of other appropriate control variates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83fa2f1c-0d14-4d8c-9275-bad8955abcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crude_Monte_Carlo(N: int, a: float, fix_seed: bool=False) -> float:\n",
    "    \"\"\"\n",
    "    Estimates the probability of both components of a random variable X being greater\n",
    "    than or equal to `a`, using a crude Monte Carlo simulation.\n",
    "    Returns estimates for mean as well as variance.\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf3b86c9-1169-461b-b83c-48429f004fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def importance_sampling(N: int, a: float, delta: float=1.0, fix_seed: bool=False) -> float:\n",
    "    \"\"\"\n",
    "    Estimates the probability of both components of a random variable X being greater\n",
    "    than or equal to `a`, using importance sampling with a Gaussian distribution.\n",
    "    Returns estimates for mean as well as variance.\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2245d764-a62c-46b9-80d2-f5e756dcd8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def control_variate(N: int, a: float, fix_seed: bool=False) -> float:\n",
    "    \"\"\"\n",
    "    Estimates the probability of both components of a random variable X being greater\n",
    "    than or equal to `a`, using a one-shot control variate algorithm.\n",
    "    Returns estimates for mean as well as variance.\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6ec4b1",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "Suppose that we wish to compute\n",
    "$\\mu =\n",
    "\\mathbb{E}\\bigl[\\Psi_\\tau(X_0,\\dots,X_\\tau)\\mathbb{I}_{\\{\\tau<\\infty\\}}\\bigr]$,\n",
    "where $\\tau$ is a stopping time adapted to the discrete time, discrete\n",
    "state Markov chain $\\{X_n\\in\\mathbb{Z}^d\\colon n\\in\\mathbb{N}_0\\}$ with\n",
    "initial probability distribution $p_0$ (i.e. $X_0\\sim p_0$) and with\n",
    "Markov transition probabilities $p_{i,j}\\in [0,1]$ such\n",
    "that\n",
    "\\begin{equation*}\n",
    "p_{i,j} = \\mathbb{P}(X_{n+1} = j \\vert X_n=i) \\quad \\forall\\,i,j\\in\\mathbb{Z}^d\\;.\n",
    "\\end{equation*}\n",
    "Instead of relying on the evolution of this Markov chain, it is\n",
    "natural to try to use importance measures that preserve the Markov\n",
    "property (so as to guarantee that the paths can be simulated\n",
    "efficiently under the importance measure). That is, one replaces the\n",
    "transition probabilities $p_{i,j}$ by other Markov transition\n",
    "probabilities $q_{i,j}\\in [0,1]$, which dominate $p_{i,j}$ (i.e.\n",
    "$q_{i,j} = 0 \\Rightarrow p_{i,j}=0$); analogously for the initial\n",
    "distribution. Moreover, we require that the stopping time $\\tau$ is\n",
    "almost surely finite for the Markov process with transition\n",
    "probabilities $q_{i,j}$, which appears natural from a practical point\n",
    "of view."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfbb859-1132-41de-ae53-2363411da15a",
   "metadata": {},
   "source": [
    "1. Prove that\n",
    "$\\mu =\n",
    "\\mathbb{E}\\bigl[\\Psi_\\tau(X_0,\\dots,X_\\tau)\\mathbb{I}_{\\tau<\\infty}\\bigr]$\n",
    "can be written as:\n",
    "\\begin{equation*}\n",
    "\\mu = \\mathbb{E}_q \\bigl[\\Psi_\\tau(X_0,\\dots,X_\\tau)w(X_0,\\dots,X_\\tau)\\bigr]\\;,\\quad\\text{with}\\quad\n",
    "w(X_0,\\dots,X_m) = \\frac{p_0(X_0)}{q_0(X_0)}\\prod_{j=1}^m \\frac{p_{X_{j-1},X_j}}{q_{X_{j-1},X_j}}\\;.\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e624c9-a333-4214-9744-5a51755ab237",
   "metadata": {},
   "source": [
    "2. Implement the importance sampling algorithm for discrete time\n",
    "Markov processes to the random walk\n",
    "$\\{X_n\\in\\mathbb{Z}\\colon X_0=0, n\\in\\mathbb{N}\\}$ with transition\n",
    "probabilities:\n",
    "\\begin{equation*}\n",
    "p_{i,i+1} \\equiv\\mathbb{P}(X_{n+1}=i+1\\vert X_{n}=i) = \\frac{1}{2} = \\mathbb{P}(X_{n+1}=i-1\\vert X_{n}=i) \\equiv  p_{i,i-1}\\;,\\quad n\\ge 0,\\,i\\in\\mathbb{Z}\\;.\n",
    "\\end{equation*}\n",
    "Consider the stopping time $\\tau_K := \\inf\\{n\\colon X_n = K\\}$ for a\n",
    "given constant $K=4$ and apply the algorithm to estimate\n",
    "$\\mathbb{P}\\bigl(\\tau_K<T\\bigr)$ with $T=10$. For the importance sampling, consider the random walk with\n",
    "transition probabilities\n",
    "\\begin{equation*}\n",
    "q_{i,i+1} \\equiv\\mathbb{P}(X_{n+1}=i+1\\vert X_{n}=i) = \\alpha > 1-\\alpha=\\mathbb{P}(X_{n+1}=i-1\\vert X_{n}=i) \\equiv  q_{i,i-1}\\;.\n",
    "\\end{equation*}\n",
    "Experiment with different\n",
    "values for $\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b06ecd77-9f4e-44a3-953a-6ce9f453db3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_prob(N: int, a: float, K: int, T: int, importance_sampling: bool=False, fix_seed: bool=False) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Estimates the probability of a random walk reaching `K` within a given\n",
    "    number of steps `T` based on `N` Monte Carlo samples.\n",
    "    Returns the mean as well as the variance of the estimator.\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
