{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: BLEU score\n",
    "The official BLEU evaluation script published by NIST is\n",
    "`mteval-v11a-cmufix_b.pl` Run the script with the argument `-h` and\n",
    "look at the \"help\" output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "export LANGUAGE=C.UTF-8\n",
    "export LC_ALL=C.UTF-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MT evaluation scorer began on 2022 Jun 2 at 09:20:44\n",
      "command line:  /usr/local/bin/mteval-v11a-cmufix_b.pl -h\n",
      "\n",
      "\n",
      "Usage: /usr/local/bin/mteval-v11a-cmufix_b.pl [-h] -r <ref_file> -s src_file -t <tst_file>\n",
      "\n",
      "Description:  This Perl script evaluates MT system performance.\n",
      "\n",
      "Required arguments:\n",
      "  -r <ref_file> is a file containing the reference translations for\n",
      "      the documents to be evaluated.\n",
      "  -s <src_file> is a file containing the source documents for which\n",
      "      translations are to be evaluated\n",
      "  -t <tst_file> is a file containing the translations to be evaluated\n",
      "\n",
      "Optional arguments:\n",
      "  -c preserves upper-case alphabetic characters\n",
      "  -b generate BLEU scores only\n",
      "  -n generate NIST scores only\n",
      "  -d detailed output flag used in conjunction with \"-b\" or \"-n\" flags:\n",
      "         0 (default) for system-level score only\n",
      "         1 to include document-level scores\n",
      "         2 to include segment-level scores\n",
      "         3 to include ngram-level scores\n",
      "  -m normalization method:\n",
      "\t      n (default) NIST MTeval script\n",
      "\t      b Bleu MTeval script\n",
      "\t      0 No text normalization\n",
      "  -e insert <s> and </s> around hyp and ref during eval\n",
      "  -z using shortest ref len to calculate length penalty for BLEU\n",
      "  -h prints this help message to STDOUT\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "255",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "mteval-v11a-cmufix_b.pl -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a)\n",
    "For each evaluation run (e.â€†g. for each test file) use the\n",
    "following arguments:  \n",
    "* i. Calculate BLEU and NIST score (`-b`, `-n`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MT evaluation scorer began on 2022 Jun 2 at 09:20:56\n",
      "command line:  /usr/local/bin/mteval-v11a-cmufix_b.pl -r /opt/data/wmt10-xlats/ref/wmt10-newssyscombtest2010-ref.en.sgm -s /opt/data/wmt10-xlats/ref/wmt10-newssyscombtest2010-src.de.sgm -t /opt/data/wmt10-xlats/newssyscombtest2010.de-en.kit.sgm -n\n",
      "NormalizationText method: None\n",
      "Use closest ref to calculate LP for BLEU\n",
      "  Evaluation of any-to-en translation using:\n",
      "    src set \"test2009\" (94 docs, 2034 segs)\n",
      "    ref set \"test2009\" (1 refs)\n",
      "    tst set \"test2009\" (1 systems)\n",
      "\n",
      "NIST LenPen=1.0000\n",
      "NIST score = 5.9367  for system kit\n",
      "\n",
      "# ------------------------------------------------------------------------\n",
      "\n",
      "Individual N-gram scoring\n",
      "        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram\n",
      "        ------   ------   ------   ------   ------   ------   ------   ------   ------\n",
      " NIST:  4.6886   1.0651   0.1679   0.0131   0.0020   0.0006   0.0001   0.0000   0.0000  \"kit\"\n",
      "\n",
      "\n",
      "# ------------------------------------------------------------------------\n",
      "Cumulative N-gram scoring\n",
      "        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram\n",
      "        ------   ------   ------   ------   ------   ------   ------   ------   ------\n",
      " NIST:  4.6886   5.7537   5.9216   5.9347   5.9367   5.9373   5.9373   5.9373   5.9373  \"kit\"\n",
      "\n",
      "MT evaluation scorer ended on 2022 Jun 2 at 09:20:59\n"
     ]
    }
   ],
   "source": [
    "mteval-v11a-cmufix_b.pl -r /opt/data/wmt10-xlats/ref/wmt10-newssyscombtest2010-ref.en.sgm -s /opt/data/wmt10-xlats/ref/wmt10-newssyscombtest2010-src.de.sgm -t /opt/data/wmt10-xlats/newssyscombtest2010.de-en.kit.sgm -n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MT evaluation scorer began on 2022 Jun 2 at 09:20:59\n",
      "command line:  /usr/local/bin/mteval-v11a-cmufix_b.pl -r /opt/data/wmt10-xlats/ref/wmt10-newssyscombtest2010-ref.en.sgm -s /opt/data/wmt10-xlats/ref/wmt10-newssyscombtest2010-src.de.sgm -t /opt/data/wmt10-xlats/newssyscombtest2010.de-en.kit.sgm -b\n",
      "NormalizationText method: None\n",
      "Use closest ref to calculate LP for BLEU\n",
      "  Evaluation of any-to-en translation using:\n",
      "    src set \"test2009\" (94 docs, 2034 segs)\n",
      "    ref set \"test2009\" (1 refs)\n",
      "    tst set \"test2009\" (1 systems)\n",
      "\n",
      "Bleu LenPen=1.0000\n",
      "\n",
      "BLEU score = 0.1822 for system kit\n",
      "\n",
      "# ------------------------------------------------------------------------\n",
      "\n",
      "Individual N-gram scoring\n",
      "        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram\n",
      "        ------   ------   ------   ------   ------   ------   ------   ------   ------\n",
      " BLEU:  0.4937   0.2412   0.1285   0.0721   0.0412   0.0242   0.0145   0.0087   0.0053  \"kit\"\n",
      "\n",
      "# ------------------------------------------------------------------------\n",
      "Cumulative N-gram scoring\n",
      "        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram\n",
      "        ------   ------   ------   ------   ------   ------   ------   ------   ------\n",
      "\n",
      " BLEU:  0.4937   0.3451   0.2483   0.1822   0.1354   0.1016   0.0769   0.0586   0.0449  \"kit\"\n",
      "MT evaluation scorer ended on 2022 Jun 2 at 09:21:02\n"
     ]
    }
   ],
   "source": [
    "mteval-v11a-cmufix_b.pl -r /opt/data/wmt10-xlats/ref/wmt10-newssyscombtest2010-ref.en.sgm -s /opt/data/wmt10-xlats/ref/wmt10-newssyscombtest2010-src.de.sgm -t /opt/data/wmt10-xlats/newssyscombtest2010.de-en.kit.sgm -b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ii.  Use the text normalization method \"BLEU\" (`-m b` option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MT evaluation scorer began on 2022 Jun 2 at 09:21:02\n",
      "command line:  /usr/local/bin/mteval-v11a-cmufix_b.pl -r /opt/data/wmt10-xlats/ref/wmt10-newssyscombtest2010-ref.en.sgm -s /opt/data/wmt10-xlats/ref/wmt10-newssyscombtest2010-src.de.sgm -t /opt/data/wmt10-xlats/newssyscombtest2010.de-en.kit.sgm -m b\n",
      "NormalizationText method: Bleu\n",
      "Use closest ref to calculate LP for BLEU\n",
      "  Evaluation of any-to-en translation using:\n",
      "    src set \"test2009\" (94 docs, 2034 segs)\n",
      "    ref set \"test2009\" (1 refs)\n",
      "    tst set \"test2009\" (1 systems)\n",
      "\n",
      "NIST LenPen=1.0000\n",
      "Bleu LenPen=1.0000\n",
      "NIST score = 6.8816 LP: 1.0000 BLEU score = 0.2397 Prec: 0.2397 LP: 1.0000 for system kit\n",
      "\n",
      "# ------------------------------------------------------------------------\n",
      "\n",
      "Individual N-gram scoring\n",
      "        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram\n",
      "        ------   ------   ------   ------   ------   ------   ------   ------   ------\n",
      " NIST:  5.2220   1.3805   0.2476   0.0265   0.0051   0.0009   0.0002   0.0001   0.0000  \"kit\"\n",
      "\n",
      " BLEU:  0.5897   0.3035   0.1756   0.1051   0.0646   0.0400   0.0255   0.0168   0.0109  \"kit\"\n",
      "\n",
      "# ------------------------------------------------------------------------\n",
      "Cumulative N-gram scoring\n",
      "        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram\n",
      "        ------   ------   ------   ------   ------   ------   ------   ------   ------\n",
      " NIST:  5.2220   6.6025   6.8501   6.8766   6.8816   6.8825   6.8827   6.8828   6.8828  \"kit\"\n",
      "\n",
      " BLEU:  0.5897   0.4230   0.3155   0.2397   0.1844   0.1429   0.1117   0.0881   0.0699  \"kit\"\n",
      "MT evaluation scorer ended on 2022 Jun 2 at 09:21:08\n"
     ]
    }
   ],
   "source": [
    "mteval-v11a-cmufix_b.pl -r /opt/data/wmt10-xlats/ref/wmt10-newssyscombtest2010-ref.en.sgm -s /opt/data/wmt10-xlats/ref/wmt10-newssyscombtest2010-src.de.sgm -t /opt/data/wmt10-xlats/newssyscombtest2010.de-en.kit.sgm -m b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* iii.  Calculate case-sensitive scores (`-c`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MT evaluation scorer began on 2022 Jun 2 at 09:21:08\n",
      "command line:  /usr/local/bin/mteval-v11a-cmufix_b.pl -r /opt/data/wmt10-xlats/ref/wmt10-newssyscombtest2010-ref.en.sgm -s /opt/data/wmt10-xlats/ref/wmt10-newssyscombtest2010-src.de.sgm -t /opt/data/wmt10-xlats/newssyscombtest2010.de-en.kit.sgm -m b -c\n",
      "NormalizationText method: Bleu\n",
      "Use closest ref to calculate LP for BLEU\n",
      "  Evaluation of any-to-en translation using:\n",
      "    src set \"test2009\" (94 docs, 2034 segs)\n",
      "    ref set \"test2009\" (1 refs)\n",
      "    tst set \"test2009\" (1 systems)\n",
      "\n",
      "NIST LenPen=1.0000\n",
      "Bleu LenPen=1.0000\n",
      "NIST score = 6.6975 LP: 1.0000 BLEU score = 0.2288 Prec: 0.2288 LP: 1.0000 for system kit\n",
      "\n",
      "# ------------------------------------------------------------------------\n",
      "\n",
      "Individual N-gram scoring\n",
      "        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram\n",
      "        ------   ------   ------   ------   ------   ------   ------   ------   ------\n",
      " NIST:  5.1633   1.2854   0.2218   0.0228   0.0042   0.0008   0.0001   0.0000   0.0000  \"kit\"\n",
      "\n",
      " BLEU:  0.5743   0.2908   0.1665   0.0985   0.0597   0.0364   0.0229   0.0149   0.0096  \"kit\"\n",
      "\n",
      "# ------------------------------------------------------------------------\n",
      "Cumulative N-gram scoring\n",
      "        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram\n",
      "        ------   ------   ------   ------   ------   ------   ------   ------   ------\n",
      " NIST:  5.1633   6.4487   6.6705   6.6933   6.6975   6.6983   6.6985   6.6985   6.6985  \"kit\"\n",
      "\n",
      " BLEU:  0.5743   0.4087   0.3029   0.2288   0.1749   0.1346   0.1045   0.0819   0.0645  \"kit\"\n",
      "MT evaluation scorer ended on 2022 Jun 2 at 09:21:13\n"
     ]
    }
   ],
   "source": [
    "mteval-v11a-cmufix_b.pl -r /opt/data/wmt10-xlats/ref/wmt10-newssyscombtest2010-ref.en.sgm -s /opt/data/wmt10-xlats/ref/wmt10-newssyscombtest2010-src.de.sgm -t /opt/data/wmt10-xlats/newssyscombtest2010.de-en.kit.sgm -m b -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   What is the BLEU and NIST score for the four systems?\n",
    "\n",
    "-   What is the Precision and Length Penalty of the BLEU scores?\n",
    "\n",
    "-   Does the automatic evaluation look like what you expected?\n",
    "\n",
    "-   How is the BLEU score calculated from the n-gram matches?\n",
    "  - Geometric means of the 1-gram to $n$-gram scores times the length penalty\n",
    "  \n",
    "-   What is the difference between the individual and the\n",
    "    cumulative score?\n",
    "  - The cumulative $n$-gram score for is effectively the $n$-gram BLEU score, e.g. the cumulative 4-gram score is the same as the standard BLEU score  \n",
    "    (it takes into account the $1..n$-gram scores)\n",
    "  - Individual $n$-gram scores take into account the $n$-grams for this one $n$ only\n",
    "\n",
    "|System |NIST   |BLEU   |Prec.  |LP    |\n",
    "|-------|-------|-------|-------|------|\n",
    "|DFKI   |4.8896 |0.1243 |0.1243 |1.0000|\n",
    "|JHU    |5.5791 |0.1542 |0.1659 |0.9790|\n",
    "|KIT    |5.9367 |0.1822 |0.1822 |1.0000|\n",
    "|RWTH   |5.9293 |0.1829 |0.1829 |1.0000|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b)\n",
    "Evaluate our system (KIT) with the case-sensitive option.\n",
    "\n",
    "-   Do you notice any difference in the score? Explain the\n",
    "    difference if any.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score = 0.2288 for system kit\n",
      "BLEU score = 0.2397 for system kit\n"
     ]
    }
   ],
   "source": [
    "mteval-v11a-cmufix_b.pl -r /opt/data/wmt10-xlats/ref/wmt10-newssyscombtest2010-ref.en.sgm -s /opt/data/wmt10-xlats/ref/wmt10-newssyscombtest2010-src.de.sgm -t /opt/data/wmt10-xlats/newssyscombtest2010.de-en.kit.sgm -b -m b -c | grep ^BLEU\n",
    "mteval-v11a-cmufix_b.pl -r /opt/data/wmt10-xlats/ref/wmt10-newssyscombtest2010-ref.en.sgm -s /opt/data/wmt10-xlats/ref/wmt10-newssyscombtest2010-src.de.sgm -t /opt/data/wmt10-xlats/newssyscombtest2010.de-en.kit.sgm -b -m b | grep ^BLEU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c)\n",
    "Evaluate our system (KIT) only for document-level BLEU score:\n",
    "\n",
    "```bash\n",
    "mteval-v11a-cmufix_b.pl \\\n",
    "    -r /opt/data/wmt10-xlats/ref/wmt10-newssyscombtest2010-ref.en.sgm \\\n",
    "    -s /opt/data/wmt10-xlats/ref/wmt10-newssyscombtest2010-src.de.sgm \\\n",
    "    -t ./newssyscombtest2010.de-en.kit.sgm \\\n",
    "    -b -m b -d 1\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MT evaluation scorer began on 2022 Jun 2 at 09:21:22\n",
      "command line:  /usr/local/bin/mteval-v11a-cmufix_b.pl -r /opt/data/wmt10-xlats/ref/wmt10-newssyscombtest2010-ref.en.sgm -s /opt/data/wmt10-xlats/ref/wmt10-newssyscombtest2010-src.de.sgm -t /opt/data/wmt10-xlats/newssyscombtest2010.de-en.kit.sgm -b -m b -d 1\n",
      "NormalizationText method: Bleu\n",
      "Use closest ref to calculate LP for BLEU\n",
      "  Evaluation of any-to-en translation using:\n",
      "    src set \"test2009\" (94 docs, 2034 segs)\n",
      "    ref set \"test2009\" (1 refs)\n",
      "    tst set \"test2009\" (1 systems)\n",
      "\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.1480 for system \"kit\" on document \"abces/2009/12/10/200783\" (13 segments, 473 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.1853 for system \"kit\" on document \"abces/2009/12/10/200784\" (16 segments, 611 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.2336 for system \"kit\" on document \"abces/2009/12/11/200957\" (9 segments, 259 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.1404 for system \"kit\" on document \"abces/2009/12/11/200981\" (9 segments, 284 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.2232 for system \"kit\" on document \"cincodias/2009/12/10/53245\" (20 segments, 737 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.1592 for system \"kit\" on document \"cincodias/2009/12/10/53246\" (12 segments, 394 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.2069 for system \"kit\" on document \"cincodias/2009/12/10/53247\" (7 segments, 160 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.2081 for system \"kit\" on document \"cincodias/2009/12/10/53248\" (32 segments, 907 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.2153 for system \"kit\" on document \"cincodias/2009/12/10/53249\" (5 segments, 112 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.1796 for system \"kit\" on document \"cincodias/2009/12/10/5325\" (4 segments, 118 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.1500 for system \"kit\" on document \"cincodias/2009/12/10/53251\" (9 segments, 238 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.2120 for system \"kit\" on document \"cincodias/2009/12/10/53252\" (28 segments, 613 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.2077 for system \"kit\" on document \"cincodias/2009/12/10/53253\" (17 segments, 411 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.1058 for system \"kit\" on document \"cincodias/2009/12/10/53255\" (5 segments, 175 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.2276 for system \"kit\" on document \"cincodias/2009/12/11/5334\" (76 segments, 1832 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.3099 for system \"kit\" on document \"economist/2009/12/10/17238\" (23 segments, 584 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.3986 for system \"kit\" on document \"economist/2009/12/10/17240\" (25 segments, 579 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.1374 for system \"kit\" on document \"elmundo/2009/12/10/10096\" (10 segments, 344 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.2248 for system \"kit\" on document \"elmundo/2009/12/10/10097\" (22 segments, 707 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.1942 for system \"kit\" on document \"elmundo/2009/12/10/10098\" (5 segments, 85 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.2349 for system \"kit\" on document \"elmundo/2009/12/10/10099\" (6 segments, 172 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.2230 for system \"kit\" on document \"elmundo/2009/12/10/10100\" (15 segments, 471 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.1213 for system \"kit\" on document \"elmundo/2009/12/10/10101\" (9 segments, 265 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.1831 for system \"kit\" on document \"elmundo/2009/12/10/10102\" (23 segments, 576 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.0000 for system \"kit\" on document \"elmundo/2009/12/11/10121\" (3 segments, 71 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.1273 for system \"kit\" on document \"elmundo/2009/12/11/10124\" (19 segments, 596 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.3398 for system \"kit\" on document \"elmundo/2009/12/11/10125\" (10 segments, 304 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.2016 for system \"kit\" on document \"elmundo/2009/12/11/10126\" (14 segments, 408 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.1136 for system \"kit\" on document \"elmundo/2009/12/11/10127\" (12 segments, 479 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.2071 for system \"kit\" on document \"elmundo/2009/12/11/10128\" (6 segments, 253 words)\n",
      "Bleu LenPen=0.9338\n",
      "BLEU score using   4-grams = 0.2836 for system \"kit\" on document \"frankfurter-rundschau/2009/12/10/9949\" (33 segments, 789 words)\n",
      "Bleu LenPen=0.9485\n",
      "BLEU score using   4-grams = 0.3232 for system \"kit\" on document \"frankfurter-rundschau/2009/12/10/99503\" (28 segments, 775 words)\n",
      "Bleu LenPen=0.9325\n",
      "BLEU score using   4-grams = 0.2111 for system \"kit\" on document \"frankfurter-rundschau/2009/12/10/99509\" (38 segments, 816 words)\n",
      "Bleu LenPen=0.9301\n",
      "BLEU score using   4-grams = 0.2440 for system \"kit\" on document \"frankfurter-rundschau/2009/12/10/99511\" (29 segments, 566 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.2166 for system \"kit\" on document \"frankfurter-rundschau/2009/12/10/99519\" (13 segments, 257 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.2999 for system \"kit\" on document \"frankfurter-rundschau/2009/12/10/9952\" (14 segments, 346 words)\n",
      "Bleu LenPen=0.9203\n",
      "BLEU score using   4-grams = 0.2590 for system \"kit\" on document \"frankfurter-rundschau/2009/12/10/99523\" (33 segments, 578 words)\n",
      "Bleu LenPen=0.9512\n",
      "BLEU score using   4-grams = 0.3147 for system \"kit\" on document \"frankfurter-rundschau/2009/12/10/99527\" (18 segments, 300 words)\n",
      "Bleu LenPen=0.9798\n",
      "BLEU score using   4-grams = 0.1311 for system \"kit\" on document \"idnes.cz/2009/12/11/76492\" (33 segments, 636 words)\n",
      "Bleu LenPen=0.9817\n",
      "BLEU score using   4-grams = 0.2622 for system \"kit\" on document \"lesechos/2009/12/10/218321\" (21 segments, 595 words)\n",
      "Bleu LenPen=0.9585\n",
      "BLEU score using   4-grams = 0.1954 for system \"kit\" on document \"lesechos/2009/12/10/218323\" (30 segments, 660 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.2363 for system \"kit\" on document \"lesechos/2009/12/10/218324\" (14 segments, 457 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.2262 for system \"kit\" on document \"lesechos/2009/12/10/218325\" (15 segments, 388 words)\n",
      "Bleu LenPen=0.9968\n",
      "BLEU score using   4-grams = 0.2201 for system \"kit\" on document \"lesechos/2009/12/10/218330\" (20 segments, 629 words)\n",
      "Bleu LenPen=0.9969\n",
      "BLEU score using   4-grams = 0.2524 for system \"kit\" on document \"lesechos/2009/12/10/218332\" (10 segments, 327 words)\n",
      "Bleu LenPen=0.9413\n",
      "BLEU score using   4-grams = 0.2536 for system \"kit\" on document \"lesechos/2009/12/10/218334\" (15 segments, 446 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.2153 for system \"kit\" on document \"lesechos/2009/12/10/218338\" (21 segments, 649 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.1887 for system \"kit\" on document \"lesechos/2009/12/11/218638\" (24 segments, 702 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.2018 for system \"kit\" on document \"lesechos/2009/12/11/218642\" (24 segments, 748 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.1868 for system \"kit\" on document \"lesechos/2009/12/11/218643\" (25 segments, 725 words)\n",
      "Bleu LenPen=0.9971\n",
      "BLEU score using   4-grams = 0.2837 for system \"kit\" on document \"lesechos/2009/12/11/218644\" (20 segments, 677 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.1901 for system \"kit\" on document \"lesechos/2009/12/11/218646\" (25 segments, 695 words)\n",
      "Bleu LenPen=0.9586\n",
      "BLEU score using   4-grams = 0.1661 for system \"kit\" on document \"lesechos/2009/12/11/218647\" (21 segments, 662 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.1945 for system \"kit\" on document \"lesechos/2009/12/11/218648\" (17 segments, 756 words)\n",
      "Bleu LenPen=0.9772\n",
      "BLEU score using   4-grams = 0.2292 for system \"kit\" on document \"lesechos/2009/12/11/218656\" (27 segments, 736 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.2977 for system \"kit\" on document \"lesechos/2009/12/11/218658\" (26 segments, 644 words)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.2795 for system \"kit\" on document \"lesechos/2009/12/11/218659\" (13 segments, 362 words)\n",
      "Bleu LenPen=0.9397\n",
      "BLEU score using   4-grams = 0.1778 for system \"kit\" on document \"lesechos/2009/12/12/218769\" (13 segments, 354 words)\n",
      "Bleu LenPen=0.9906\n",
      "BLEU score using   4-grams = 0.1601 for system \"kit\" on document \"lesechos/2009/12/12/218771\" (15 segments, 529 words)\n",
      "Bleu LenPen=0.9729\n",
      "BLEU score using   4-grams = 0.1319 for system \"kit\" on document \"lidovky.cz/2009/12/10/75424\" (23 segments, 510 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.1502 for system \"kit\" on document \"lidovky.cz/2009/12/10/75429\" (47 segments, 754 words)\n",
      "Bleu LenPen=0.9001\n",
      "BLEU score using   4-grams = 0.0903 for system \"kit\" on document \"lidovky.cz/2009/12/10/75456\" (12 segments, 285 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.2328 for system \"kit\" on document \"lidovky.cz/2009/12/10/75462\" (24 segments, 622 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.3311 for system \"kit\" on document \"lidovky.cz/2009/12/10/75469\" (14 segments, 275 words)\n",
      "Bleu LenPen=0.9133\n",
      "BLEU score using   4-grams = 0.1217 for system \"kit\" on document \"lidovky.cz/2009/12/10/75470\" (22 segments, 540 words)\n",
      "Bleu LenPen=0.9826\n",
      "BLEU score using   4-grams = 0.2006 for system \"kit\" on document \"lidovky.cz/2009/12/10/75474\" (33 segments, 799 words)\n",
      "Bleu LenPen=0.9213\n",
      "BLEU score using   4-grams = 0.2450 for system \"kit\" on document \"lidovky.cz/2009/12/10/75478\" (23 segments, 598 words)\n",
      "Bleu LenPen=0.9656\n",
      "BLEU score using   4-grams = 0.1295 for system \"kit\" on document \"lidovky.cz/2009/12/10/75482\" (25 segments, 514 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.2759 for system \"kit\" on document \"lidovky.cz/2009/12/10/75483\" (15 segments, 339 words)\n",
      "Bleu LenPen=0.9742\n",
      "BLEU score using   4-grams = 0.1717 for system \"kit\" on document \"lidovky.cz/2009/12/10/75485\" (20 segments, 383 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.2844 for system \"kit\" on document \"lidovky.cz/2009/12/10/75486\" (30 segments, 781 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.1986 for system \"kit\" on document \"lidovky.cz/2009/12/10/75487\" (21 segments, 552 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.2393 for system \"kit\" on document \"lidovky.cz/2009/12/10/75493\" (14 segments, 365 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.1971 for system \"kit\" on document \"lidovky.cz/2009/12/10/75501\" (13 segments, 283 words)\n",
      "Bleu LenPen=0.9648\n",
      "BLEU score using   4-grams = 0.1783 for system \"kit\" on document \"lidovky.cz/2009/12/10/75519\" (31 segments, 837 words)\n",
      "Bleu LenPen=0.9393\n",
      "BLEU score using   4-grams = 0.2575 for system \"kit\" on document \"spiegel/2009/12/12/73253\" (24 segments, 431 words)\n",
      "Bleu LenPen=0.9771\n",
      "BLEU score using   4-grams = 0.2680 for system \"kit\" on document \"spiegel/2009/12/12/73257\" (127 segments, 2543 words)\n",
      "Bleu LenPen=0.9545\n",
      "BLEU score using   4-grams = 0.3431 for system \"kit\" on document \"spiegel/2009/12/12/73266\" (21 segments, 494 words)\n",
      "Bleu LenPen=0.9627\n",
      "BLEU score using   4-grams = 0.2556 for system \"kit\" on document \"spiegel/2009/12/12/73268\" (29 segments, 552 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.2891 for system \"kit\" on document \"times-of-london/2009/12/11/100520\" (10 segments, 266 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.2080 for system \"kit\" on document \"times-of-london/2009/12/11/100521\" (28 segments, 809 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.2916 for system \"kit\" on document \"times-of-london/2009/12/11/100522\" (30 segments, 736 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.2578 for system \"kit\" on document \"washpost/2009/12/12/79400\" (29 segments, 1089 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.2886 for system \"kit\" on document \"washpost/2009/12/12/79407\" (51 segments, 1264 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.3419 for system \"kit\" on document \"washpost/2009/12/12/79408\" (20 segments, 761 words)\n",
      "Bleu LenPen=0.9947\n",
      "BLEU score using   4-grams = 0.3707 for system \"kit\" on document \"washpost/2009/12/12/79410\" (22 segments, 568 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.2525 for system \"kit\" on document \"washpost/2009/12/12/79411\" (17 segments, 519 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.3127 for system \"kit\" on document \"washpost/2009/12/12/79417\" (19 segments, 496 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.2678 for system \"kit\" on document \"washpost/2009/12/12/79419\" (21 segments, 619 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.3138 for system \"kit\" on document \"washpost/2009/12/12/79420\" (30 segments, 961 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.2989 for system \"kit\" on document \"washpost/2009/12/12/79421\" (19 segments, 554 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.2620 for system \"kit\" on document \"washpost/2009/12/12/79422\" (17 segments, 537 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.3446 for system \"kit\" on document \"washpost/2009/12/12/79423\" (26 segments, 669 words)\n",
      "Bleu LenPen=1.0000\n",
      "BLEU score using   4-grams = 0.2824 for system \"kit\" on document \"washpost/2009/12/12/79432\" (28 segments, 743 words)\n",
      "Bleu LenPen=1.0000\n",
      "\n",
      "BLEU score = 0.2397 for system kit\n",
      "\n",
      "# ------------------------------------------------------------------------\n",
      "\n",
      "Individual N-gram scoring\n",
      "        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram\n",
      "        ------   ------   ------   ------   ------   ------   ------   ------   ------\n",
      " BLEU:  0.5897   0.3035   0.1756   0.1051   0.0646   0.0400   0.0255   0.0168   0.0109  \"kit\"\n",
      "\n",
      "# ------------------------------------------------------------------------\n",
      "Cumulative N-gram scoring\n",
      "        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram\n",
      "        ------   ------   ------   ------   ------   ------   ------   ------   ------\n",
      "\n",
      " BLEU:  0.5897   0.4230   0.3155   0.2397   0.1844   0.1429   0.1117   0.0881   0.0699  \"kit\"\n",
      "MT evaluation scorer ended on 2022 Jun 2 at 09:21:26\n"
     ]
    }
   ],
   "source": [
    "mteval-v11a-cmufix_b.pl \\\n",
    "    -r /opt/data/wmt10-xlats/ref/wmt10-newssyscombtest2010-ref.en.sgm \\\n",
    "    -s /opt/data/wmt10-xlats/ref/wmt10-newssyscombtest2010-src.de.sgm \\\n",
    "    -t /opt/data/wmt10-xlats/newssyscombtest2010.de-en.kit.sgm \\\n",
    "    -b -m b -d 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Why does one of the documents have a zero score?\n",
    "  - Document `elmundo/2009/12/11/10121` only has 71 words in total\n",
    "  - Due to short document length there might not be a single matching 4-gram\n",
    "  - Product of $n$-gram scores becomes 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Bag Girl'\n",
      "Close to Karl Lagerfeld, the image of the Coco Cocoon line and occasional 'starlet' of the catwalk,the singer lavishes her bad-girl image with as much contempt as she has Chanel bags.\n",
      "More than a 'Bad Girl' or 'It Girl', she is a'Bag Girl'.\n",
      "\n",
      "Bag girl '\n",
      "The singer, a friend of Finland by Karl storage area, is the face of the cosmetics line Coco Cocoon and a Gelegenheitsstarlett during the Modenschauen ' maison ', they presented their rude face with the same such stubbornness as their pockets of Chanel.\n",
      "Much more than \"bad girl\" or \"it girl\", she is a \"Bag girl.\"\n"
     ]
    }
   ],
   "source": [
    "cat /opt/data/wmt10-xlats/ref/wmt10-newssyscombtest2010-ref.en.sgm |\n",
    "    grep -F -A8 'elmundo/2009/12/11/10121' |\n",
    "    perl -ne '/<seg id=\"\\d+\"> (.*)<\\/seg>/ && print $1, \"\\n\"'\n",
    "\n",
    "echo\n",
    "\n",
    "cat /opt/data/wmt10-xlats/newssyscombtest2010.de-en.kit.sgm |\n",
    "    grep -F -A8 'elmundo/2009/12/11/10121' |\n",
    "    perl -ne '/<seg id=\"\\d+\"> (.*)<\\/seg>/ && print $1, \"\\n\"'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the document with the highest and the lowest BLEU score\n",
    "(ignore the document with zero score) and read the translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score using   4-grams = 0.0000 for system \"kit\" on document \"elmundo/2009/12/11/10121\" (3 segments, 71 words)\n",
      "BLEU score using   4-grams = 0.0903 for system \"kit\" on document \"lidovky.cz/2009/12/10/75456\" (12 segments, 285 words)\n",
      "BLEU score using   4-grams = 0.1058 for system \"kit\" on document \"cincodias/2009/12/10/53255\" (5 segments, 175 words)\n",
      "BLEU score using   4-grams = 0.1136 for system \"kit\" on document \"elmundo/2009/12/11/10127\" (12 segments, 479 words)\n",
      "BLEU score using   4-grams = 0.1213 for system \"kit\" on document \"elmundo/2009/12/10/10101\" (9 segments, 265 words)\n",
      "BLEU score using   4-grams = 0.1217 for system \"kit\" on document \"lidovky.cz/2009/12/10/75470\" (22 segments, 540 words)\n",
      "BLEU score using   4-grams = 0.1273 for system \"kit\" on document \"elmundo/2009/12/11/10124\" (19 segments, 596 words)\n",
      "BLEU score using   4-grams = 0.1295 for system \"kit\" on document \"lidovky.cz/2009/12/10/75482\" (25 segments, 514 words)\n",
      "BLEU score using   4-grams = 0.1311 for system \"kit\" on document \"idnes.cz/2009/12/11/76492\" (33 segments, 636 words)\n",
      "BLEU score using   4-grams = 0.1319 for system \"kit\" on document \"lidovky.cz/2009/12/10/75424\" (23 segments, 510 words)\n",
      "BLEU score using   4-grams = 0.1374 for system \"kit\" on document \"elmundo/2009/12/10/10096\" (10 segments, 344 words)\n",
      "BLEU score using   4-grams = 0.1404 for system \"kit\" on document \"abces/2009/12/11/200981\" (9 segments, 284 words)\n",
      "BLEU score using   4-grams = 0.1480 for system \"kit\" on document \"abces/2009/12/10/200783\" (13 segments, 473 words)\n",
      "BLEU score using   4-grams = 0.1500 for system \"kit\" on document \"cincodias/2009/12/10/53251\" (9 segments, 238 words)\n",
      "BLEU score using   4-grams = 0.1502 for system \"kit\" on document \"lidovky.cz/2009/12/10/75429\" (47 segments, 754 words)\n",
      "BLEU score using   4-grams = 0.1592 for system \"kit\" on document \"cincodias/2009/12/10/53246\" (12 segments, 394 words)\n",
      "BLEU score using   4-grams = 0.1601 for system \"kit\" on document \"lesechos/2009/12/12/218771\" (15 segments, 529 words)\n",
      "BLEU score using   4-grams = 0.1661 for system \"kit\" on document \"lesechos/2009/12/11/218647\" (21 segments, 662 words)\n",
      "BLEU score using   4-grams = 0.1717 for system \"kit\" on document \"lidovky.cz/2009/12/10/75485\" (20 segments, 383 words)\n",
      "BLEU score using   4-grams = 0.1778 for system \"kit\" on document \"lesechos/2009/12/12/218769\" (13 segments, 354 words)\n",
      "BLEU score using   4-grams = 0.1783 for system \"kit\" on document \"lidovky.cz/2009/12/10/75519\" (31 segments, 837 words)\n",
      "BLEU score using   4-grams = 0.1796 for system \"kit\" on document \"cincodias/2009/12/10/5325\" (4 segments, 118 words)\n",
      "BLEU score using   4-grams = 0.1831 for system \"kit\" on document \"elmundo/2009/12/10/10102\" (23 segments, 576 words)\n",
      "BLEU score using   4-grams = 0.1853 for system \"kit\" on document \"abces/2009/12/10/200784\" (16 segments, 611 words)\n",
      "BLEU score using   4-grams = 0.1868 for system \"kit\" on document \"lesechos/2009/12/11/218643\" (25 segments, 725 words)\n",
      "BLEU score using   4-grams = 0.1887 for system \"kit\" on document \"lesechos/2009/12/11/218638\" (24 segments, 702 words)\n",
      "BLEU score using   4-grams = 0.1901 for system \"kit\" on document \"lesechos/2009/12/11/218646\" (25 segments, 695 words)\n",
      "BLEU score using   4-grams = 0.1942 for system \"kit\" on document \"elmundo/2009/12/10/10098\" (5 segments, 85 words)\n",
      "BLEU score using   4-grams = 0.1945 for system \"kit\" on document \"lesechos/2009/12/11/218648\" (17 segments, 756 words)\n",
      "BLEU score using   4-grams = 0.1954 for system \"kit\" on document \"lesechos/2009/12/10/218323\" (30 segments, 660 words)\n",
      "BLEU score using   4-grams = 0.1971 for system \"kit\" on document \"lidovky.cz/2009/12/10/75501\" (13 segments, 283 words)\n",
      "BLEU score using   4-grams = 0.1986 for system \"kit\" on document \"lidovky.cz/2009/12/10/75487\" (21 segments, 552 words)\n",
      "BLEU score using   4-grams = 0.2006 for system \"kit\" on document \"lidovky.cz/2009/12/10/75474\" (33 segments, 799 words)\n",
      "BLEU score using   4-grams = 0.2016 for system \"kit\" on document \"elmundo/2009/12/11/10126\" (14 segments, 408 words)\n",
      "BLEU score using   4-grams = 0.2018 for system \"kit\" on document \"lesechos/2009/12/11/218642\" (24 segments, 748 words)\n",
      "BLEU score using   4-grams = 0.2069 for system \"kit\" on document \"cincodias/2009/12/10/53247\" (7 segments, 160 words)\n",
      "BLEU score using   4-grams = 0.2071 for system \"kit\" on document \"elmundo/2009/12/11/10128\" (6 segments, 253 words)\n",
      "BLEU score using   4-grams = 0.2077 for system \"kit\" on document \"cincodias/2009/12/10/53253\" (17 segments, 411 words)\n",
      "BLEU score using   4-grams = 0.2080 for system \"kit\" on document \"times-of-london/2009/12/11/100521\" (28 segments, 809 words)\n",
      "BLEU score using   4-grams = 0.2081 for system \"kit\" on document \"cincodias/2009/12/10/53248\" (32 segments, 907 words)\n",
      "BLEU score using   4-grams = 0.2111 for system \"kit\" on document \"frankfurter-rundschau/2009/12/10/99509\" (38 segments, 816 words)\n",
      "BLEU score using   4-grams = 0.2120 for system \"kit\" on document \"cincodias/2009/12/10/53252\" (28 segments, 613 words)\n",
      "BLEU score using   4-grams = 0.2153 for system \"kit\" on document \"cincodias/2009/12/10/53249\" (5 segments, 112 words)\n",
      "BLEU score using   4-grams = 0.2153 for system \"kit\" on document \"lesechos/2009/12/10/218338\" (21 segments, 649 words)\n",
      "BLEU score using   4-grams = 0.2166 for system \"kit\" on document \"frankfurter-rundschau/2009/12/10/99519\" (13 segments, 257 words)\n",
      "BLEU score using   4-grams = 0.2201 for system \"kit\" on document \"lesechos/2009/12/10/218330\" (20 segments, 629 words)\n",
      "BLEU score using   4-grams = 0.2230 for system \"kit\" on document \"elmundo/2009/12/10/10100\" (15 segments, 471 words)\n",
      "BLEU score using   4-grams = 0.2232 for system \"kit\" on document \"cincodias/2009/12/10/53245\" (20 segments, 737 words)\n",
      "BLEU score using   4-grams = 0.2248 for system \"kit\" on document \"elmundo/2009/12/10/10097\" (22 segments, 707 words)\n",
      "BLEU score using   4-grams = 0.2262 for system \"kit\" on document \"lesechos/2009/12/10/218325\" (15 segments, 388 words)\n",
      "BLEU score using   4-grams = 0.2276 for system \"kit\" on document \"cincodias/2009/12/11/5334\" (76 segments, 1832 words)\n",
      "BLEU score using   4-grams = 0.2292 for system \"kit\" on document \"lesechos/2009/12/11/218656\" (27 segments, 736 words)\n",
      "BLEU score using   4-grams = 0.2328 for system \"kit\" on document \"lidovky.cz/2009/12/10/75462\" (24 segments, 622 words)\n",
      "BLEU score using   4-grams = 0.2336 for system \"kit\" on document \"abces/2009/12/11/200957\" (9 segments, 259 words)\n",
      "BLEU score using   4-grams = 0.2349 for system \"kit\" on document \"elmundo/2009/12/10/10099\" (6 segments, 172 words)\n",
      "BLEU score using   4-grams = 0.2363 for system \"kit\" on document \"lesechos/2009/12/10/218324\" (14 segments, 457 words)\n",
      "BLEU score using   4-grams = 0.2393 for system \"kit\" on document \"lidovky.cz/2009/12/10/75493\" (14 segments, 365 words)\n",
      "BLEU score using   4-grams = 0.2440 for system \"kit\" on document \"frankfurter-rundschau/2009/12/10/99511\" (29 segments, 566 words)\n",
      "BLEU score using   4-grams = 0.2450 for system \"kit\" on document \"lidovky.cz/2009/12/10/75478\" (23 segments, 598 words)\n",
      "BLEU score using   4-grams = 0.2524 for system \"kit\" on document \"lesechos/2009/12/10/218332\" (10 segments, 327 words)\n",
      "BLEU score using   4-grams = 0.2525 for system \"kit\" on document \"washpost/2009/12/12/79411\" (17 segments, 519 words)\n",
      "BLEU score using   4-grams = 0.2536 for system \"kit\" on document \"lesechos/2009/12/10/218334\" (15 segments, 446 words)\n",
      "BLEU score using   4-grams = 0.2556 for system \"kit\" on document \"spiegel/2009/12/12/73268\" (29 segments, 552 words)\n",
      "BLEU score using   4-grams = 0.2575 for system \"kit\" on document \"spiegel/2009/12/12/73253\" (24 segments, 431 words)\n",
      "BLEU score using   4-grams = 0.2578 for system \"kit\" on document \"washpost/2009/12/12/79400\" (29 segments, 1089 words)\n",
      "BLEU score using   4-grams = 0.2590 for system \"kit\" on document \"frankfurter-rundschau/2009/12/10/99523\" (33 segments, 578 words)\n",
      "BLEU score using   4-grams = 0.2620 for system \"kit\" on document \"washpost/2009/12/12/79422\" (17 segments, 537 words)\n",
      "BLEU score using   4-grams = 0.2622 for system \"kit\" on document \"lesechos/2009/12/10/218321\" (21 segments, 595 words)\n",
      "BLEU score using   4-grams = 0.2678 for system \"kit\" on document \"washpost/2009/12/12/79419\" (21 segments, 619 words)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score using   4-grams = 0.2680 for system \"kit\" on document \"spiegel/2009/12/12/73257\" (127 segments, 2543 words)\n",
      "BLEU score using   4-grams = 0.2759 for system \"kit\" on document \"lidovky.cz/2009/12/10/75483\" (15 segments, 339 words)\n",
      "BLEU score using   4-grams = 0.2795 for system \"kit\" on document \"lesechos/2009/12/11/218659\" (13 segments, 362 words)\n",
      "BLEU score using   4-grams = 0.2824 for system \"kit\" on document \"washpost/2009/12/12/79432\" (28 segments, 743 words)\n",
      "BLEU score using   4-grams = 0.2836 for system \"kit\" on document \"frankfurter-rundschau/2009/12/10/9949\" (33 segments, 789 words)\n",
      "BLEU score using   4-grams = 0.2837 for system \"kit\" on document \"lesechos/2009/12/11/218644\" (20 segments, 677 words)\n",
      "BLEU score using   4-grams = 0.2844 for system \"kit\" on document \"lidovky.cz/2009/12/10/75486\" (30 segments, 781 words)\n",
      "BLEU score using   4-grams = 0.2886 for system \"kit\" on document \"washpost/2009/12/12/79407\" (51 segments, 1264 words)\n",
      "BLEU score using   4-grams = 0.2891 for system \"kit\" on document \"times-of-london/2009/12/11/100520\" (10 segments, 266 words)\n",
      "BLEU score using   4-grams = 0.2916 for system \"kit\" on document \"times-of-london/2009/12/11/100522\" (30 segments, 736 words)\n",
      "BLEU score using   4-grams = 0.2977 for system \"kit\" on document \"lesechos/2009/12/11/218658\" (26 segments, 644 words)\n",
      "BLEU score using   4-grams = 0.2989 for system \"kit\" on document \"washpost/2009/12/12/79421\" (19 segments, 554 words)\n",
      "BLEU score using   4-grams = 0.2999 for system \"kit\" on document \"frankfurter-rundschau/2009/12/10/9952\" (14 segments, 346 words)\n",
      "BLEU score using   4-grams = 0.3099 for system \"kit\" on document \"economist/2009/12/10/17238\" (23 segments, 584 words)\n",
      "BLEU score using   4-grams = 0.3127 for system \"kit\" on document \"washpost/2009/12/12/79417\" (19 segments, 496 words)\n",
      "BLEU score using   4-grams = 0.3138 for system \"kit\" on document \"washpost/2009/12/12/79420\" (30 segments, 961 words)\n",
      "BLEU score using   4-grams = 0.3147 for system \"kit\" on document \"frankfurter-rundschau/2009/12/10/99527\" (18 segments, 300 words)\n",
      "BLEU score using   4-grams = 0.3232 for system \"kit\" on document \"frankfurter-rundschau/2009/12/10/99503\" (28 segments, 775 words)\n",
      "BLEU score using   4-grams = 0.3311 for system \"kit\" on document \"lidovky.cz/2009/12/10/75469\" (14 segments, 275 words)\n",
      "BLEU score using   4-grams = 0.3398 for system \"kit\" on document \"elmundo/2009/12/11/10125\" (10 segments, 304 words)\n",
      "BLEU score using   4-grams = 0.3419 for system \"kit\" on document \"washpost/2009/12/12/79408\" (20 segments, 761 words)\n",
      "BLEU score using   4-grams = 0.3431 for system \"kit\" on document \"spiegel/2009/12/12/73266\" (21 segments, 494 words)\n",
      "BLEU score using   4-grams = 0.3446 for system \"kit\" on document \"washpost/2009/12/12/79423\" (26 segments, 669 words)\n",
      "BLEU score using   4-grams = 0.3707 for system \"kit\" on document \"washpost/2009/12/12/79410\" (22 segments, 568 words)\n",
      "BLEU score using   4-grams = 0.3986 for system \"kit\" on document \"economist/2009/12/10/17240\" (25 segments, 579 words)\n"
     ]
    }
   ],
   "source": [
    "mteval-v11a-cmufix_b.pl \\\n",
    "    -r /opt/data/wmt10-xlats/ref/wmt10-newssyscombtest2010-ref.en.sgm \\\n",
    "    -s /opt/data/wmt10-xlats/ref/wmt10-newssyscombtest2010-src.de.sgm \\\n",
    "    -t /opt/data/wmt10-xlats/newssyscombtest2010.de-en.kit.sgm \\\n",
    "    -b -m b -d 1 |\n",
    "    grep \"^BLEU score using\" |\n",
    "    sort -k6 -n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Can we explain the difference in scores?\n",
    "  - Performance is very much dependent on the document type/domain\n",
    "-   Try to provide a speculation about the reasons for the\n",
    "    different quality of the translations.\n",
    "  - Documents with bad performance tend to be from non-German and non-English news\n",
    "  - Could result in greater number of out-of-vocabulary words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: TER Score\n",
    "TER stands for Translation Error Rate. The TER is the ratio of\n",
    "errors in the hypothesis to the number of words in the reference\n",
    "translation. The mistakes are composed of insertions, deletions,\n",
    "substitutions and shifts of words.\n",
    "\n",
    "## (a) \n",
    "Calculate the translation error rate for the first sentence of\n",
    "the translation of our system (KIT):\n",
    "\n",
    "-   How many editing actions do you need to restore the\n",
    "    reference from the hypothesis?\n",
    "\n",
    "| ref:  | lack of snow |   in   | mountains | causes problems |  for hoteliers   |\n",
    "|-------|--------------|--------|-----------|-----------------|------------------|\n",
    "| dist: | 0            |   2    |    0      |       2         |        3         |\n",
    "| hyp:  | lack of snow | on the | mountains |  has bedeviled  | the hotel owners |\n",
    "\n",
    "Execute the script to calculate the TER score for this\n",
    "translation\n",
    "\n",
    "```bash\n",
    "tercom_v6b.pl -h <hypothesis-file> -r <reference-file> -i sgm -N\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# the hypothesis directory needs to be writable so copy it to /tmp\n",
    "cp /opt/data/wmt10-xlats/newssyscombtest2010.de-en.kit.sgm /tmp\n",
    "tercom_v6b.pl -h /tmp/newssyscombtest2010.de-en.kit.sgm -r /opt/data/wmt10-xlats/ref/wmt10-newssyscombtest2010-ref.en.sgm -i sgm -N > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b)\n",
    "While the program is running, you can take a look at the file\n",
    "**newssyscombtest2010.de-en.kit.sgm.sys.pra** (it is being\n",
    "generated by the script).\n",
    "\n",
    "-   Did you calculate the TER of the first sentence correctly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence ID: idnes.cz/2009/12/11/76492-1\n",
      "Best Ref: lack of snow in mountains causes problems for hoteliers\n",
      "Orig Hyp: lack of snow on the mountains has bedeviled the hotel owners\n",
      "\n",
      "REF:  lack of snow ** IN  mountains *** CAUSES    PROBLEMS FOR   HOTELIERS\n",
      "HYP:  lack of snow ON THE mountains HAS BEDEVILED THE      HOTEL OWNERS   \n",
      "EVAL:              I  S             I   S         S        S     S        \n",
      "SHFT:                                                                     \n",
      "TER Score:  77.78 (  7.0/  9.0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "head -n 10 /tmp/newssyscombtest2010.de-en.kit.sgm.sys.pra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Is it possible for the error rate to exceed 100%? How can\n",
    "    this happen?\n",
    "  - Yes, it's possible.  \n",
    "    We divide by the reference length so a long hypothesis might result in a large number of deletions,\n",
    "    resulting in an error count higher than the reference length\n",
    "  - See part (c) below for an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence ID: idnes.cz/2009/12/11/76492-1\n",
      "Best Ref: lack of snow in mountains causes problems for hoteliers\n",
      "Orig Hyp: lack of snow on the mountains has bedeviled the hotel owners\n",
      "\n",
      "REF:  lack of snow ** IN  mountains *** CAUSES    PROBLEMS FOR   HOTELIERS\n",
      "HYP:  lack of snow ON THE mountains HAS BEDEVILED THE      HOTEL OWNERS   \n",
      "EVAL:              I  S             I   S         S        S     S        \n",
      "SHFT:                                                                     \n",
      "TER Score:  77.78 (  7.0/  9.0)\n",
      "\n",
      "\n",
      "Sentence ID: idnes.cz/2009/12/11/76492-2\n",
      "Best Ref: it's not only krkonoÅ¡e ski-lift operators who are worried by these bare slopes .\n",
      "Orig Hyp: make scneelose pisten sorgenn not only the giant mountains-local residents .\n",
      "\n",
      "REF:  IT'S   not only   KRKONOÅ¡E SKI-LIFT OPERATORS WHO       ARE    WORRIED   BY  THESE BARE            SLOPES    .\n",
      "HYP:  **** [ not only ] ********* ******** MAKE      SCNEELOSE PISTEN SORGENN @ THE GIANT MOUNTAINS-LOCAL RESIDENTS .\n",
      "EVAL: D                 D         D        S         S         S      S         S   S     S               S          \n",
      "SHFT:      1          1                                                       1                                      \n",
      "TER Score:  85.71 ( 12.0/ 14.0)\n",
      "\n",
      "Shift [not only] 4 words left\n",
      " REF:  IT'S   not only   KRKONOÅ¡E SKI-LIFT OPERATORS WHO       ARE    WORRIED   BY  THESE BARE            SLOPES    .\n",
      " HYP:  **** [ not only ] ********* ******** MAKE      SCNEELOSE PISTEN SORGENN @ THE GIANT MOUNTAINS-LOCAL RESIDENTS .\n",
      "\n",
      "\n",
      "Sentence ID: idnes.cz/2009/12/11/76492-3\n",
      "Best Ref: the lack of snow is putting people off booking ski holidays in hotels and guest houses .\n",
      "Orig Hyp: the lack of snow will deter people from appointment of skiaufenthalte in hotels and pensions .\n",
      "\n",
      "REF:  the lack of snow IS   PUTTING people OFF  BOOKING     SKI HOLIDAYS       in hotels and GUEST HOUSES   .\n",
      "HYP:  the lack of snow WILL DETER   people FROM APPOINTMENT OF  SKIAUFENTHALTE in hotels and ***** PENSIONS .\n",
      "EVAL:                  S    S              S    S           S   S                            D     S         \n",
      "SHFT:                                                                                                        \n",
      "TER Score:  47.06 (  8.0/ 17.0)\n",
      "\n",
      "\n",
      "Sentence ID: idnes.cz/2009/12/11/76492-4\n",
      "Best Ref: this means vacancies are still available in the krkonoÅ¡e throughout the winter , including christmas and new year's eve .\n",
      "Orig Hyp: therefore , one can get in giant still free rooms for all winter dates incl . christmas and new year's eve .\n",
      "\n",
      "REF:  *********   THIS MEANS VACANCIES   ARE   still **** AVAILABLE   in   THE KRKONOÅ¡E   THROUGHOUT THE    winter     ,   INCLUDING christmas and new year's eve .\n",
      "HYP:  THEREFORE @ ONE  CAN   GET       @ GIANT still FREE ROOMS     [ in ] FOR ALL       @ DATES      INCL [ winter ] [ , ] .         christmas and new year's eve .\n",
      "EVAL: I           S    S     S           S           I    S                S   S           S          S                     S                                       \n",
      "SHFT:           1                      2                            2    2               3                 3        3 1   1                                         \n",
      "TER Score:  75.00 ( 15.0/ 20.0)\n",
      "\n",
      "Shift [,] 13 words right\n",
      " REF:  *********   *** THIS MEANS VACANCIES ARE   still AVAILABLE IN    THE KRKONOÅ¡E THROUGHOUT THE   WINTER   ,   INCLUDING christmas and new year's eve .\n",
      " HYP:  THEREFORE @ ONE CAN  GET   IN        GIANT still FREE      ROOMS FOR ALL       WINTER     DATES INCL   [ , ] .         christmas and new year's eve .\n",
      "\n",
      "Shift [in] 4 words right\n",
      " REF:  ********* THIS MEANS VACANCIES   ARE   still **** AVAILABLE   in   THE KRKONOÅ¡E THROUGHOUT THE   WINTER , INCLUDING christmas and new year's eve .\n",
      " HYP:  THEREFORE ONE  CAN   GET       @ GIANT still FREE ROOMS     [ in ] FOR ALL       WINTER     DATES INCL   , .         christmas and new year's eve .\n",
      "\n",
      "Shift [winter] 2 words right\n",
      " REF:  ********* THIS MEANS VACANCIES ARE   still **** AVAILABLE in THE KRKONOÅ¡E   THROUGHOUT THE    winter   , INCLUDING christmas and new year's eve .\n",
      " HYP:  THEREFORE ONE  CAN   GET       GIANT still FREE ROOMS     in FOR ALL       @ DATES      INCL [ winter ] , .         christmas and new year's eve .\n",
      "\n",
      "\n",
      "Sentence ID: idnes.cz/2009/12/11/76492-5\n",
      "Best Ref: we're getting plenty of visitors to our site .\n",
      "Orig Hyp: our pages are often visited .\n",
      "\n",
      "REF:  WE'RE GETTING PLENTY   OF    VISITORS TO      our   SITE    .\n",
      "HYP:  ***** ******* ****** @ PAGES ARE      OFTEN [ our ] VISITED .\n",
      "EVAL: D     D       D        S     S        S             S        \n",
      "SHFT:                      1                      1     1          \n",
      "TER Score:  88.89 (  8.0/  9.0)\n",
      "\n",
      "Shift [our] 3 words right\n",
      " REF:  WE'RE GETTING PLENTY   OF    VISITORS TO      our   SITE    .\n",
      " HYP:  ***** ******* ****** @ PAGES ARE      OFTEN [ our ] VISITED .\n",
      "\n",
      "\n",
      "Sentence ID: idnes.cz/2009/12/11/76492-6\n",
      "Best Ref: people are browsing the offers , checking prices , but , so far , are worried about making a definite booking .\n",
      "Orig Hyp: people go to the offers by the prices , but now they are afraid to order mandatory .\n",
      "\n",
      "REF:  people ARE BROWSING the offers ,  CHECKING prices , but , SO FAR ,    are WORRIED ABOUT MAKING A  DEFINITE BOOKING   .\n",
      "HYP:  people GO  TO       the offers BY THE      prices , but * ** NOW THEY are ******* ***** AFRAID TO ORDER    MANDATORY .\n",
      "EVAL:        S   S                   S  S                     D D  S   S        D       D     S      S  S        S          \n",
      "SHFT:                                                                                                                       \n",
      "TER Score:  63.64 ( 14.0/ 22.0)\n",
      "\n",
      "\n",
      "Sentence ID: idnes.cz/2009/12/11/76492-7\n",
      "Best Ref: \" when they call , the first thing they ask is if we think they'll see snow or mud , \" says martin jandura , who runs the spindl . info information web site .\n",
      "Orig Hyp: and if they call us to ask them immediately , whether we believe that this year's christmas on snow or \" matsch \" will be led by the operators of the information spindl . info portal , martin jandura .\n",
      "\n",
      "REF:  ***   \"   WHEN they call ** ,    the     FIRST THING         THEY        ask   ******* IS   IF     we   THINK  THEY'LL   SEE snow or   MUD      ,   \" **** ** SAYS   martin jandura   ,    WHO       RUNS the   spindl . info   information   WEB    SITE   .\n",
      "HYP:  AND [ \" ] IF   they call US TO [ the ] @ THEM  IMMEDIATELY @ WHETHER @ [ ask ] BELIEVE THAT THIS [ we ] YEAR'S CHRISTMAS ON  snow or @ MATSCH [ , ] \" WILL BE LED  [ martin jandura ] BY @ OPERATORS OF   the @ spindl . info [ information ] PORTAL ,    @ .\n",
      "EVAL: I         S              I  S            S     S             S                 I       S    S           S      S         S             S              I    I  S                       S    S         S                                        S      S       \n",
      "SHFT:     6   6                      7     7 3                   4         5 3     3                   5    5                              6        4   4                1                1    7                    2               2             2             1  \n",
      "TER Score:  82.86 ( 29.0/ 35.0)\n",
      "\n",
      "Shift [martin jandura] 11 words left\n",
      " REF:  \"   WHEN they call ** ** ,   THE  FIRST       THING THEY    ASK IS      IF   WE   THINK  THEY'LL   SEE snow or MUD ,      \" **** ** SAYS   martin jandura   ** ,   WHO       RUNS the *********** spindl . info INFORMATION WEB    SITE   .\n",
      " HYP:  AND IF   they call US TO ASK THEM IMMEDIATELY ,     WHETHER WE  BELIEVE THAT THIS YEAR'S CHRISTMAS ON  snow or \"   MATSCH \" WILL BE LED  [ martin jandura ] BY THE OPERATORS OF   the INFORMATION spindl . info *********** PORTAL ,    @ .\n",
      "\n",
      "Shift [information] 3 words right\n",
      " REF:  \"   WHEN they call ** ** ,   THE  FIRST       THING THEY    ASK IS      IF   WE   THINK  THEY'LL   SEE snow or MUD ,      \" **** ** SAYS martin jandura ** ,   WHO       RUNS the   spindl . info   information   WEB    SITE .\n",
      " HYP:  AND IF   they call US TO ASK THEM IMMEDIATELY ,     WHETHER WE  BELIEVE THAT THIS YEAR'S CHRISTMAS ON  snow or \"   MATSCH \" WILL BE LED  martin jandura BY THE OPERATORS OF   the @ spindl . info [ information ] PORTAL ,    .\n",
      "\n",
      "Shift [ask] 5 words right\n",
      " REF:  \"   WHEN they call ** **   ,    THE         FIRST THING   THEY   ask   IS      IF   WE   THINK  THEY'LL   SEE snow or MUD ,      \" **** ** SAYS martin jandura ** ,   WHO       RUNS the spindl . info information WEB    SITE .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " HYP:  AND IF   they call US TO @ THEM IMMEDIATELY ,     WHETHER WE   [ ask ] BELIEVE THAT THIS YEAR'S CHRISTMAS ON  snow or \"   MATSCH \" WILL BE LED  martin jandura BY THE OPERATORS OF   the spindl . info information PORTAL ,    .\n",
      "\n",
      "Shift [,] 13 words right\n",
      " REF:  \"   WHEN they call ** ,  THE  FIRST         THING   THEY ask IS      IF   WE   THINK  THEY'LL   SEE snow or * MUD      ,   \" **** ** SAYS martin jandura ** ,   WHO       RUNS the spindl . info information WEB    SITE .\n",
      " HYP:  AND IF   they call US TO THEM IMMEDIATELY @ WHETHER WE   ask BELIEVE THAT THIS YEAR'S CHRISTMAS ON  snow or \" MATSCH [ , ] \" WILL BE LED  martin jandura BY THE OPERATORS OF   the spindl . info information PORTAL ,    .\n",
      "\n",
      "Shift [we] 4 words right\n",
      " REF:  \"   WHEN they call ,  THE FIRST THING       THEY      ask ******* IS   IF     we   THINK  THEY'LL   SEE snow or * MUD    , \" **** ** SAYS martin jandura ** ,   WHO       RUNS the spindl . info information WEB    SITE .\n",
      " HYP:  AND IF   they call US TO  THEM  IMMEDIATELY WHETHER @ ask BELIEVE THAT THIS [ we ] YEAR'S CHRISTMAS ON  snow or \" MATSCH , \" WILL BE LED  martin jandura BY THE OPERATORS OF   the spindl . info information PORTAL ,    .\n",
      "\n",
      "Shift [\"] 18 words left\n",
      " REF:  ***   \"   WHEN they call ,  THE FIRST THING       THEY    ask ******* IS   IF   we THINK  THEY'LL   SEE snow or   MUD    , \" **** ** SAYS martin jandura ** ,   WHO       RUNS the spindl . info information WEB    SITE .\n",
      " HYP:  AND [ \" ] IF   they call US TO  THEM  IMMEDIATELY WHETHER ask BELIEVE THAT THIS we YEAR'S CHRISTMAS ON  snow or @ MATSCH , \" WILL BE LED  martin jandura BY THE OPERATORS OF   the spindl . info information PORTAL ,    .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "head -n 120 /tmp/newssyscombtest2010.de-en.kit.sgm.sys.pra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c)\n",
    "Find the sentence ID \"idnes.cz/2009/12/11/76492-24\" in the file\n",
    "**newssyscombtest2010.de-en.kit.sgm.sys.pra**.\n",
    "\n",
    "The source sentence was:\n",
    "`Wir liegen etwa um fÃ¼nf Prozent besser als im Vorjahr.`\n",
    "\n",
    "-   What is the TER of the sentence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence ID: idnes.cz/2009/12/11/76492-24\n",
      "Best Ref: we're up about 5 percent .\n",
      "Orig Hyp: we are about five per cent better than in the previous year .\n",
      "\n",
      "REF:  WE'RE UP  about **** *** **** ****** **** ** *** 5        PERCENT .\n",
      "HYP:  WE    ARE about FIVE PER CENT BETTER THAN IN THE PREVIOUS YEAR    .\n",
      "EVAL: S     S         I    I   I    I      I    I  I   S        S        \n",
      "SHFT:                                                                    \n",
      "TER Score: 183.33 ( 11.0/  6.0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grep -F -A9 \"idnes.cz/2009/12/11/76492-24\" /tmp/newssyscombtest2010.de-en.kit.sgm.sys.pra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   What error rate would you have given (as a human being) if\n",
    "    you do not look at the reference but at the source sentence\n",
    "    for comparison?\n",
    "    \n",
    "-   How can you partly tackle this problem?\n",
    "  - Better Normalization of the sentences (e.g. `we're` -> `we &apos; re`) will result in less errors in this case\n",
    "  - More on that in the next exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (d)\n",
    "In the file newssyscombtest2010.de-en.kit.sgm.sys.sum\\_doc you\n",
    "will find the TER scores for all documents and for the entire\n",
    "test set.\n",
    "\n",
    "-   What is the TER score for the KIT system?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sent_Id  |  Ins   |  Del   |  Sub    |  Shft  |  WdSh  |  NumEr    |  NumWd      |  TER\n",
      "TOTAL    |  5261  |  3878  |  17010  |  4050  |  5285  |  30199.0  |  51023.000  |  59.187\n"
     ]
    }
   ],
   "source": [
    "#perl -ne 's/Sent Id/Send_Id/; print if ($. == 4 || $. == '\"$(wc -l < /tmp/newssyscombtest2010.de-en.kit.sgm.sys.sum_doc)\"')' < /tmp/newssyscombtest2010.de-en.kit.sgm.sys.sum_doc | column -t\n",
    "sed -ne '/Sent Id/ {s/Sent Id/Sent_Id/; p}; $p' < /tmp/newssyscombtest2010.de-en.kit.sgm.sys.sum_doc | column -t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   You can repeat the TER computation with the other 3 systems.\n",
    "  - No thanks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: TER Score - Character-based\n",
    "Look at the following files. The files contain the same sentences\n",
    "but in a different format.\n",
    "\n",
    "*References:*  \n",
    "`/opt/data/wmt16-ende/newstest2015-ende-ref.de.sgm`  \n",
    "`/opt/data/wmt16-ende/newstest2015-ende-ref.de`  \n",
    "\n",
    "*Hypotheses:*  \n",
    "`/opt/data/wmt16-ende/newstest2015-ende.kit.de.sgm`  \n",
    "`/opt/data/wmt16-ende/newstest2015-ende.kit.de`  \n",
    "\n",
    "Copy them into your directory.\n",
    "```bash\n",
    "cp /opt/data/wmt16-ende/newstest2015-ende-ref.de.sgm .\n",
    "cp /opt/data/wmt16-ende/newstest2015-ende-ref.de .\n",
    "cp /opt/data/wmt16-ende/newstest2015-ende.kit.de.sgm .\n",
    "cp /opt/data/wmt16-ende/newstest2015-ende.kit.de .\n",
    "```\n",
    "\n",
    "## (a)\n",
    "Calculate the translation quality with character-based TER using\n",
    "the following command:\n",
    "\n",
    "```bash\n",
    "CharacTER.py \\\n",
    "    -r newstest2015-ende-ref.de \\\n",
    "    -o newstest2015-ende.kit.de \\\n",
    "    -v > wmt15_kit_charTER.Log\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CharacTER of sentence 1 is 0.6889\n",
      "CharacTER of sentence 2 is 0.6516\n",
      "CharacTER of sentence 3 is 0.4266\n",
      "CharacTER of sentence 4 is 0.8615\n",
      "CharacTER of sentence 5 is 0.7176\n",
      "CharacTER of sentence 6 is 0.5632\n",
      "CharacTER of sentence 7 is 0.3012\n",
      "CharacTER of sentence 8 is 0.6558\n",
      "CharacTER of sentence 9 is 0.5960\n",
      "CharacTER of sentence 10 is 0.4958\n",
      "CharacTER of sentence 11 is 0.9327\n",
      "CharacTER of sentence 12 is 0.4464\n",
      "CharacTER of sentence 13 is 0.1642\n",
      "CharacTER of sentence 14 is 0.3913\n",
      "CharacTER of sentence 15 is 0.6026\n",
      "CharacTER of sentence 16 is 0.4270\n",
      "...\n",
      "0.5674459255624126\n",
      "Shift cost:\n",
      "0.08672359368481158\n"
     ]
    }
   ],
   "source": [
    "CharacTER.py \\\n",
    "    -r /opt/data/wmt16-ende/newstest2015-ende-ref.de \\\n",
    "    -o /opt/data/wmt16-ende/newstest2015-ende.kit.de \\\n",
    "    -v |\n",
    "    sed -n '1,16p; 17s/^.*$/.../; /^CharacTER/! p'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now look at the output file:\n",
    "\n",
    "-   What is the char-TER score of each sentence? Which sentence\n",
    "    is the best and which one is the worst?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CharacTER of sentence 1029 is 0.0000\n",
      "CharacTER of sentence 316 is 1.8000\n"
     ]
    }
   ],
   "source": [
    "CharacTER.py \\\n",
    "    -r /opt/data/wmt16-ende/newstest2015-ende-ref.de \\\n",
    "    -o /opt/data/wmt16-ende/newstest2015-ende.kit.de \\\n",
    "    -v |\n",
    "    grep \"^CharacTER\" |\n",
    "    sort -k6 -n |\n",
    "    sed -n '1p; $p'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best:\n",
      "Asbest ist schlieÃŸlich ein Produkt der Vergangenheit.\n",
      "Asbest ist schlieÃŸlich ein Produkt der Vergangenheit.\n",
      "\n",
      "Worst:\n",
      "Beweg dich!\n",
      "Move!\n"
     ]
    }
   ],
   "source": [
    "echo \"Best:\"\n",
    "sed -n -s '1029p' /opt/data/wmt16-ende/newstest2015-ende{-ref,.kit}.de\n",
    "echo\n",
    "echo \"Worst:\"\n",
    "sed -n -s '316p' /opt/data/wmt16-ende/newstest2015-ende{-ref,.kit}.de"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b)\n",
    "Calculate the translation quality with word-based TER using the\n",
    "following command:\n",
    "\n",
    "```bash\n",
    "tercom_v6b.pl \\\n",
    "    -r newstest2015-ende-ref.de.sgm \\\n",
    "    -h newstest2015-ende.kit.de.sgm -i sgm -N\n",
    "```\n",
    "\n",
    "Look at the following file\n",
    "`newstest2015-ende.kit.de.sgm.sys.pra` and\n",
    "`newstest2015-ende.kit.de.sgm.sys.sum_doc`.\n",
    "\n",
    "-   What is the word-TER score of each document? Which sentence\n",
    "    is the best and which one is the worst?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp /opt/data/wmt16-ende/newstest2015-ende.kit.de.sgm /tmp\n",
    "tercom_v6b.pl \\\n",
    "    -r /opt/data/wmt16-ende/newstest2015-ende-ref.de.sgm \\\n",
    "    -h /tmp/newstest2015-ende.kit.de.sgm -i sgm -N > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sent_Id                         |  Ins   |  Del   |  Sub    |  Shft  |  WdSh  |  NumEr    |  NumWd      |  TER\n",
      "1012-bbc                        |  10    |  7     |  34     |  7     |  15    |  58.0     |  95.000     |  61.053\n",
      "1035-news.com.au                |  7     |  23    |  55     |  6     |  7     |  91.0     |  179.000    |  50.838\n",
      "107-stv.tv                      |  1     |  12    |  44     |  8     |  20    |  65.0     |  133.000    |  48.872\n",
      "1141-thenation.com              |  33    |  80    |  280    |  50    |  58    |  443.0    |  816.000    |  54.289\n",
      "1149-reuters                    |  23    |  64    |  164    |  33    |  39    |  284.0    |  484.000    |  58.678\n",
      "1158-news.com.au                |  16    |  59    |  152    |  28    |  34    |  255.0    |  434.000    |  58.756\n",
      "1209-telegraph                  |  16    |  19    |  115    |  25    |  33    |  175.0    |  275.000    |  63.636\n",
      "12325-dw                        |  25    |  23    |  73     |  11    |  16    |  132.0    |  228.000    |  57.895\n",
      "1275-abcnews                    |  7     |  12    |  54     |  3     |  4     |  76.0     |  139.000    |  54.676\n",
      "1330-hellwegeranzeiger.de       |  47    |  2     |  60     |  6     |  9     |  115.0    |  139.000    |  82.734\n",
      "1381-thelocal                   |  28    |  39    |  112    |  28    |  33    |  207.0    |  345.000    |  60.000\n",
      "1383-news.com.au                |  20    |  25    |  118    |  21    |  31    |  184.0    |  256.000    |  71.875\n",
      "14399-tagesspiegel.de           |  91    |  9     |  227    |  34    |  37    |  361.0    |  467.000    |  77.302\n",
      "1440-abcnews                    |  34    |  77    |  197    |  41    |  51    |  349.0    |  690.000    |  50.580\n",
      "14428-abendzeitung-muenchen.de  |  62    |  6     |  64     |  17    |  26    |  149.0    |  178.000    |  83.708\n",
      "14539-mopo.de                   |  30    |  6     |  58     |  8     |  9     |  102.0    |  158.000    |  64.557\n",
      "1472-smh.com.au                 |  13    |  30    |  89     |  14    |  19    |  146.0    |  285.000    |  51.228\n",
      "15070-np-coburg.de              |  66    |  19    |  196    |  45    |  57    |  326.0    |  459.000    |  71.024\n",
      "15707-general-anzeiger-bonn.de  |  96    |  23    |  213    |  47    |  58    |  379.0    |  486.000    |  77.984\n",
      "15715-mz-web.de                 |  20    |  2     |  32     |  5     |  8     |  59.0     |  95.000     |  62.105\n",
      "159-wn.de                       |  57    |  12    |  145    |  17    |  20    |  231.0    |  362.000    |  63.812\n",
      "16011-wienerzeitung.at          |  80    |  12    |  123    |  22    |  30    |  237.0    |  270.000    |  87.778\n",
      "1620-telegraph                  |  122   |  122   |  519    |  100   |  119   |  863.0    |  1650.000   |  52.303\n",
      "16532-derstandart.at            |  14    |  6     |  58     |  6     |  8     |  84.0     |  165.000    |  50.909\n",
      "1679-bbc                        |  24    |  13    |  98     |  22    |  28    |  157.0    |  263.000    |  59.696\n",
      "1701-wn.de                      |  28    |  3     |  33     |  12    |  23    |  76.0     |  106.000    |  71.698\n",
      "17155-merkur-online.de          |  152   |  26    |  251    |  51    |  61    |  480.0    |  662.000    |  72.508\n",
      "17589-kreis-anzeiger.de         |  137   |  31    |  263    |  41    |  52    |  472.0    |  704.000    |  67.045\n",
      "1790-novinite.com               |  8     |  16    |  49     |  3     |  3     |  76.0     |  133.000    |  57.143\n",
      "1836-euronews-en                |  20    |  10    |  64     |  10    |  12    |  104.0    |  199.000    |  52.261\n",
      "1839-telegraph                  |  28    |  39    |  176    |  21    |  25    |  264.0    |  476.000    |  55.462\n",
      "1858-abcnews                    |  23    |  69    |  158    |  34    |  39    |  284.0    |  464.000    |  61.207\n",
      "1867-ft                         |  31    |  57    |  207    |  43    |  61    |  338.0    |  544.000    |  62.132\n",
      "1878-foxnews                    |  13    |  31    |  105    |  13    |  14    |  162.0    |  302.000    |  53.642\n",
      "191-independent                 |  162   |  296   |  893    |  168   |  192   |  1519.0   |  2855.000   |  53.205\n",
      "1925-upi                        |  17    |  48    |  119    |  26    |  30    |  210.0    |  349.000    |  60.172\n",
      "1973-bbc                        |  29    |  52    |  157    |  28    |  38    |  266.0    |  512.000    |  51.953\n",
      "2000-dailymail.co.uk            |  217   |  249   |  930    |  172   |  214   |  1568.0   |  3591.000   |  43.665\n",
      "2032-bbc                        |  5     |  13    |  36     |  2     |  3     |  56.0     |  101.000    |  55.446\n",
      "2158-foxnews                    |  33    |  51    |  156    |  25    |  28    |  265.0    |  436.000    |  60.780\n",
      "2194-telegraph                  |  354   |  355   |  1535   |  243   |  286   |  2487.0   |  4375.000   |  56.846\n",
      "2252-washpost                   |  53    |  62    |  220    |  54    |  67    |  389.0    |  695.000    |  55.971\n",
      "2318-telegraph                  |  25    |  52    |  112    |  33    |  35    |  222.0    |  347.000    |  63.977\n",
      "232-washpost                    |  84    |  107   |  356    |  76    |  103   |  623.0    |  1198.000   |  52.003\n",
      "2323-bbc                        |  12    |  27    |  65     |  9     |  10    |  113.0    |  180.000    |  62.778\n",
      "2379-news.com.au                |  19    |  30    |  92     |  20    |  27    |  161.0    |  240.000    |  67.083\n",
      "2381-rundschau-online.de        |  175   |  51    |  358    |  69    |  82    |  653.0    |  915.000    |  71.366\n",
      "2708-tagesspiegel.de            |  107   |  22    |  164    |  30    |  46    |  323.0    |  601.000    |  53.744\n",
      "285-mittelbayerische.de         |  111   |  39    |  267    |  51    |  69    |  468.0    |  665.000    |  70.376\n",
      "295-cbsnews                     |  17    |  50    |  147    |  25    |  26    |  239.0    |  444.000    |  53.829\n",
      "2980-haller-kreisblatt.de       |  56    |  17    |  176    |  27    |  38    |  276.0    |  390.000    |  70.769\n",
      "32-novinite.com                 |  17    |  8     |  56     |  8     |  10    |  89.0     |  144.000    |  61.806\n",
      "3470-derstandart.at             |  79    |  29    |  168    |  42    |  64    |  318.0    |  575.000    |  55.304\n",
      "3839-merkur-online.de           |  89    |  20    |  179    |  39    |  54    |  327.0    |  447.000    |  73.154\n",
      "399-news.com.au                 |  32    |  45    |  173    |  33    |  40    |  283.0    |  537.000    |  52.700\n",
      "4050-ntz.de                     |  10    |  6     |  49     |  12    |  17    |  77.0     |  127.000    |  60.630\n",
      "42-washpost                     |  53    |  94    |  311    |  61    |  78    |  519.0    |  916.000    |  56.659\n",
      "4245-frankfurter-rundschau      |  80    |  38    |  178    |  35    |  43    |  331.0    |  641.000    |  51.638\n",
      "444-abcnews                     |  10    |  15    |  40     |  11    |  17    |  76.0     |  153.000    |  49.673\n",
      "4590-an-online.de               |  28    |  9     |  25     |  7     |  9     |  69.0     |  89.000     |  77.528\n",
      "495-news.com.au                 |  18    |  77    |  201    |  41    |  46    |  337.0    |  641.000    |  52.574\n",
      "5391-volksstimme.de             |  114   |  41    |  298    |  40    |  58    |  493.0    |  684.000    |  72.076\n",
      "5805-general-anzeiger-bonn.de   |  31    |  6     |  59     |  13    |  16    |  109.0    |  135.000    |  80.741\n",
      "597-news.com.au                 |  20    |  17    |  81     |  7     |  7     |  125.0    |  228.000    |  54.825\n",
      "6348-merkur-online.de           |  78    |  28    |  238    |  39    |  47    |  383.0    |  598.000    |  64.047\n",
      "685-theglobeandmail.com         |  64    |  43    |  315    |  53    |  67    |  475.0    |  789.000    |  60.203\n",
      "7-telegraph                     |  46    |  52    |  171    |  22    |  27    |  291.0    |  470.000    |  61.915\n",
      "7046-goettinger-tageblatt.de    |  85    |  26    |  149    |  22    |  25    |  282.0    |  448.000    |  62.946\n",
      "740-bbc                         |  5     |  2     |  20     |  8     |  9     |  35.0     |  76.000     |  46.053\n",
      "748-news.com.au                 |  3     |  22    |  46     |  10    |  14    |  81.0     |  150.000    |  54.000\n",
      "7655-volksfreund.de             |  54    |  23    |  117    |  28    |  36    |  222.0    |  357.000    |  62.185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7896-oe24.at                    |  133   |  57    |  317    |  83    |  122   |  590.0    |  932.000    |  63.305\n",
      "7917-mainpost.de                |  61    |  21    |  202    |  39    |  58    |  323.0    |  465.000    |  69.462\n",
      "8108-jungewelt.de               |  103   |  30    |  222    |  44    |  57    |  399.0    |  601.000    |  66.389\n",
      "8152-mittelbayerische.de        |  14    |  9     |  47     |  5     |  6     |  75.0     |  177.000    |  42.373\n",
      "837-telegraph                   |  15    |  61    |  121    |  28    |  35    |  225.0    |  466.000    |  48.283\n",
      "899-reuters                     |  27    |  57    |  138    |  34    |  46    |  256.0    |  502.000    |  50.996\n",
      "918-telegraph                   |  25    |  36    |  114    |  17    |  20    |  192.0    |  263.000    |  73.004\n",
      "940-latimes                     |  49    |  112   |  350    |  66    |  78    |  577.0    |  1044.000   |  55.268\n",
      "949-news.com.au                 |  14    |  43    |  107    |  16    |  22    |  180.0    |  343.000    |  52.478\n",
      "9940-fnp.de                     |  86    |  57    |  308    |  52    |  65    |  503.0    |  727.000    |  69.188\n",
      "TOTAL                           |  4301  |  3589  |  15169  |  2805  |  3546  |  25864.0  |  44260.000  |  58.437\n"
     ]
    }
   ],
   "source": [
    "cat /tmp/newstest2015-ende.kit.de.sgm.sys.sum_doc | sed '1,3d; s/Sent Id/Sent_Id/' | grep -v '^-*$' | column -t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
