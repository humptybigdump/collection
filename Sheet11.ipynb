{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.use_deterministic_algorithms(True)"
      ],
      "metadata": {
        "id": "5L6Vvx1VFdjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1: Digit Image Classifier"
      ],
      "metadata": {
        "id": "YA0svCoGFjD7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot loss history\n",
        "def plot_history(train_history, test_history=None, ylabel=\"\"):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    train_history = np.array(train_history)\n",
        "    plt.plot(train_history[:, 0], train_history[:, 1], label=\"Train history\")\n",
        "\n",
        "    if test_history:\n",
        "        test_history = np.array(test_history)\n",
        "        plt.plot(test_history[:, 0], test_history[:, 1], label=\"Test history\")\n",
        "\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def evaluate(X_test, y_test):\n",
        "    # Evaluate the model using the test set\n",
        "    classifier.eval()\n",
        "    correct = 0\n",
        "    eval_loss = 0.0\n",
        "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
        "    with torch.no_grad():\n",
        "        for X, y in zip(X_test, y_test):\n",
        "            # Unpack batch dimensions\n",
        "            X = X.unsqueeze(0)\n",
        "            y = y.unsqueeze(0)\n",
        "            # Calculate outputs by running images through the network\n",
        "            y_pred = classifier(X)\n",
        "            loss = softmax_loss(y_pred, y)\n",
        "            # The predicted class label is the maximum prediction\n",
        "            predicted = torch.argmax(y_pred, 1)\n",
        "            true = torch.argmax(y, 1)\n",
        "            correct += (predicted == true).sum().item()\n",
        "            eval_loss += loss\n",
        "\n",
        "    eval_loss /= X_test.shape[0]\n",
        "\n",
        "    return eval_loss, correct"
      ],
      "metadata": {
        "id": "tgqeDb6JFiDq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## a) Load and Visualize MNIST Dataset: Utilize sklearn’s datasets to load the MNIST digit dataset, where each image is composed of $8 \\times 8$ pixels and has grayscale values, and plot some samples to understand what the images look like."
      ],
      "metadata": {
        "id": "glbT8_WbIdW6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Load small MNIST dataset using sklearn.datasets.load_digits.\n",
        "\n",
        "# TODO: plot example images from MNIST dataset"
      ],
      "metadata": {
        "id": "1-78DmbgFrIT"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "GLKk0SBQLbkc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Convert labels to one-hot encodings for classification:"
      ],
      "metadata": {
        "id": "v5z3HRl4KuNU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Convert y to be one-hot encoded (this is important for classification!)\n"
      ],
      "metadata": {
        "id": "6bxuEWQHIb3W"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Add a channel dimension to input data, as PyTorch expects inputs of the shape [B, C, H, W (, D)] where B is the batch dimension, C the number of channels of the input, H the image height, W the image width, and, for 3D CNNs, D the depth of the image."
      ],
      "metadata": {
        "id": "EeX4sJw_LUni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Add channel dimension to X (Before (B, H, W), After (B, 1, H, D))\n",
        "# hint: as we have grayscale images the number of channels is one"
      ],
      "metadata": {
        "id": "MQHBvZKKLT8n"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Split the dataset into training and test sets using sklearn’s train_test_split, ensuring a reasonable ratio and shuffling the data."
      ],
      "metadata": {
        "id": "vDhcWau4MDTq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Split up the dataset into train and test sets with a reasonable amount of test samples."
      ],
      "metadata": {
        "id": "N1OOtHG_MJ3Q"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Convert the data for PyTorch: Transform the numpy arrays into PyTorch tensors, preparing them for model input."
      ],
      "metadata": {
        "id": "0Ao3g5QETAOQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Convert numpy arrays to torch tensors"
      ],
      "metadata": {
        "id": "5lhs8n-dTPhq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## c) Build the CNN model architecture using PyTorch:\n",
        "1. Create a CNN class inheriting from nn.Module.\n",
        "2. Define the architecture considering parameters like the input in_channels, n_conv, n_filters, n_-\n",
        "classes, and kernel_size. Consider how many convolutional layers to choose, as well as using pooling layers. For the convolutional layers choose an appropriate border padding\n",
        "mode that preserves the feature maps’ shape dimensions during feature extraction.\n",
        "3. Use ReLU activations for intermediate layers and the softmax activation for the output layer. The\n",
        "softmax function $z(x_i)$ is defined as\n",
        "<center>$z(x_i) = \\frac{e^{x_i}}{\\sum_j e^{x_j}}$\n",
        "\n",
        "  for each element $x_i$ in the input vector. In multi-class classification, softmax is used at the output layer because it transforms the outputs into probability distributions. Each output value represents the probability that the input belongs to one of the classes. This is particularly useful for classification tasks like digit recognition, where each class (digit) is mutually exclusive."
      ],
      "metadata": {
        "id": "j_sGPBbTTdPQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, in_channels=1, n_conv=8, n_filters=128, n_classes=10, kernel_size=(3, 3)):\n",
        "        super(CNN, self).__init__()\n",
        "        # TODO: define the network architecture\n",
        "\n",
        "        self.n_conv = n_conv\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO: define how input is propagated through the layers AND activation functions\n",
        "        return x\n",
        "\n",
        "    # Count trainable weights\n",
        "    def count_parameters(self):\n",
        "        return sum(p.numel() for p in self.parameters() if p.requires_grad)"
      ],
      "metadata": {
        "id": "GAKS1iF_Fswk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "ebdcd365-8431-4553-8830-371f93c0c545"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'nn' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-cd1606081b9c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_conv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_filters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;31m# TODO: define the network architecture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## e) Define hyperparameters for training. Therefore, set the number of epochs to train, the learning rate, and other relevant parameters, such as the number of convolutional filters and the number of hidden units. (There is not one correct solution. You can try out different parameters and see what the outcome of your training is.)"
      ],
      "metadata": {
        "id": "njn_seESWQb2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Define hyperparameters"
      ],
      "metadata": {
        "id": "MYaHXPwmFuE7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## f) Initialize and analyze the model architecture: Print the number of trainable parameters, choose an optimizer like Stochastic Gradient Descent (SGD) that accepts both the learning rate and model parameters, and define the loss function (cross entropy loss). Check initial loss before training and evaluate the model on the test set using the evaluate(...) function of the CNN."
      ],
      "metadata": {
        "id": "UWL4hxs5WW6h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Initialize CNN\n",
        "\n",
        "# TODO: Print number of trainable weights\n",
        "\n",
        "# TODO: Setup optimizer and define loss function\n",
        "\n",
        "# TODO: Evaluate the classification model on testset"
      ],
      "metadata": {
        "id": "UlMSBthyFukX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## g) Training Process: Implement the loop over n epochs. For each epoch:\n",
        "1. Zero the parameter gradients.\n",
        "2. Forward pass the training images to calculate predictions.\n",
        "3. Compute loss between prediction y_pred and y_train.\n",
        "4. Perform a backward pass.\n",
        "5. Update network parameters.\n",
        "6. Evaluate on the test set periodically, log and track the training and test losses."
      ],
      "metadata": {
        "id": "13iOYfy5WoyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Train the model using the training set\n",
        "# store training and testing loss and accuracy history for later visualization\n",
        "\n",
        "# TODO: implement training loop\n",
        "for epoch in range(0, n_epochs):\n",
        "    # TODO: zero the parameter gradients\n",
        "\n",
        "    # TODO: forward pass\n",
        "\n",
        "    # TODO: calculate loss\n",
        "\n",
        "    # TODO: Backward pass\n",
        "\n",
        "    # TODO: Optimize\n",
        "\n",
        "    # TODO: Track and log losses\n",
        "\n",
        "# TODO: Evaluate the classification model on testset\n",
        "# you can use the function evaluate() for this"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "sL1QsiXlWn9q",
        "outputId": "4cd7f75b-416f-4a75-e385-4ee770ebd86c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "incomplete input (<ipython-input-9-c0b336c8d1e3>, line 19)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-c0b336c8d1e3>\"\u001b[0;36m, line \u001b[0;32m19\u001b[0m\n\u001b[0;31m    # you can use the function evaluate() for this\u001b[0m\n\u001b[0m                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## g) Plot results of the training and test loss history over epochs and plot the accuracy on the test set over epochs. If your training is not successful try to find possible solutions. Maybe your network size is to small. Try changing the number of filters in each convolutional layer or the number of convolutional layers."
      ],
      "metadata": {
        "id": "6hyf9bZFXEPq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Plot loss history over epochs\n",
        "# you can use the function plot_history for this\n"
      ],
      "metadata": {
        "id": "GdKuH2UzFxp0"
      },
      "execution_count": 1,
      "outputs": []
    }
  ]
}