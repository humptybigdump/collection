{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "581012"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn.datasets\n",
    "\n",
    "dataset = sklearn.datasets.fetch_covtype(shuffle=True, random_state=42)\n",
    "len(dataset.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name | Data Type | Measurement | Description\n",
    "-----|-----------|-------------|------------\n",
    "Elevation | quantitative |meters | Elevation in meters\n",
    "Aspect | quantitative | azimuth | Aspect in degrees azimuth\n",
    "Slope | quantitative | degrees | Slope in degrees\n",
    "Horizontal_Distance_To_Hydrology | quantitative | meters | Horz Dist to nearest surface water features\n",
    "Vertical_Distance_To_Hydrology | quantitative | meters | Vert Dist to nearest surface water features\n",
    "Horizontal_Distance_To_Roadways | quantitative | meters | Horz Dist to nearest roadway\n",
    "Hillshade_9am | quantitative | 0 to 255 index | Hillshade index at 9am, summer solstice\n",
    "Hillshade_Noon | quantitative | 0 to 255 index | Hillshade index at noon, summer soltice\n",
    "Hillshade_3pm | quantitative | 0 to 255 index | Hillshade index at 3pm, summer solstice\n",
    "Horizontal_Distance_To_Fire_Points | quantitative | meters | Horz Dist to nearest wildfire ignition points\n",
    "Wilderness_Area (4 binary columns) | qualitative | 0 (absence) or 1 (presence) | Wilderness area designation\n",
    "Soil_Type (40 binary columns) | qualitative | 0 (absence) or 1 (presence) | Soil Type designation\n",
    "Cover_Type (7 types) | integer | 1 to 7 | Forest Cover Type designation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.351e+03, 2.060e+02, 2.700e+01, 7.260e+02, 1.240e+02, 3.813e+03,\n",
       "       1.920e+02, 2.520e+02, 1.800e+02, 2.271e+03, 1.000e+00, 0.000e+00,\n",
       "       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "       0.000e+00, 0.000e+00, 0.000e+00, 1.000e+00, 0.000e+00, 0.000e+00])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     0, 211840, 283301,  35754,   2747,   9493,  17367,  20510],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(dataset.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_input_features = dataset.data.shape[1]\n",
    "num_input_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = dataset.target.max()\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dev_samples = num_test_samples = len(dataset.data) // 10\n",
    "num_train_samples = len(dataset.data) - num_dev_samples - num_test_samples\n",
    "training_data = {\"features\": dataset.data[:num_train_samples], \"labels\": dataset.target[:num_train_samples]}\n",
    "dev_data = {\"features\": dataset.data[num_train_samples:num_train_samples+num_dev_samples],\n",
    "       \"labels\": dataset.target[num_train_samples:num_train_samples+num_dev_samples]}\n",
    "test_data = {\"features\": dataset.data[-num_test_samples:],\n",
    "       \"labels\": dataset.target[-num_test_samples:]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def softmax(x):\n",
    "    expx = np.exp(x)\n",
    "    return expx / np.sum(expx)\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, num_input_features, num_hidden_features, num_output_features):\n",
    "        self.weights1 = np.random.normal(0, 0.25, (num_input_features, num_hidden_features))\n",
    "        self.biases1 = np.zeros((num_hidden_features,))\n",
    "        self.weights2 = np.random.normal(0, 0.25, (num_hidden_features, num_output_features))\n",
    "        self.biases2 = np.zeros((num_output_features,))\n",
    "    \n",
    "    def predict(self, features, label=None):\n",
    "        hidden_features = sigmoid(np.matmul(features, self.weights1) + self.biases1)\n",
    "        output_features = softmax(np.matmul(hidden_features, self.weights2) + self.biases2)\n",
    "        if label is not None:\n",
    "            loss = -np.log(output_features[label])\n",
    "            return output_features, loss\n",
    "        return output_features\n",
    "    \n",
    "    def compute_loss_and_gradients(self, features, label):\n",
    "        hidden_preactivations = np.matmul(features, self.weights1) + self.biases1\n",
    "        hidden_features = sigmoid(hidden_preactivations)\n",
    "        output_preactivations = np.matmul(hidden_features, self.weights2) + self.biases2\n",
    "        output_features = softmax(output_preactivations)\n",
    "        loss = -np.log(output_features[label])\n",
    "        \n",
    "        output_preactivations_gradients = output_features\n",
    "        output_preactivations_gradients[label] -= 1\n",
    "        \n",
    "        biases2_gradients = output_preactivations_gradients\n",
    "        weights2_gradients = np.outer(hidden_features, output_preactivations_gradients)\n",
    "        hidden_features_gradients = np.matmul(output_preactivations_gradients, self.weights2.T)\n",
    "        \n",
    "        hidden_preactivations_gradients = hidden_features_gradients * (hidden_features * (1 - hidden_features))\n",
    "        biases1_gradients = hidden_preactivations_gradients\n",
    "        weights1_gradients = np.outer(features, hidden_preactivations_gradients)\n",
    "        return loss, (weights1_gradients, biases1_gradients, weights2_gradients, biases2_gradients)\n",
    "    \n",
    "    def update_parameters(self, gradients, learning_rate):\n",
    "        parameters = (self.weights1, self.biases1, self.weights2, self.biases2)\n",
    "        for param, grad in zip(parameters, gradients):\n",
    "            param -= grad * learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = np.mean(training_data[\"features\"], axis=0)\n",
    "stds = np.std(training_data[\"features\"], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/464810: train 2.47 | dev 1.90\n",
      "20000/464810: train 0.93 | dev 0.79\n",
      "40000/464810: train 0.84 | dev 0.73\n",
      "60000/464810: train 0.80 | dev 0.72\n",
      "80000/464810: train 0.78 | dev 0.71\n",
      "100000/464810: train 0.76 | dev 0.70\n",
      "120000/464810: train 0.75 | dev 0.69\n",
      "140000/464810: train 0.74 | dev 0.69\n",
      "160000/464810: train 0.74 | dev 0.68\n",
      "180000/464810: train 0.73 | dev 0.68\n",
      "200000/464810: train 0.73 | dev 0.68\n",
      "220000/464810: train 0.72 | dev 0.67\n",
      "240000/464810: train 0.72 | dev 0.67\n",
      "260000/464810: train 0.71 | dev 0.66\n",
      "280000/464810: train 0.71 | dev 0.66\n",
      "300000/464810: train 0.71 | dev 0.66\n",
      "320000/464810: train 0.70 | dev 0.66\n",
      "340000/464810: train 0.70 | dev 0.66\n",
      "360000/464810: train 0.70 | dev 0.66\n",
      "380000/464810: train 0.70 | dev 0.66\n",
      "400000/464810: train 0.69 | dev 0.65\n",
      "420000/464810: train 0.69 | dev 0.65\n",
      "440000/464810: train 0.69 | dev 0.65\n",
      "460000/464810: train 0.69 | dev 0.65\n"
     ]
    }
   ],
   "source": [
    "model = Model(num_input_features, 4, num_classes)\n",
    "\n",
    "learning_rate = 0.005\n",
    "evaluate_every = 20000\n",
    "train_log = []\n",
    "dev_log = []\n",
    "train_losses = []\n",
    "\n",
    "for step in range(num_train_samples):\n",
    "    features = training_data[\"features\"][step]\n",
    "    features = (features - means) / stds\n",
    "    label = training_data[\"labels\"][step] - 1\n",
    "    \n",
    "    loss, gradients = model.compute_loss_and_gradients(features, label)\n",
    "    train_losses.append(loss)\n",
    "    \n",
    "    if step % evaluate_every == 0:\n",
    "        dev_losses = []\n",
    "        for j in range(num_dev_samples):\n",
    "            dev_features = dev_data[\"features\"][j]\n",
    "            dev_features = (dev_features - means) / stds\n",
    "            dev_label = dev_data[\"labels\"][j] - 1\n",
    "            dev_output, dev_loss = model.predict(dev_features, dev_label)\n",
    "            dev_losses.append(dev_loss)\n",
    "        \n",
    "        dev_mean_loss = np.mean(dev_losses)\n",
    "        dev_log.append(dev_mean_loss)\n",
    "        train_mean_loss = np.mean(train_losses)\n",
    "        train_log.append(train_mean_loss)\n",
    "        print(f\"{step}/{num_train_samples}: train {train_mean_loss:.2f} | dev {dev_mean_loss:.2f}\")\n",
    "    \n",
    "    model.update_parameters(gradients, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.arange(len(train_log)) * evaluate_every, train_log)\n",
    "plt.plot(np.arange(len(dev_log)) * evaluate_every, dev_log)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 73.4%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for i in range(num_test_samples):\n",
    "    features = test_data[\"features\"][i]\n",
    "    features = (features - means) / stds\n",
    "    label = test_data[\"labels\"][i] - 1\n",
    "    prediction = model.predict(features).argmax()\n",
    "    if prediction == label:\n",
    "        correct += 1\n",
    "accuracy = correct / num_test_samples\n",
    "print(f\"Test Accuracy: {accuracy:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
